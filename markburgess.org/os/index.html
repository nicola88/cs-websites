<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 99.2beta6 (1.42)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>A short introduction to operating systems</TITLE>
<META NAME="description" CONTENT="A short introduction to operating systems">
<META NAME="keywords" CONTENT="os">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v99.2beta6">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="os.css">

</HEAD>

<BODY >
<!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive"
 SRC="http://markburgess.org/usr/share/latex2html/icons/nx_grp_g.png"> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://markburgess.org/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://markburgess.org/usr/share/latex2html/icons/prev_g.png">   
<BR>
<BR>
<BR>
<!--End of Navigation Panel-->
<H1 ALIGN="CENTER">A short introduction to operating systems</H1>
<P ALIGN="CENTER"><STRONG>Mark Burgess</STRONG></P>
<P ALIGN="CENTER"><STRONG>October 3, 2001</STRONG></P>
<BR>

<H2><A NAME="SECTION00100000000000000000">
Contents</A>
</H2>
<!--Table of Contents-->

<UL>
<LI><A NAME="tex2html535"
  HREF="os.html">Contents</A>
<LI><A NAME="tex2html536"
  HREF="os.html#SECTION00200000000000000000">1. What is an operating system?</A>
<UL>
<LI><A NAME="tex2html537"
  HREF="os.html#SECTION00210000000000000000">1.1 Key concepts</A>
<UL>
<LI><A NAME="tex2html538"
  HREF="os.html#SECTION00211000000000000000">1.1.1 Hierarchies and black boxes</A>
<LI><A NAME="tex2html539"
  HREF="os.html#SECTION00212000000000000000">1.1.2 Resources and sharing</A>
<LI><A NAME="tex2html540"
  HREF="os.html#SECTION00213000000000000000">1.1.3 Communication, protocols, data types</A>
<LI><A NAME="tex2html541"
  HREF="os.html#SECTION00214000000000000000">1.1.4 System overhead</A>
<LI><A NAME="tex2html542"
  HREF="os.html#SECTION00215000000000000000">1.1.5 Caching</A>
</UL>
<LI><A NAME="tex2html543"
  HREF="os.html#SECTION00220000000000000000">1.2 Hardware</A>
<UL>
<LI><A NAME="tex2html544"
  HREF="os.html#SECTION00221000000000000000">1.2.1 The CPU</A>
<LI><A NAME="tex2html545"
  HREF="os.html#SECTION00222000000000000000">1.2.2 Memory</A>
<LI><A NAME="tex2html546"
  HREF="os.html#SECTION00223000000000000000">1.2.3 Devices</A>
<LI><A NAME="tex2html547"
  HREF="os.html#SECTION00224000000000000000">1.2.4 Interrupts, traps, exceptions</A>
</UL>
<LI><A NAME="tex2html548"
  HREF="os.html#SECTION00230000000000000000">1.3 Software</A>
<UL>
<LI><A NAME="tex2html549"
  HREF="os.html#SECTION00231000000000000000">1.3.1 Resource management</A>
<LI><A NAME="tex2html550"
  HREF="os.html#SECTION00232000000000000000">1.3.2 Spooling</A>
<LI><A NAME="tex2html551"
  HREF="os.html#SECTION00233000000000000000">1.3.3 System calls</A>
<LI><A NAME="tex2html552"
  HREF="os.html#SECTION00234000000000000000">1.3.4 Basic command language</A>
<LI><A NAME="tex2html553"
  HREF="os.html#SECTION00235000000000000000">1.3.5 Filesystem</A>
<LI><A NAME="tex2html554"
  HREF="os.html#SECTION00236000000000000000">1.3.6 Multiple windows and screens</A>
</UL>
<LI><A NAME="tex2html555"
  HREF="os.html#SECTION00240000000000000000">Note</A>
<LI><A NAME="tex2html556"
  HREF="os.html#SECTION00250000000000000000">Exercises</A>
</UL>
<LI><A NAME="tex2html557"
  HREF="os.html#SECTION00300000000000000000">2. Single-task OS</A>
<UL>
<LI><A NAME="tex2html558"
  HREF="os.html#SECTION00310000000000000000">2.1 Memory map and registers</A>
<LI><A NAME="tex2html559"
  HREF="os.html#SECTION00320000000000000000">2.2 Stack</A>
<LI><A NAME="tex2html560"
  HREF="os.html#SECTION00330000000000000000">2.3 Input/Output</A>
<UL>
<LI><A NAME="tex2html561"
  HREF="os.html#SECTION00331000000000000000">2.3.1 Interrupts</A>
<LI><A NAME="tex2html562"
  HREF="os.html#SECTION00332000000000000000">2.3.2 Buffers</A>
<LI><A NAME="tex2html563"
  HREF="os.html#SECTION00333000000000000000">2.3.3 Synchronous and asynchronous I/O</A>
<LI><A NAME="tex2html564"
  HREF="os.html#SECTION00334000000000000000">2.3.4 DMA - Direct Memory Access</A>
</UL>
<LI><A NAME="tex2html565"
  HREF="os.html#SECTION00340000000000000000">Exercises</A>
</UL>
<LI><A NAME="tex2html566"
  HREF="os.html#SECTION00400000000000000000">3. Multi-tasking and multi-user OS</A>
<UL>
<LI><A NAME="tex2html567"
  HREF="os.html#SECTION00410000000000000000">3.1 Competition for resources</A>
<UL>
<LI><A NAME="tex2html568"
  HREF="os.html#SECTION00411000000000000000">3.1.1 Users - authentication</A>
<LI><A NAME="tex2html569"
  HREF="os.html#SECTION00412000000000000000">3.1.2 Privileges and security</A>
<LI><A NAME="tex2html570"
  HREF="os.html#SECTION00413000000000000000">3.1.3 Tasks - two-mode operation</A>
<LI><A NAME="tex2html571"
  HREF="os.html#SECTION00414000000000000000">3.1.4 I/O and Memory protection</A>
<LI><A NAME="tex2html572"
  HREF="os.html#SECTION00415000000000000000">3.1.5 Time sharing</A>
</UL>
<LI><A NAME="tex2html573"
  HREF="os.html#SECTION00420000000000000000">3.2 Memory map</A>
<LI><A NAME="tex2html574"
  HREF="os.html#SECTION00430000000000000000">3.3 Kernel and shells - layers of software</A>
<LI><A NAME="tex2html575"
  HREF="os.html#SECTION00440000000000000000">3.4 Services: daemons</A>
<LI><A NAME="tex2html576"
  HREF="os.html#SECTION00450000000000000000">3.5 Multiprocessors - parallelism</A>
<LI><A NAME="tex2html577"
  HREF="os.html#SECTION00460000000000000000">Exercises</A>
</UL>
<LI><A NAME="tex2html578"
  HREF="os.html#SECTION00500000000000000000">4. Processes and Thread</A>
<UL>
<LI><A NAME="tex2html579"
  HREF="os.html#SECTION00510000000000000000">4.1 Key concepts</A>
<UL>
<LI><A NAME="tex2html580"
  HREF="os.html#SECTION00511000000000000000">4.1.1 Naming conventions</A>
<LI><A NAME="tex2html581"
  HREF="os.html#SECTION00512000000000000000">4.1.2 Scheduling</A>
<LI><A NAME="tex2html582"
  HREF="os.html#SECTION00513000000000000000">4.1.3 Scheduling hierarchy</A>
<LI><A NAME="tex2html583"
  HREF="os.html#SECTION00514000000000000000">4.1.4 Runs levels - priority</A>
<LI><A NAME="tex2html584"
  HREF="os.html#SECTION00515000000000000000">4.1.5 Context switching</A>
<LI><A NAME="tex2html585"
  HREF="os.html#SECTION00516000000000000000">4.1.6 Interprocess communication</A>
</UL>
<LI><A NAME="tex2html586"
  HREF="os.html#SECTION00520000000000000000">4.2 Creation and scheduling</A>
<UL>
<LI><A NAME="tex2html587"
  HREF="os.html#SECTION00521000000000000000">4.2.1 Creating processes</A>
<LI><A NAME="tex2html588"
  HREF="os.html#SECTION00522000000000000000">4.2.2 Process hierarchy: children and parent processes</A>
<LI><A NAME="tex2html589"
  HREF="os.html#SECTION00523000000000000000">4.2.3 Unix: fork() and wait()</A>
<LI><A NAME="tex2html590"
  HREF="os.html#SECTION00524000000000000000">4.2.4 Process states</A>
<LI><A NAME="tex2html591"
  HREF="os.html#SECTION00525000000000000000">4.2.5 Queue scheduling</A>
<LI><A NAME="tex2html592"
  HREF="os.html#SECTION00526000000000000000">4.2.6 Round-robin scheduling</A>
<LI><A NAME="tex2html593"
  HREF="os.html#SECTION00527000000000000000">4.2.7 CPU quotas and accounting</A>
</UL>
<LI><A NAME="tex2html594"
  HREF="os.html#SECTION00530000000000000000">4.3 Threads</A>
<UL>
<LI><A NAME="tex2html595"
  HREF="os.html#SECTION00531000000000000000">4.3.1 Heavy and lightweight processes</A>
<LI><A NAME="tex2html596"
  HREF="os.html#SECTION00532000000000000000">4.3.2 Why use threads?</A>
<LI><A NAME="tex2html597"
  HREF="os.html#SECTION00533000000000000000">4.3.3 Levels of threads</A>
<LI><A NAME="tex2html598"
  HREF="os.html#SECTION00534000000000000000">4.3.4 Symmetric and asymmetric multiprocessing</A>
<LI><A NAME="tex2html599"
  HREF="os.html#SECTION00535000000000000000">4.3.5 Example: POSIX pthreads</A>
<LI><A NAME="tex2html600"
  HREF="os.html#SECTION00536000000000000000">4.3.6 Example: LWPs in Solaris 1</A>
</UL>
<LI><A NAME="tex2html601"
  HREF="os.html#SECTION00540000000000000000">4.4 Synchronization of processes and threads</A>
<UL>
<LI><A NAME="tex2html602"
  HREF="os.html#SECTION00541000000000000000">4.4.1 Problems with sharing for processes</A>
<LI><A NAME="tex2html603"
  HREF="os.html#SECTION00542000000000000000">4.4.2 Serialization</A>
<LI><A NAME="tex2html604"
  HREF="os.html#SECTION00543000000000000000">4.4.3 Mutexes: mutual exclusion</A>
<LI><A NAME="tex2html605"
  HREF="os.html#SECTION00544000000000000000">4.4.4 User synchronization: file locks</A>
<LI><A NAME="tex2html606"
  HREF="os.html#SECTION00545000000000000000">4.4.5 Exclusive and non-exclusive locks</A>
<LI><A NAME="tex2html607"
  HREF="os.html#SECTION00546000000000000000">4.4.6 Critical sections: the mutex solution</A>
<LI><A NAME="tex2html608"
  HREF="os.html#SECTION00547000000000000000">4.4.7 Flags and semaphores</A>
<LI><A NAME="tex2html609"
  HREF="os.html#SECTION00548000000000000000">4.4.8 Monitors</A>
</UL>
<LI><A NAME="tex2html610"
  HREF="os.html#SECTION00550000000000000000">4.5 Deadlock</A>
<UL>
<LI><A NAME="tex2html611"
  HREF="os.html#SECTION00551000000000000000">4.5.1 Cause</A>
<LI><A NAME="tex2html612"
  HREF="os.html#SECTION00552000000000000000">4.5.2 Prevention</A>
<LI><A NAME="tex2html613"
  HREF="os.html#SECTION00553000000000000000">4.5.3 Detection</A>
<LI><A NAME="tex2html614"
  HREF="os.html#SECTION00554000000000000000">4.5.4 Recovery</A>
</UL>
<LI><A NAME="tex2html615"
  HREF="os.html#SECTION00560000000000000000">4.6 Summary</A>
<LI><A NAME="tex2html616"
  HREF="os.html#SECTION00570000000000000000">Exercises</A>
<LI><A NAME="tex2html617"
  HREF="os.html#SECTION00580000000000000000">Project</A>
</UL>
<LI><A NAME="tex2html618"
  HREF="os.html#SECTION00600000000000000000">5. Memory and storage</A>
<UL>
<LI><A NAME="tex2html619"
  HREF="os.html#SECTION00610000000000000000">5.1 Logical and Physical Memory</A>
<UL>
<LI><A NAME="tex2html620"
  HREF="os.html#SECTION00611000000000000000">5.1.1 Physical Address space</A>
<LI><A NAME="tex2html621"
  HREF="os.html#SECTION00612000000000000000">5.1.2 Word size</A>
<LI><A NAME="tex2html622"
  HREF="os.html#SECTION00613000000000000000">5.1.3 Paged RAM/ROM</A>
<LI><A NAME="tex2html623"
  HREF="os.html#SECTION00614000000000000000">5.1.4 Address binding - coexistence in memory</A>
<LI><A NAME="tex2html624"
  HREF="os.html#SECTION00615000000000000000">5.1.5 Shared libraries</A>
<LI><A NAME="tex2html625"
  HREF="os.html#SECTION00616000000000000000">5.1.6 Runtime binding</A>
<LI><A NAME="tex2html626"
  HREF="os.html#SECTION00617000000000000000">5.1.7 Segmentation - sharing</A>
<LI><A NAME="tex2html627"
  HREF="os.html#SECTION00618000000000000000">5.1.8 The malloc() function</A>
<LI><A NAME="tex2html628"
  HREF="os.html#SECTION00619000000000000000">5.1.9 Page size, fragmentation and alignment</A>
<LI><A NAME="tex2html629"
  HREF="os.html#SECTION006110000000000000000">5.1.10 Reclaiming fragmented memory (Tetris!)</A>
</UL>
<LI><A NAME="tex2html630"
  HREF="os.html#SECTION00620000000000000000">5.2 Virtual Memory</A>
<UL>
<LI><A NAME="tex2html631"
  HREF="os.html#SECTION00621000000000000000">5.2.1 Paging and Swapping</A>
<LI><A NAME="tex2html632"
  HREF="os.html#SECTION00622000000000000000">5.2.2 Demand Paging - Lazy evaluation</A>
<LI><A NAME="tex2html633"
  HREF="os.html#SECTION00623000000000000000">5.2.3 Swapping and paging algorithms</A>
<LI><A NAME="tex2html634"
  HREF="os.html#SECTION00624000000000000000">5.2.4 Thrashing</A>
</UL>
<LI><A NAME="tex2html635"
  HREF="os.html#SECTION00630000000000000000">5.3 Disks: secondary storage</A>
<UL>
<LI><A NAME="tex2html636"
  HREF="os.html#SECTION00631000000000000000">5.3.1 Physical structure</A>
<LI><A NAME="tex2html637"
  HREF="os.html#SECTION00632000000000000000">5.3.2 Device drivers and IDs</A>
<LI><A NAME="tex2html638"
  HREF="os.html#SECTION00633000000000000000">5.3.3 Checking data consistency and formatting</A>
<LI><A NAME="tex2html639"
  HREF="os.html#SECTION00634000000000000000">5.3.4 Scheduling</A>
<LI><A NAME="tex2html640"
  HREF="os.html#SECTION00635000000000000000">5.3.5 Partitions</A>
<LI><A NAME="tex2html641"
  HREF="os.html#SECTION00636000000000000000">5.3.6 Stripes</A>
</UL>
<LI><A NAME="tex2html642"
  HREF="os.html#SECTION00640000000000000000">5.4 Disk Filesystems</A>
<UL>
<LI><A NAME="tex2html643"
  HREF="os.html#SECTION00641000000000000000">5.4.1 Hierachical filesystems and links</A>
<LI><A NAME="tex2html644"
  HREF="os.html#SECTION00642000000000000000">5.4.2 File types and device nodes</A>
<LI><A NAME="tex2html645"
  HREF="os.html#SECTION00643000000000000000">5.4.3 Permissions and access</A>
<LI><A NAME="tex2html646"
  HREF="os.html#SECTION00644000000000000000">5.4.4 File system protocols</A>
<LI><A NAME="tex2html647"
  HREF="os.html#SECTION00645000000000000000">5.4.5 Filesystem implementation and storage</A>
<LI><A NAME="tex2html648"
  HREF="os.html#SECTION00646000000000000000">5.4.6 The UNIX <EM>ufs</EM> filesystem</A>
</UL>
<LI><A NAME="tex2html649"
  HREF="os.html#SECTION00650000000000000000">Exercises</A>
<LI><A NAME="tex2html650"
  HREF="os.html#SECTION00660000000000000000">Project</A>
</UL>
<LI><A NAME="tex2html651"
  HREF="os.html#SECTION00700000000000000000">6. Networks: Services and protocols</A>
<UL>
<LI><A NAME="tex2html652"
  HREF="os.html#SECTION00710000000000000000">6.1 Services: the client-server model</A>
<LI><A NAME="tex2html653"
  HREF="os.html#SECTION00720000000000000000">6.2 Communication and protocol</A>
<LI><A NAME="tex2html654"
  HREF="os.html#SECTION00730000000000000000">6.3 Services and Ports</A>
<LI><A NAME="tex2html655"
  HREF="os.html#SECTION00740000000000000000">6.4 UNIX client-server implementation</A>
<UL>
<LI><A NAME="tex2html656"
  HREF="os.html#SECTION00741000000000000000">6.4.1 Socket based communication</A>
<LI><A NAME="tex2html657"
  HREF="os.html#SECTION00742000000000000000">6.4.2 RPC services</A>
</UL>
<LI><A NAME="tex2html658"
  HREF="os.html#SECTION00750000000000000000">6.5 The telnet command</A>
<LI><A NAME="tex2html659"
  HREF="os.html#SECTION00760000000000000000">6.6 X11</A>
<LI><A NAME="tex2html660"
  HREF="os.html#SECTION00770000000000000000">6.7 html: hypertext markup language</A>
<LI><A NAME="tex2html661"
  HREF="os.html#SECTION00780000000000000000">Exercises</A>
<LI><A NAME="tex2html662"
  HREF="os.html#SECTION00790000000000000000">Project</A>
</UL>
<LI><A NAME="tex2html663"
  HREF="os.html#SECTION00800000000000000000">7. TCP/IP Networks</A>
<UL>
<LI><A NAME="tex2html664"
  HREF="os.html#SECTION00810000000000000000">7.1 The protocol hierarchy</A>
<UL>
<LI><A NAME="tex2html665"
  HREF="os.html#SECTION00811000000000000000">7.1.1 The OSI model</A>
<LI><A NAME="tex2html666"
  HREF="os.html#SECTION00812000000000000000">7.1.2 Data encapsulation</A>
</UL>
<LI><A NAME="tex2html667"
  HREF="os.html#SECTION00820000000000000000">7.2 The internet protocol family</A>
<UL>
<LI><A NAME="tex2html668"
  HREF="os.html#SECTION00821000000000000000">7.2.1 udp</A>
<LI><A NAME="tex2html669"
  HREF="os.html#SECTION00822000000000000000">7.2.2 tcp</A>
</UL>
<LI><A NAME="tex2html670"
  HREF="os.html#SECTION00830000000000000000">7.3 The physical layer</A>
<UL>
<LI><A NAME="tex2html671"
  HREF="os.html#SECTION00831000000000000000">7.3.1 Network connectivity</A>
<LI><A NAME="tex2html672"
  HREF="os.html#SECTION00832000000000000000">7.3.2 Ethernet addresses</A>
</UL>
<LI><A NAME="tex2html673"
  HREF="os.html#SECTION00840000000000000000">7.4 Internet Addresses and Routing</A>
<UL>
<LI><A NAME="tex2html674"
  HREF="os.html#SECTION00841000000000000000">7.4.1 IP addresses, networks and domain names</A>
<LI><A NAME="tex2html675"
  HREF="os.html#SECTION00842000000000000000">7.4.2 Netmask and broadcast address</A>
<LI><A NAME="tex2html676"
  HREF="os.html#SECTION00843000000000000000">7.4.3 Routers and gateways</A>
</UL>
<LI><A NAME="tex2html677"
  HREF="os.html#SECTION00850000000000000000">7.5 Network Naming services</A>
<UL>
<LI><A NAME="tex2html678"
  HREF="os.html#SECTION00851000000000000000">7.5.1 The Domain Name Service</A>
<LI><A NAME="tex2html679"
  HREF="os.html#SECTION00852000000000000000">7.5.2 Network Information Service</A>
</UL>
<LI><A NAME="tex2html680"
  HREF="os.html#SECTION00860000000000000000">7.6 Distributed Filesystems</A>
<UL>
<LI><A NAME="tex2html681"
  HREF="os.html#SECTION00861000000000000000">7.6.1 NFS - the network filesystem</A>
<LI><A NAME="tex2html682"
  HREF="os.html#SECTION00862000000000000000">7.6.2 AFS - the andrew filesystem</A>
<LI><A NAME="tex2html683"
  HREF="os.html#SECTION00863000000000000000">7.6.3 DCE - the distributed computing environment</A>
</UL>
</UL>
<LI><A NAME="tex2html684"
  HREF="os.html#SECTION00900000000000000000">8. Security: design considerations</A>
<UL>
<LI><A NAME="tex2html685"
  HREF="os.html#SECTION00910000000000000000">8.1 Who is responsible?</A>
<LI><A NAME="tex2html686"
  HREF="os.html#SECTION00920000000000000000">8.2 Passwords and encryption</A>
<UL>
<LI><A NAME="tex2html687"
  HREF="os.html#SECTION00921000000000000000">8.2.1 UNIX passwords</A>
<LI><A NAME="tex2html688"
  HREF="os.html#SECTION00922000000000000000">8.2.2 Bad passwords</A>
</UL>
<LI><A NAME="tex2html689"
  HREF="os.html#SECTION00930000000000000000">8.3 Super-user, or system administrator</A>
<UL>
<LI><A NAME="tex2html690"
  HREF="os.html#SECTION00931000000000000000">8.3.1 Network administration</A>
<LI><A NAME="tex2html691"
  HREF="os.html#SECTION00932000000000000000">8.3.2 Setuid programs in unix</A>
</UL>
<LI><A NAME="tex2html692"
  HREF="os.html#SECTION00940000000000000000">8.4 Backups</A>
<LI><A NAME="tex2html693"
  HREF="os.html#SECTION00950000000000000000">8.5 Intruders: Worms and Viruses</A>
<UL>
<LI><A NAME="tex2html694"
  HREF="os.html#SECTION00951000000000000000">8.5.1 Back doors</A>
</UL>
<LI><A NAME="tex2html695"
  HREF="os.html#SECTION00960000000000000000">8.6 Firewall</A>
<LI><A NAME="tex2html696"
  HREF="os.html#SECTION00970000000000000000">8.7 Public and Private Keys</A>
</UL>
<LI><A NAME="tex2html697"
  HREF="os.html#SECTION001000000000000000000">Where next?</A>
<UL>
<LI><A NAME="tex2html698"
  HREF="os.html#SECTION001010000000000000000">Glossary</A>
</UL>
<LI><A NAME="tex2html699"
  HREF="os.html#SECTION001100000000000000000">Index</A>
<LI><A NAME="tex2html700"
  HREF="os.html#SECTION001200000000000000000">About this document ...</A>
</UL>
<!--End of Table of Contents-->
<P>

<P>

<H1><A NAME="SECTION00200000000000000000">
1. What is an operating system?</A>
</H1>

<P>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
An operating system is a layer of software which takes care of 
technical aspects of a computer's operation. 
<A NAME="29"></A> It shields the user 
of the machine from the low-level details of the machine's operation
and provides frequently needed facilities.  There is no universal
definition of what an operating system consists of. You can think of
it as being the software which is already installed on a machine,
before you add anything of your own. Normally the operating system has
a number of key elements: (i) a <EM>technical layer of software</EM> for
driving the hardware of the computer, like disk drives, the keyboard
and the screen; (ii) a <EM>filesystem</EM> which provides a way of
organizing files logically, and (iii) a simple <EM>command
language</EM><A NAME="33"></A> which enables users to run their own
programs and to manipulate their files in a simple way.  Some
operating systems also provide text editors, compilers, debuggers and
a variety of other tools. Since the operating system (OS) is in charge
of a computer, all requests to use its resources and devices need to
go through the OS. An OS therefore provides (iv) <EM>legal entry
points</EM>
<A NAME="35"></A>
into its code for performing basic operations like writing to devices.

<P>
Operating systems may be classified by both how many tasks they can
perform `simultaneously' and by how many users can be using the system
`simultaneously'. That is: <EM>single-user</EM><A NAME="37"></A>
or <EM>multi-user</EM><A NAME="39"></A> and <EM>single-task</EM> or
<EM>multi-tasking</EM>. A multi-user system must clearly be
multi-tasking. The table below shows some examples.<A NAME="42"></A><A NAME="43"></A>

<P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">OS</TD>
<TD ALIGN="CENTER">Users</TD>
<TD ALIGN="CENTER">Tasks</TD>
<TD ALIGN="CENTER">Processors</TD>
</TR>
<TR><TD ALIGN="LEFT">MS/PC DOS</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">Windows 3x</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">QM</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">Macintosh System 7.*</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">QM</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">Windows 9x</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">M*</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">AmigaDOS</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">hline
MTS</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">UNIX</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER"><IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"></TD>
</TR>
<TR><TD ALIGN="LEFT">VMS</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">1</TD>
</TR>
<TR><TD ALIGN="LEFT">NT</TD>
<TD ALIGN="CENTER">S/M</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER"><IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"></TD>
</TR>
<TR><TD ALIGN="LEFT">Windows 2000</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER"><IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"></TD>
</TR>
<TR><TD ALIGN="LEFT">BeOS (Hamlet?)</TD>
<TD ALIGN="CENTER">S</TD>
<TD ALIGN="CENTER">M</TD>
<TD ALIGN="CENTER"><IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"></TD>
</TR>
</TABLE>
</DIV>
The first of these (MS/PC DOS/Windows 3x)<A NAME="49"></A><A NAME="50"></A>
are single user, single-task systems which build on a ROM based
library of basic functions called the BIOS<A NAME="51"></A>.  These are
system calls which write to the screen or to disk etc. Although all
the operating systems can service <EM>interrupts</EM><A NAME="53"></A>,
and therefore simulate the appearance of multitasking in some
situations, the older PC environments cannot be thought of as a
multi-tasking systems in any sense. Only a single user application
could be open at any time.  Windows 95 replaced the old coroutine
approach of quasi-multitasking with a true context switching approach,
but only a single user system, without proper memory
protection. Windows NT added a proper kernel with memory protection,
based on the VMS system, originally written for the DEC/Vax.  Later
versions of Windows NT and Windows 2000 (a security and kernel
enhanced version of NT) allow multiple logins also through a terminal
server. Windows 2000 thus has comparable functionality to Unix in this
respect.

<P>
The Macintosh<A NAME="54"></A><A NAME="55"></A> system 7 can be
classified as single-user quasi-multitasking<A NAME="tex2html1"
  HREF="footnode.html#foot56"><SUP>1.1</SUP></A>.  That means that it is possible to use several user
applications simultaneously. A window manager can simulate the
appearance of several programs running simultaneously, but this relies
on each program obeying specific rules in order to achieve the
illusion. The MacIntosh not a true multitasking system in the sense
that, if one program crashes, the whole system crashes. Windows <IMG
 WIDTH="23" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$9x$">
is purported to be preemptive multitasking but most program crashes
also crash the entire system. This might be due to the lack of proper
memory protection. The claim is somewhat confusing.

<P>
AmigaDOS<A NAME="57"></A> is an operating system for the Commodore
Amiga computer. It is based on the UNIX model and is a fully
multi-tasking, single-user system.  Several programs may be actively
running at any time. The operating system includes a window
environment which means that each independent program has a `screen'
of its own and does not therefore have to compete for the screen with
other programs. This has been a major limitation on multi-tasking
operating systems in the past.

<P>
MTS (Michigan timesharing system)<A NAME="58"></A> was the first
time-sharing multi-user system<A NAME="tex2html2"
  HREF="footnode.html#foot59"><SUP>1.2</SUP></A>.  It
supports only simple single-screen terminal based input/output and has
no hierarchical file system.

<P>
Unix is arguably the most important operating system today, and one
which we shall frequently refer to below. It comes in many forms,
developed by different manufacturers. Originally designed at AT&amp;T,
<A NAME="60"></A>
UNIX split into two camps early on: BSD (Berkeley software
distribution)<A NAME="61"></A> and system 5 (AT&amp;T license).
<A NAME="62"></A> The BSD version was
developed as a research project at the university of Berkeley,
California. Many of the networking and user-friendly features
originate from these modifications. With time these two versions have
been merged back together and most systems are now a mixture of both
worlds. Historically BSD Unix has been most prevalent in universities,
while system 5 has been dominant in business environments. The trend
during the last three years by Sun Microsystems and Hewlett-Packard
amongst others has been to move towards system 5, keeping only the
most important features of the BSD system. A standardization committee
for Unix called POSIX, formed by the major vendors, attempts to bring
compatibility to the Unix world.  Here are some common versions of
UNIX.<A NAME="63"></A><A NAME="64"></A>

<P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">Unix</TD>
<TD ALIGN="CENTER">Manufacturer</TD>
<TD ALIGN="CENTER">Mainly BSD / Sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">BSD</TD>
<TD ALIGN="CENTER">Berkeley</TD>
<TD ALIGN="CENTER">BSD</TD>
</TR>
<TR><TD ALIGN="LEFT">SunOS (solaris 1)</TD>
<TD ALIGN="CENTER">Sun Microsystems</TD>
<TD ALIGN="CENTER">BSD/sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">Solaris 2</TD>
<TD ALIGN="CENTER">Sun Microsystems</TD>
<TD ALIGN="CENTER">Sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">Ultrix</TD>
<TD ALIGN="CENTER">DEC/Compaq</TD>
<TD ALIGN="CENTER">BSD</TD>
</TR>
<TR><TD ALIGN="LEFT">OSF 1/Digital Unix</TD>
<TD ALIGN="CENTER">DEC/Compaq</TD>
<TD ALIGN="CENTER">BSD/sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">HPUX</TD>
<TD ALIGN="CENTER">Hewlett-Packard</TD>
<TD ALIGN="CENTER">Sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">AIX</TD>
<TD ALIGN="CENTER">IBM</TD>
<TD ALIGN="CENTER">Sys 5 / BSD</TD>
</TR>
<TR><TD ALIGN="LEFT">IRIX</TD>
<TD ALIGN="CENTER">Silicon Graphics</TD>
<TD ALIGN="CENTER">Sys 5</TD>
</TR>
<TR><TD ALIGN="LEFT">GNU/Linux</TD>
<TD ALIGN="CENTER">Public Domain</TD>
<TD ALIGN="CENTER">Posix (Sys V/BSD)</TD>
</TR>
<TR><TD ALIGN="LEFT">SCO unix</TD>
<TD ALIGN="CENTER">Novell</TD>
<TD ALIGN="CENTER">Sys 5</TD>
</TR>
</TABLE>
</DIV>
<A NAME="70"></A> 
Note that the original BSD source code is now in the public domain.
Unix is generally regarded as the most portable and powerful operating
system available today by impartial judges, but NT is improving
quickly. Unix runs on everything from laptop computers to CRAY
mainframes. It is particularly good at managing large database
applications and can run on systems with hundreds of processors.
Most Unix types support symmetric multithreaded processing and
all support simultaneous logins by multiple users.

<P>
NT is a `new' operating system from Microsoft based on the old VAX/VMS
kernel from the Digital Equipment Corporation (VMS's inventor moved to
Microsoft) and the Windows32 API. Initially it reinvented many
existing systems, but it is gradually being forced to adopt many open
standards from the Unix world. It is fully multitasking, and can
support multiple users (but only one at a time-- multiple logins by
different users is not possible). It has virtual memory and
multithreaded support for several processors. NT has a built in
object model and security framework which is amongst the most modern
in use.

<P>
The Be operating system, originally developed for a new multimedia
computer called the BeBox, is also new and is a fully multitasking
OS. It is optimized for multimedia and is now saleable software
developed by Be.Com after the new computer concept failed due to lack
of financial backing.  BeOS has proper memory protection but allows
direct access to video memory (required for fast video games). It also
has virtual memory, is pre-emptive multitasking and is based on a
microkernel design.  Is shares little with Unix except for a Bash
shell, a POSIX programming interface and about 150 Unix commands
(including Perl).
<A NAME="71"></A>
<A NAME="72"></A>

<P>

<H1><A NAME="SECTION00210000000000000000">
1.1 Key concepts</A>
</H1>

<P>
Before discussing more of the details, let's review some key ideas
which lie behind the whole OS idea. Although these ideas may seem
simple, you will do well to keep them in mind later.  Simple ideas
often get lost amongst distracting details, but it is important to
remember that the ideas are simple.

<P>

<H2><A NAME="SECTION00211000000000000000">
1.1.1 Hierarchies and black boxes</A>
</H2>

<P>
A hierarchy is a way of organizing information using <EM>levels of
detail</EM>. The phrase <EM>high-level</EM><A NAME="77"></A> implies few details, whereas <EM>low-level</EM><A NAME="79"></A> implies a lot of detail, down in the guts of things. A
hierarchy usually has the form of a tree, which branches from the
highest level to the lowest, since each <EM>high-level</EM> object is
composed of several <EM>lower-level</EM> objects. The key to making large
computer programs and to solving difficult problems is to create a
hierarchical structure, in which large high-level problems are
gradually broken up into manageable low-level problems.  Each level
works by using a series of `black boxes'<A NAME="82"></A> (e.g. subroutines) whose
inner details are not directly visible. This allows us to hide details
and remain sane as the complexity builds up.

<P>
This is the single most important concept in computing! It is used
repeatedly to organize complex problems.

<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="85"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 1.1:</STRONG>
The hierarchy is the most important concept in computing.</CAPTION>
<TR><TD><IMG
 WIDTH="563" HEIGHT="251" BORDER="0"
 SRC="img3.png"
 ALT="\begin{figure}\psfig{file=figs/hierachy.eps,width=12cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00212000000000000000">
1.1.2 Resources and sharing</A>
</H2>

<P>
A computer is not just a box which adds numbers together. It has <EM>resources</EM><A NAME="89"></A> like the keyboard and the screen, the disk drives and the
memory.  In a multi-tasking system there may be several programs which
need to receive input or write output simultaneously and thus the
operating system may have to share these resources between several
running programs. If the system has two keyboards (or terminals)
connected to it, then the OS can allocate both to different
programs. If only a single keyboard is connected then competing
programs must wait for the resources to become free.
<A NAME="90"></A>

<P>
Most multi-tasking systems have only a single <EM>central processor
unit</EM> and yet this is the most precious resource a computer has. An
multi-tasking operating system must therefore share <EM>cpu-time</EM>
between programs. That is, it must work for a time on one program,
then work a while on the next program, and so on. If the first program
was left unfinished, it must then return to work more on that, in a
systematic way.  The way an OS decides to share its time between
different tasks is called <EM>scheduling</EM>.
<A NAME="94"></A>

<P>

<H2><A NAME="SECTION00213000000000000000">
1.1.3 Communication, protocols, data types</A>
</H2>

<P>
<A NAME="96"></A>
<A NAME="97"></A>
<A NAME="98"></A>
The exchange of information is an essential part of computing. Suppose
computer A sends a message to computer B reporting on the names
of all the users and how long they have been working. To do
this it sends a stream of bits across a network. When computer B receives
a stream of bits, it doesn't automatically know what they mean. 
It must decide if the bits represent numbers or characters, integers
or floating point numbers, or a mixture of all of them. These different
<EM>types</EM> of data are all stored as binary information - the only
difference between them is the way one chooses to interpret them.

<P>
The resolution to this problem is to define a <EM>protocol</EM>. This is
a convention or agreement between the operating systems of two
machines on what messages may contain.  The agreement may say, for
instance, that the first thirty-two bits are four integers which give
the address of the machine which sent the message. The next thirty-two
bits are a special number telling the OS which protocol to use in
order to interpret the data. The OS can then look up this protocol and
discover that the rest of the data are arranged according to a pattern
of
<PRE>
&lt;name&gt;&lt;time&gt;&lt;name&gt;&lt;time&gt;...
</PRE>
where the name is a string of bytes, terminated by a zero, and the time
is a four byte digit containing the time in hours. Computer B now
knows enough to be able to extract the information from the stream of
bits.

<P>
It is important to understand that all computers have to agree on the
way in which the data are sent <EM>in advance</EM>. If the wrong
protocol is diagnosed, then a string of characters could easily
be converted into a floating point number - but the result would
have been nonsense. Similarly, if computer A had sent the information
incorrectly, computer B might not be able to read the data and a
<EM>protocol error</EM> would arise.

<P>
<DIV ALIGN="CENTER">
<EM>More generally, a protocol is an agreed sequence</EM>
<BR><EM>of behaviour which must be followed.</EM>

</DIV>

<P>
<A NAME="109"></A>
For example, when passing parameters to functions in a computer
program, there are rules about how the parameter should be declared
and in which order they are sent. This is a simple example of a
protocol.  Protocols are an important part of communication and data
typing and they will appear in many forms during our discussion of
operating systems.

<P>

<H2><A NAME="SECTION00214000000000000000">
1.1.4 System overhead</A>
</H2>

<P>
<A NAME="111"></A>
<A NAME="112"></A>
An operating system is itself a computer program which must be
executed.  It therefore requires its own share of a computer's
resources.  This is especially true on multitasking systems, such as
UNIX, where the OS is running all the time along side users'
programs. Since user programs have to wait for the OS to perform
certain services, such as allocating resources, they are slowed down
by the OS<A NAME="tex2html37"
  HREF="footnode.html#foot113"><SUP>1.3</SUP></A>. The time spent by the OS servicing user requests is called
the <EM>system overhead</EM>. On a multi-user system one would like this
overhead to be kept to a minimum, since programs which make many
requests of the OS slow not only themselves down, but all other
programs which are queuing up for resources.

<P>
In the UNIX C-shell (csh) environment, it is possible to find out the
exact fraction of time spent by the OS working on a program's behalf
by using the <code>time</code> function.<A NAME="115"></A>

<P>

<H2><A NAME="SECTION00215000000000000000">
1.1.5 Caching</A>
</H2> Caching is a technique used to speed up
communication with slow devices.  Usually the CPU can read data much
faster from memory than it can from a disk or network connection, so
it would like to keep an up-to-date copy of <EM>frequently used
information</EM> in memory. The memory area used to do this is called a
<EM>cache</EM>.  You can think of the whole of the primary memory as
being a cache for the secondary memory (disk).<A NAME="119"></A>

<P>
Sometimes caching is used more generally to mean `keeping a local
copy of data for convenience'. 

<P>

<H1><A NAME="SECTION00220000000000000000">
1.2 Hardware</A>
</H1>

<P>
Here we list the main hardware concepts.

<P>

<H2><A NAME="SECTION00221000000000000000"></A>
<A NAME="122"></A>
<BR>
1.2.1 The CPU
</H2>
The CPU, or <EM>central processor unit</EM> is the heart and soul of
every computer. This is the part which does the work of executing
machine instructions. Traditionally, it is just one microprocessor
with lots of pins to connect is to memory and devices - usually
identifiable by being the largest chip.  On modern machines, there may
be several CPUs which can work in parallel. Also VLSI or <EM>very
large scale integration</EM> technology has made it possible to put very
many separate processors and memory into a single package, so the
physical distinction between the CPU and its support chips is getting
blurred. Nevertheless, the CPU is still logically separate from the
memory and devices.<A NAME="125"></A>

<P>
The CPU is driven by a `clock' or pulse generator. Each instruction
completes in a certain number of `clock cycles'.<A NAME="126"></A>
Traditionally CPUs are based on CISC (Complex Instruction Set
Computing) architecture, where a single instruction takes one or more
clock cycles to complete.<A NAME="127"></A> A new trend is to build RISC
(Reduced Instruction Set Computing) processors which aim to be more
efficient for a subset of instructions by using redundancy. These have
simpler instructions but can execute much more quickly, sometimes with
several instructions per clock cycle.

<P>

<H2><A NAME="SECTION00222000000000000000">
1.2.2 Memory</A>
</H2>

<P>
The <EM>primary memory</EM><A NAME="130"></A> is the most important resource a computer
has.  Since CPUs are only made with instructions for reading and
writing to memory, no programs would be able to run without it. There
are two types of memory: RAM - random access memory,<A NAME="131"></A> or read/write
memory, which loses its contents when the machine is switched off, and
ROM - read only memory, which never loses its contents unless
destroyed.  ROM<A NAME="132"></A> is normally used for storing those most fundamental
parts of the operating system which are required the instant a
computer is switched on, before it knows about disks etc.

<P>

<H2><A NAME="SECTION00223000000000000000"></A><A NAME="134"></A>
<BR>
1.2.3 Devices
</H2> The concepts of a device really
has two parts. There is the hardware unit which is connected to the
machine, and there is the <EM>logical device</EM><A NAME="136"></A>
which is a name given by the OS to a <EM>legal entry point</EM> for
talking to a hardware-device. When a user writes to a logical device,
the OS invokes a <EM>device driver</EM><A NAME="139"></A> which
performs the physical operations of controlling the hardware. For
example, when writing to a disk, the OS must control the movement of
the read-write heads. When writing to a printer, the OS places the
information in a queue and services the request when the printer
becomes free.

<P>
Some common logical devices are: the system disks, the keyboard, the
screen, the printer and the audio device.

<P>
Disks and tapes are often called <EM>secondary memory</EM> or secondary storage.
<A NAME="141"></A>

<P>

<H2><A NAME="SECTION00224000000000000000">
1.2.4 Interrupts, traps, exceptions</A>
</H2>

<P>
Interrupts are hardware signals which are sent to the CPU by the
devices it is connected to. These signals literally interrupt the CPU
from what it is doing and demand that it spend a few clock cycles
servicing a request.  For example, interrupts may come from the
keyboard because a user pressed a key. Then the CPU must stop what it
is doing and read the keyboard, place the key value into a buffer for
later reading, and return to what it was doing. Other `events'
generate interrupts: the system clock sends interrupts at periodic
intervals, disk devices generate interrupts when they have finished an
I/O task and interrupts can be used to allow computers to monitor
sensors and detectors. User programs can also generate `software
interrupts' in order to handle special situations like a `division by
zero' error. These are often called <EM>traps</EM> or <EM>exceptions</EM> on
some systems.<A NAME="145"></A><A NAME="146"></A><A NAME="147"></A>

<P>
Interrupts are graded in <EM>levels</EM>. <EM>Low level</EM> interrupts have
a low priority, whereas <EM>high level</EM> interrupts have a high
priority.  A high level interrupt can interrupt a low level interrupt,
so that the CPU must be able to recover from several `layers' of
interruption and end up doing what it was originally doing. This is
accomplished by means of a <EM>stack</EM> or <EM>heap</EM><A NAME="tex2html53"
  HREF="footnode.html#foot153"><SUP>1.4</SUP></A>. Moreover, programs can
often choose whether or not they wish to be interrupted by setting an
<EM>interrupt mask</EM> which masks out the interrupts it does not want
to hear about. Masking interrupts can be dangerous, since data can be
lost. All systems therefore have <EM>non-maskable interrupts</EM> for the
most crucial operations.

<P>

<H1><A NAME="SECTION00230000000000000000">
1.3 Software</A>
</H1>

<P>

<H2><A NAME="SECTION00231000000000000000">
1.3.1 Resource management</A>
</H2>

<P>
In order to keep track of how the system resources are being used, an
OS must keep tables or lists telling it what is free an what is not.
For example, data cannot be stored neatly on a disk. As files become
deleted, holes appear and the data become scattered randomly over the
disk surface.

<P>

<H2><A NAME="SECTION00232000000000000000">
1.3.2 Spooling</A>
</H2>

<P>
<A NAME="159"></A>
Spooling is a way of processing data <EM>serially</EM>. Print jobs are
spooled to the printer, because they must be printed in the right
order (it would not help the user if the lines of his/her file were
liberally mixed together with parts of someone elses file). During
a spooling operation, only one job is performed at a time and other
jobs wait in a queue to be processed. Spooling is a form of
<EM>batch processing</EM>. 

<P>
Spooling comes from the need to copy data onto a spool of tape for storage.
It has since been dubbed <B>S</B>imultaneous <B>P</B>eripheral 
<B>O</B>peration <B>O</B>n-<B>L</B>ine, which is a pretty lousy attempt
to make something more meaningful out of the word `spool'!

<P>

<H2><A NAME="SECTION00233000000000000000">
1.3.3 System calls</A>
</H2>

<P>
<A NAME="168"></A>
An important task of an operating system is to provide
black-box functions for the most frequently needed operations, so that
users do not have to waste their time programming very low level code
which is irrelevant to their purpose.  These ready-made functions 
comprise <EM>frequently used code</EM> and are called <EM>system calls</EM>.

<P>
For example, controlling devices requires very careful and complex
programming. Users should not have to write code to position the head
of the disk drive at the right place just to save a file to the disk.
This is a very basic operation which everyone requires and thus it 
becomes the responsibility of the OS. Another example is <EM>mathematical
functions</EM> or <EM>graphics</EM> primitives.

<P>
System calls can be thought of as a very simple <EM>protocol</EM> -
an agreed way of asking the OS to perform a service. Some typical
OS calls are: <EM>read</EM>, <EM>write</EM> (to screen, disk, printer etc),
<EM>stat</EM> (get the status of a file: its size and type) and
<EM>malloc</EM> (request for memory allocation).

<P>
On older microcomputers, where high level languages are
uncommon, system calls are often available only through
assembler or machine code. On modern systems and integrated
systems like UNIX, they are available as functions in a high
level language like C.

<P>

<H2><A NAME="SECTION00234000000000000000">
1.3.4 Basic command language</A>
</H2>

<P>
Commands like
<PRE>
dir                 ; list files (DOS)
ls                  ; list files (UNIX)
cd                  ; change directory
copy file prn       ; copy file to printer
myprog              ; execute program `myprog'
</PRE>
constitute a <EM>basic command language</EM>. Every computer must
have such a language (except perhaps the Macintosh - yawn!). 
In microcomputer operating systems the
command language is often built into the system code, whereas on
larger systems (UNIX) the commands are just executable programs
like the last example above.

<P>
The command language deals typically with: <EM>file management</EM>, <EM>process
management</EM> and <EM>text editing</EM>.

<P>

<H2><A NAME="SECTION00235000000000000000">
1.3.5 Filesystem</A>
</H2>

<P>
In creating a system to store files we must answer some basic
questions.<A NAME="186"></A>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Should the filesystem distinguish between <EM>types</EM> of
files <EM>e.g.</EM> executable files, text files, scripts. If so how? One way
is to use <EM>file extensions</EM>, or a naming convention to identify files, like
<EM>myprog.exe</EM>, <EM>SCRIPT.BAT</EM>, <EM>file.txt</EM>. The problem with this
is that the names can be abused by users. If one tries to execute a file
which is not meant to be executed, the result would be nonsense and might even be dangerous to the point of crashing the system. One way around this
problem is to introduce a <EM>protocol</EM> or <EM>standard format</EM> for
executable files, so that when the OS opens a file for execution it first
checks to see whether the file obeys the protocol. This method is
used for binary files in UNIX, for instance.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Protection.</EM> If several users will be storing files
together on the same disk, should each user's files be exclusive to
him or her?
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Is a mechanism required for sharing files between several
users?
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A hierarchical filesystem is a good starting point for
organizing files, but it can be too restrictive. Sometimes it is useful
to have a file appear in several places at one time. This can be
accomplished with <EM>links</EM>. A link is not a copy of a file, but a
pointer to where a file really is. By making links to other places in
a hierarchical filesystem, its flexibility is increased considerably.
</DD>
</DL>

<P>

<H2><A NAME="SECTION00236000000000000000">
1.3.6 Multiple windows and screens</A>
</H2>

<P>
<A NAME="201"></A>
<A NAME="202"></A>
Multitasking cannot be fully exploited if each user has only one output
terminal (screen). Each interactive program needs its own screen and
keyboard<A NAME="tex2html60"
  HREF="footnode.html#foot219"><SUP>1.5</SUP></A>. There are three solutions to
this problem:

<OL>
<LI>Several physical screens can be attached to the computer. 
This is expensive and probably wasteful.
</LI>
<LI>Toggling between `logical screens'. By pressing a key on the keyboard
the user can switch between two different images, which are separately
maintained in memory.
</LI>
<LI>Window system.
</LI>
</OL>
<A NAME="209"></A>
The technology for the last of these solutions has only been available
for a few years. While it is clearly the best of the three
(and can be combined with <IMG
 WIDTH="23" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.png"
 ALT="$[1]$">), it requires a considerable amount of
memory and CPU power to implement. The problem of overlapping windows
requires there to be a manager which controls the sharing of space
on the screen. All of the graphics must be drawn and redrawn continuously.
The operating system must provide primitives for doing this.

<P>
We shall not consider windowing further in this text, but it is worth
bearing in mind that the principles are very similar to those of
operating systems. <EM>Sharing</EM> and <EM>management</EM> are the key concepts.

<P>

<H1><A NAME="SECTION00240000000000000000">
Note</A>
</H1>

<P>
Before proceeding, you should note that the design of operating
systems is an active area of research. There are no universal
solutions to the issues that we shall discuss, rather OS design must
be thought of as a study of compromises. Hopefully you will get a
feel for this during the course of the tutorial.

<P>

<H1><A NAME="SECTION00250000000000000000">
Exercises</A>
</H1>

<P>

<OL>
<LI>What are the key ingredients of an operating system?
</LI>
<LI>What is the usefulness of system calls?
</LI>
<LI>What is the difference between primary and secondary storage.
</LI>
<LI>What is a logical device?
</LI>
<LI>Should different users be able to change one another's data?
If so, under what circumstances?
</LI>
<LI>How do hardware devices send signals to the CPU?

<P>
</LI>
</OL>

<H1><A NAME="SECTION00300000000000000000">
2. Single-task OS</A>
</H1>

<P>
Before tackling the complexities of multi-tasking, it is useful to
think about the operation of a single-task OS without all the clutter
that multi-tasking entails. In a multi-task OS the features we shall
discuss below have to be reproduced <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$">-times and then augmented by
extra control structures.

<P>

<H1><A NAME="SECTION00310000000000000000">
2.1 Memory map and registers</A>
</H1>

<P>
The key elements of a single-task computer are shown in figure
<A HREF="os.html#fig:2">2.1</A>.  Roughly speaking, at the hardware level a computer
consists of a CPU, memory and a number of peripheral devices. The CPU
contains <EM>registers</EM> or `internal variables' which control its
operation. The CPU can store information only in the memory it can
address and in the registers of other microprocessors it is connected
to. The CPU reads <EM>machine code</EM> instructions, one at a time, from
the memory and executes them forever without stopping.

<P>
Here is a brief summary of the types of register a CPU has. Some
microprocessors have several of each type.

<P>
<BR>
<BR>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">Register</TD>
<TD ALIGN="LEFT">Purpose</TD>
</TR>
<TR><TD ALIGN="LEFT">Accumulator</TD>
<TD ALIGN="LEFT">Holds the data currently being worked on.</TD>
</TR>
<TR><TD ALIGN="LEFT">Program counter</TD>
<TD ALIGN="LEFT">Holds the address of the next instruction</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">to be executed</TD>
</TR>
<TR><TD ALIGN="LEFT">Index (addressing) registers</TD>
<TD ALIGN="LEFT">Used to specify the address of
data to be loaded into or</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">saved from the accumulator, or operated on in some way.</TD>
</TR>
<TR><TD ALIGN="LEFT">Stack pointer</TD>
<TD ALIGN="LEFT">Points to the top of the CPUs</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">own hardware controlled stack.</TD>
</TR>
<TR><TD ALIGN="LEFT">Status register</TD>
<TD ALIGN="LEFT">Contains status information after each instruction</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">which can be tested for to detect errors etc.</TD>
</TR>
</TABLE>
<BR>
<BR>
<A NAME="548"></A>
<A NAME="549"></A>
<A NAME="550"></A>
<A NAME="551"></A>
<A NAME="552"></A>

<P>
The memory, as seen by the CPU, is a large string of bytes starting
with address <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$0$"> and increasing up to the maximum address. Physically
it is made up, like a jigsaw puzzle, of many memory chips and control
chips. mapped into the diagram shown. Normally, because of the
hardware design of the CPU, not all of the memory is available to the
user of the machine. Some of it is required for the operation of the
CPU.<A NAME="553"></A>

<P>
The roughly distinguished areas in figure  <A HREF="os.html#fig:2">2.1</A> are

<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Zero page:</EM> The first
t `page' of the memory is often reserved for a special purpose. It is
often faster to write to the zero page because you don't have to code
the leading zero for the address - special instructions for the zero
page can leave the `zero' implicit.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Stack:</EM> Every CPU needs a stack for executing subroutines. The stack is explained in more detail below.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>User programs:</EM> Space the user programs can `grow into'.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Screen memory:</EM> What you see on the screen of a computer
is the image of an area of memory, converted into colours and
positions by a hardware video-controller. The screen memory is the
area of memory needed to define the colour of every `point' or `unit'
on the screen.  Depending on what kind of visual system a computer
uses, this might be one byte per character and it might be four bytes
per pixel!
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Memory mapped I/O:</EM> Hardware devices like disks and
video controllers contain smaller microprocessors of their own. 
The CPU gives them instructions by placing numbers into their registers.
To make this process simpler, these device registers (only a few bytes
per device, perhaps) are `wired' into the main memory map, so that writing
to the device is the same as writing to the rest of the memory.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Operating system:</EM> The operating system itself
is a large program which often
takes up a large part of the available memory.
</DD>
</DL>
Note that this figure is very simplified. It does not show, for instance,
special memory which might be located inside the
devices or CPU. Such memory is often used for caching. Also it does
not show how the various components are connected together by means
of a high speed <EM>data bus</EM>.
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>
<BR>

<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="fig:2"></A><A NAME="567"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 2.1:</STRONG>
<EM>A simple schematic memory map of a microcomputer. The order of the
different segments of memory can vary depending on the system.</EM></CAPTION>
<TR><TD><IMG
 WIDTH="563" HEIGHT="578" BORDER="0"
 SRC="img8.png"
 ALT="\begin{figure}\psfig{file=figs/fig2.1.eps,width=12cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H1><A NAME="SECTION00320000000000000000">
2.2 Stack</A>
</H1>

<P>
A stack is a so-called <EM>last-in first-out</EM> (LIFO) data<A NAME="572"></A>
<A NAME="573"></A>
structure. That is to say - the last thing to be placed on top of a
stack, when making it, is the first item which gets removed when
un-making it.  Stacks are used by the CPU to store the current
position within a program before jumping to subroutines, so that they
remember where to return to after the subroutine is finished.  Because
of the nature of the stack, the CPU can simply deposit the address of
the <EM>next</EM> instruction to be executed (after the subroutine is
finished) on top of the stack. When the subroutine is finished, the CPU
pulls the first address it finds off the top of the stack and jumps to
that location.

<P>
Notice that the stack mechanism will continue to work even if the
subroutine itself calls another subroutine, since the second subroutine
causes another <EM>stack frame</EM> to be saved on the top of the stack.
When that is finished, it returns to the first subroutine and then
to the original program in the correct order.<A NAME="576"></A>

<P>
On many older microcomputers and in many operating systems the stack
is allocated with a fixed size in advance. If too many levels of
nested subroutines are called, the stack can <EM>overflow</EM>. Consider the
following example code for a stack. <A NAME="578"></A>

<P>
<PRE>
//
// A simple stack handler. 
//
// Use the commands "push" and "pop" to push onto the stack and to pop 
// "out" of the stack. The allocated stacksize is very small so that 
// an overflow can occur if you push too far!! e.g. input
//
//  push 23
//  push 4
//  pop
//  push 678
//  quit
//
//  In a real stack handler the numbers would be the address of the next
//  instruction to return to after completing a subroutine.
//
//  The program is compiled with
//
//        g++ stack.C
//
//  MB 1994
//
//*********************************************************************

#include &lt;iostream.h&gt;
#include &lt;strstream.h&gt;
#include &lt;string.h&gt;

//**********************************************************************
// Include file
//**********************************************************************

const int forever = 1;
const int stacksize = 10;
const int bufsize = 20;

//**********************************************************************

class Stack
   {
   public:

   int stack[stacksize];
   
   Stack();   
   void ShowStack();
   void Push(int);
   int  Pop();

   private:

   int stackpointer;
   };


//**********************************************************************
// Level 0
//**********************************************************************

main ()

{ char input[bufsize];
  char command[5];
  int number, newnumber;
  Stack s;

cout &lt;&lt; "Stack demo\n\n";

s.ShowStack();

while (forever)
   {
   cout &lt;&lt; "Enter command: ";

   // Extract command
   
   cin.getline(input,bufsize);
   istrstream(input,sizeof(input)) &gt;&gt; command &gt;&gt; number;

   // Interpret command
   
   if (strcmp(command,"push") == 0)
      {
      s.Push(number);
      }
   else if (strcmp(command,"pop")==0)
      {
      newnumber = s.Pop();
      }
   else if (strcmp(command,"quit")==0)
      {
      break;
      }
   else
      {
      number = 0;
      cout &lt;&lt; "Bad command\n\n";
      }
   
   s.ShowStack();
   }

s.ShowStack();
}

//**********************************************************************
// Class Stack
//**********************************************************************

Stack::Stack()

{ int i;

stackpointer = 0;

for (i = 0; i &lt; stacksize; i++)
   {
   stack[i] = 0;
   }
}

//**********************************************************************

void Stack::Push (int n)

{
cout &lt;&lt; "Pushing " &lt;&lt; n &lt;&lt; " on the stack\n";

if (stackpointer &gt;= stacksize)
   {
   cerr &lt;&lt; "Stack overflow!\n";
   return;
   }

stack[stackpointer] = n;
stackpointer++;
}

//**********************************************************************

int Stack::Pop ()

{
if (stackpointer == 0)
   {
   cerr &lt;&lt; "Stack underflow!\n";
   return 0;
   }

stackpointer--;
cout &lt;&lt; "Popped " &lt;&lt; stack[stackpointer] &lt;&lt; " from stack\n";

return (stack[stackpointer]);
}

//**********************************************************************

void Stack::ShowStack ()

{ int i;

for (i = stacksize-1; i &gt;= 0; i--)
   {
   cout &lt;&lt; "stack[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; stack[i];

   if (i == stackpointer)
      {
      cout &lt;&lt; " &lt;&lt;-- Pointer\n";
      }
   else
      {
      cout &lt;&lt; endl;
      }
   }
}
</PRE>
<P>
<FONT SIZE="-2">In this example, only numbers are stored. At the hardware level, this
kind of stack is used by the CPU to store addresses and registers
during machine-code subroutine jumps. Operating systems also use <EM>software controlled stacks</EM> during the execution of users' programs.
High level languages subroutines can have local variables which are
also copied to the stack as one large <EM>stack frame</EM> during the
execution of subroutines.
</FONT>
<P>

<H1><A NAME="SECTION00330000000000000000">
2.3 Input/Output</A>
</H1>
<P>
<FONT SIZE="-2">Input arrives at the computer at unpredictable intervals. The system
must be able to detect its arrival and respond to it.
</FONT>
<P>

<H2><A NAME="SECTION00331000000000000000">
2.3.1 Interrupts</A>
</H2>
<P>
<FONT SIZE="-2">Interrupts are hardware triggered signals which cause the CPU to
stop what it is doing and jump to a special subroutine. Interrupts
normally arrive from hardware devices, such as when the user presses
a key on the keyboard, or the disk device has fetched some data from
the disk. They can also be generated in software by errors like
<EM>division by zero</EM> or <EM>illegal memory address</EM>. <A NAME="587"></A>
</FONT>
<P>
<FONT SIZE="-2">When the CPU receives an interrupt, it saves the contents of its
registers on the hardware stack and jumps to a special routine
which will determine the cause of the interrupt and respond to
it appropriately. Interrupts occur at different levels. Low level
interrupts can be interrupted by high level interrupts. Interrupt
handling routines have to work quickly, or the computer will be
drowned in the business of servicing interrupts. For certain
critical operations, low level interrupts can be ignored by
setting a <EM>mask</EM> (See also the generalization of this for
multiuser systems in chapter 4). 
</FONT>
<P>
<FONT SIZE="-2">There is no logical difference between what happens during the
execution of an interrupt routine and a subroutine. The difference
is that interrupt routines are triggered by <EM>events</EM>, whereas
software subroutines follow a prearranged plan.
</FONT>
<P>
<FONT SIZE="-2">An important area is the <EM>interrupt vector</EM>. This is a region
of memory reserved by the hardware for servicing of interrupts. 
Each interrupt has a number from zero<A NAME="591"></A>
to the maximum number of interrupts supported on the CPU; 
for each interrupt, the interrupt
vector must be programmed with the address of a routine which is
to be executed when the interrupt occurs. i.e. when an interrupt
occurs, the system examines the address in the interrupt vector
for that interrupt and jumps to that location. The routine exits
when it meets an RTI (return from interrupt) instruction.
</FONT>
<P>

<H2><A NAME="SECTION00332000000000000000">
2.3.2 Buffers</A>
</H2>
<P>
<FONT SIZE="-2">The CPU and the devices attached to it do not work at the same speed.
<EM>Buffers</EM> are therefore needed to store incoming or outgoing
information temporarily, while it is waiting to be picked up by
the other party. A buffer is simply an area of memory which works
as a waiting area. It is a <EM>first-in first-out</EM> (FIFO) data
structure or <EM>queue</EM>.<A NAME="596"></A>
<A NAME="597"></A>
<A NAME="598"></A>
</FONT>
<P>

<H2><A NAME="SECTION00333000000000000000">
2.3.3 Synchronous and asynchronous I/O</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="600"></A>
<A NAME="601"></A>
To start an I/O operation, the CPU writes appropriate values into
the registers of the device controller. The device controller acts on
the values it finds in its registers. For example, if the operation
is to read from a disk, the device controller fetches data from the
disk and places it in its local buffer. It then signals the
CPU by generating an interrupt. 
</FONT>
<P>
<FONT SIZE="-2">While the CPU is waiting for the I/O to complete it may do one of two
things. It can do nothing or <EM>idle</EM> until the device returns with
the data (synchronous I/O), or it can continue doing something else
until the completion interrupt arrives (asynchronous I/O). The
second of these possibilities is clearly much more efficient.
</FONT>
<P>

<H2><A NAME="SECTION00334000000000000000">
2.3.4 DMA - Direct Memory Access</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="604"></A>
<A NAME="605"></A>
Very high speed devices could place heavy demands on the CPU for
I/O servicing if they relied on the CPU to copy data word by word.
The DMA controller is a device which copies <EM>blocks</EM> of data
at a time from one place to the other, without the intervention of
the CPU. To use it, its registers must be loaded with the information
about what it should copy and where it should copy to. Once this is done,
it generates an interrupt to signal the completion of the task. The
advantage of the DMA is that it transfers large amounts of data before
generating an interrupt. Without it, the CPU would have to copy the
data one register-full at a time, using up hundreds or even thousands
of interrupts and possibly bringing a halt to the machine!
</FONT>
<P>

<H1><A NAME="SECTION00340000000000000000">
Exercises</A>
</H1>
<OL>
<LI>What is the program counter?

<P>
</LI>
<LI>Explain why a stack is used to store local variables.

<P>
</LI>
<LI>Some microprocessors (68000/Intel 386 upward) 
support multitasking internally. A separate stack is 
then needed for each process. How can this be
achieved?

<P>
</LI>
<LI>Write a program to create a stack (LIFO) which can store any
number of local variables for each subroutine. 
Hint: use a linked list for the stack and for the variables.

<P>
</LI>
<LI>Write a program to implement a buffer (FIFO).

<P>
</LI>
<LI>When a computer is first switched on, it executes a program called
a <EM>bootstrap</EM> program. This comes from the expression `to lift oneself
by one's own bootstraps'. The computer must begin to execute instructions
and `get going'. Find out for yourself, or speculate on how this takes
place.

<P>
</LI>
<LI>What is a stack-frame?

<P>
</LI>
<LI>What is memory mapped I/O?

<P>
</LI>
</OL><FONT SIZE="-2">
</FONT>
<H1><A NAME="SECTION00400000000000000000">
3. Multi-tasking and multi-user OS</A>
</H1>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<P>
<FONT SIZE="-2"><A NAME="779"></A>
To make a multi-tasking OS we need loosely to reproduce all of the
features discussed in the last chapter for each task or process which
runs. It is not 
necessary for each task to have its own set of devices. The
basic hardware resources of the system are shared between the tasks.
The operating system must therefore have a `manager' which shares
resources at all times. This manager is called the `kernel' and
it constitutes the main difference between single and multitasking
operating systems.
</FONT>
<P>

<H1><A NAME="SECTION00410000000000000000">
3.1 Competition for resources</A>
</H1>
<P>

<H2><A NAME="SECTION00411000000000000000"></A>
<A NAME="782"></A>
<A NAME="783"></A>
<A NAME="784"></A>
<A NAME="785"></A>
<BR>
3.1.1 Users - authentication
</H2><FONT SIZE="-2">
If a system supports several users, then each user must have his or her
own place on the system disk, where files can be stored. Since each
user's files may be private, the file system should record the
<EM>owner</EM> of each file. For this to be possible, all users must
have a <EM>user identity</EM> or <EM>login name</EM> and must supply a
<EM>password</EM> which prevents others from impersonating them. Passwords
are stored in a cryptographic (coded) form. When a user logs in, the OS encrypts
the typed password and compares it to the stored version.
Stored passwords are never decrypted for comparison.
</FONT>
<P>

<H2><A NAME="SECTION00412000000000000000">
3.1.2 Privileges and security</A>
</H2>
<P>
<FONT SIZE="-2">On a multi-user system it is important that one user should not
be able to interfere with another user's activities, either purposefully
or accidentally. Certain commands and system calls are therefore not
available to normal users directly. The <EM>super-user</EM> is a
<EM>privileged user</EM> (normally the system operator) who has permission
to do anything, but normal users have restrictions placed on them
in the interest of system safety.<A NAME="793"></A><A NAME="794"></A>
<A NAME="795"></A>
</FONT>
<P>
<FONT SIZE="-2">For example: normal users should never be able to halt the system; nor
should they be able to control the devices connected to the computer, or
write directly into memory without making a formal request of the OS.
One of the tasks of the OS is to prevent collisions between users.
</FONT>
<P>

<H2><A NAME="SECTION00413000000000000000">
3.1.3 Tasks - two-mode operation</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="797"></A>
It is crucial for the security of the system that different tasks,
working side by side, should not be allowed to interfere with one
another (although this occasionally happens in microcomputer
operating systems, like the Macintosh, which allow several programs to
be resident in memory simultaneously). <EM>Protection</EM> mechanisms are
needed to deal with this problem. The way this is normally done is to
make the operating system all-powerful and allow no user to access the
system resources without going via the OS.
</FONT>
<P>
<FONT SIZE="-2">To prevent users from tricking the OS, multiuser systems are based on
hardware which supports <EM>two-mode</EM> operation: <EM>privileged
mode</EM> for executing OS instructions and <EM>user mode</EM> for working on
user programs. When running in <EM>user mode</EM> a task has no special
privileges and must ask the OS for resources through system
calls. When I/O or resource management is performed, the OS takes over
and switches to <EM>privileged</EM> mode. The OS switches between these
modes personally, so provided it starts off in control of the system,
it will alway remain in control.<A NAME="804"></A><A NAME="805"></A>
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>At boot-time, the system starts in privileged mode.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>During user execution, it is switched to user mode.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>When interrupts occur, the OS takes over and
it is switched back to privileged mode.
</DD>
</DL><FONT SIZE="-2">
Other names for privileged
mode are <EM>monitor mode</EM> or <EM>supervisor mode</EM>.<A NAME="813"></A>
</FONT>
<P>

<H2><A NAME="SECTION00414000000000000000">
3.1.4 I/O and Memory protection</A>
</H2>
<P>
<FONT SIZE="-2">To prevent users from gaining control of devices, by tricking the
OS, a mechanism is required to prevent them from writing to an
arbitrary address in the memory. For example, if the user could
modify the OS program, then it would clearly be possible to gain control
of the entire system in privileged mode. All a user would have to
do would be to change the addresses in the interrupt vector
to point to a routine of their own making. This routine would then
be executed when an interrupt was received in privileged mode.
</FONT>
<P>
<FONT SIZE="-2">The solution to this problem is to let the OS define a segment of
memory for each user process and to check, when running in user mode,
<EM>every</EM> address that the user program refers to. If the user
attempts to read or write outside this allowed segment, a <EM>segmentation fault</EM> is generated and control returns to the OS. This
checking is normally hard-wired into the hardware of the computer so
that it cannot be switched off. <A NAME="817"></A>
<A NAME="818"></A>
No checking is required in privileged
mode.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
//******************************************************************
//
// Example of a segmentation fault in user mode
//
//******************************************************************

main()           // When we start, we are by definition in user mode.

{ int *ptr;

ptr = 0;         // An address guaranteed to NOT be in our segment.

cout &lt;&lt; *ptr;
}
</PRE><FONT SIZE="-2"></FONT>
<P>

<H2><A NAME="SECTION00415000000000000000"></A>
<A NAME="822"></A>
<BR>
3.1.5 Time sharing
</H2><FONT SIZE="-2">
There is always the problem in a multi-tasking system that a user program
will go into an infinite loop, so that control never returns to the OS
and the whole system stops. We have to make sure that the OS always 
remains in control by some method. Here are two possibilities:
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>
The operating system fetches each instruction from the user program
and executes it personally, never giving it directly to the CPU. 
The OS software switches between different processes by fetching 
the instructions it decides to execute.
This
is a kind of <EM>software emulation</EM>. This method works, but it is
extremely inefficient because the OS and the user program are always
running together. The full speed of the CPU is not realized.
This method is often used to make simulators and
debuggers.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>
A more common method is to switch off the OS while the user program
is executing and switch off the user process while the OS is
executing. The switching is achieved by hardware rather than
software, as follows.
When handing control to a user program, the OS uses a hardware timer
to ensure that control will return after a certain time. The OS
loads a fixed time interval into the timer's control registers
and gives control to the user process. The timer then
counts down to zero and when it reaches zero it generates a
<EM>non-maskable interrupt</EM>, whereupon control returns to the
OS. 

<P>
</DD>
</DL>
<P>

<H1><A NAME="SECTION00420000000000000000">
3.2 Memory map</A>
</H1>
<P>
<FONT SIZE="-2">We can represent a multi-tasking system schematically as in figure
<A HREF="os.html#fig:4">3.1</A>. Clearly the
memory map of a computer does not look like this figure.  It looks
like the figures in the previous chapter, so the OS has to simulate
this behaviour using software. The point of this diagram is only that
it shows the elements required by each process executing on the
system.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="fig:4"></A><A NAME="831"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 3.1:</STRONG>
Schematic diagram of a multitasking system.</CAPTION>
<TR><TD><IMG
 WIDTH="454" HEIGHT="531" BORDER="0"
 SRC="img9.png"
 ALT="\begin{figure}\psfig{file=figs/fig3.1.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
Each program must have a memory area to work in and a <EM>stack</EM>
to keep track of subroutine calls and local variables. 
</FONT>
<P>
<FONT SIZE="-2">Each
program must have its own input/output sources. These cannot
be the actual resources of the system: instead, each program
has a <EM>virtual I/O</EM> stream. The operating system arranges
things so that the virtual I/O looks, to the user program, as
though it is just normal I/O. In reality, the OS controls all
the I/O itself and arranges the sharing of resources transparently.
The virtual output stream for a program might be a <EM>window</EM>
on the real screen, for instance. The virtual printer is really
a print-queue. The keyboard is only `connected' to one task
at a time, but the OS can share this too. For example, in a window
environment, this happens when a user clicks in a particular window.
</FONT>
<P>

<H1><A NAME="SECTION00430000000000000000">
3.3 Kernel and shells - layers of software</A>
</H1>
<P>
<FONT SIZE="-2">So far we have talked about the OS almost as though it were a
living thing. In a multitasking, multi-user OS like UNIX this is not a
bad approximation to the truth! In what follows we make use of
UNIX terminology and all of the examples we shall cover later
will refer to versions of the UNIX operating system.<A NAME="838"></A>
<A NAME="839"></A>
</FONT>
<P>
<FONT SIZE="-2">The part of the OS which handles all of the details of sharing
and device handling is called the <EM>kernel</EM> or <EM>core</EM>.
The kernel is not something which can be used directly, although
its services can be accessed through system calls. What is needed
is a <EM>user interface</EM> or <EM>command line interface</EM> (CLI) which
allows users to log onto the machine and manipulate files,
compile programs and execute them using simple commands.
Since this is a layer of software which<A NAME="844"></A>
wraps the kernel in more acceptable clothes, it
is called a <EM>shell</EM> around the kernel. 
</FONT>
<P>
<FONT SIZE="-2">It is only by making layers of software, in a <EM>hierachy</EM> that
very complex programs can be written and maintained. The idea of
layers and hierarchies returns again and again.
</FONT>
<P>

<H1><A NAME="SECTION00440000000000000000">
3.4 Services: daemons</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="848"></A>
<A NAME="849"></A>
The UNIX kernel is a very large program, but it does not perform
all of the services required in an OS. To keep the size of
the kernel to a minimum, it only deals with the sharing of 
resources. Other jobs for operating system (which we can call
services) are implemented by writing program which
run along side user's programs. Indeed, they are
just `user programs' - the only
difference is that are owned by the system.
These programs are called daemons. Here are some example from UNIX.
</FONT>
<UL>
<LI><B>mountd</B>: Deals with requests for `mounting' this machine's disks
on other machines - i.e. requests to access the disk on this machine
from another machine on the network.
</LI>
<LI><B>rlogind</B>: Handles requests to login from remote terminals.
</LI>
<LI><B>keyserv</B>: A server which stores public and private keys. Part of a 
network security system.
</LI>
<LI><B>syslogd</B>: Records information about important events in a log file.
</LI>
<LI><B>named</B>: Converts machine names into their network addresses and
vice versa.
</LI>
</UL>
<P>

<H1><A NAME="SECTION00450000000000000000"></A>
<A NAME="858"></A>
<A NAME="859"></A>
<BR>
3.5 Multiprocessors - parallelism
</H1><FONT SIZE="-2">
The idea of constructing computers with more than one CPU
has become more popular recently. On a system with several CPUs
it is not just a <EM>virtual</EM> fact that several tasks can be
performed simultaneously - it is a reality. This introduces a
number of complications in OS design. For example - how can we
stop two independent processors from altering some
memory location which they both share <EM>simultaneously</EM> (so that
neither of them can detect the collision)? This is
a problem in process <EM>synchronization</EM>. The solution to this
problem is much simpler in a single CPU system since no two things
ever happen <EM>truly</EM> simultaneously. <A NAME="864"></A>
</FONT>
<P>
<FONT SIZE="-2">We shall consider this in more detail in later chapters. For now it is
useful to keep in mind that multiprocessors are an important element
of modern OS design.
</FONT>
<P>

<H1><A NAME="SECTION00460000000000000000">
Exercises</A>
</H1>
<OL>
<LI>Write a program to manage an array of many stacks.
</LI>
<LI>Describe the difference between the kernel and daemons
in UNIX. What is the point of making this distinction?
</LI>
<LI>What is two-mode operation?
</LI>
<LI>What is the difference between an <EM>emulator</EM> or <EM>simulator</EM>
and true multi-tasking?
</LI>
<LI>To prepare to for the project suggestion in the next chapter,
write a program which reads fictitious commands in from a file.
The commands should be of the form:
<PRE>
operator operand

load     12
add      23
store    1334
jsr      5678
wait     1
fork     0
</PRE>
etc. Read in the commands and print out a log of what the commands are,
in the form "Executing (operator) on (operand)". You should be
able to recognize the commands `wait' and `fork' specially, but the
other commands may be anything you like. The aim is to simulate the
type of commands a real program has to execute.

</LI>
</OL><FONT SIZE="-2">
</FONT>
<H1><A NAME="SECTION00500000000000000000">
4. Processes and Thread</A>
</H1>
<P>

<H1><A NAME="SECTION00510000000000000000">
4.1 Key concepts</A>
</H1>
<P>
<FONT SIZE="-2">Multitasking and multi-user systems need to distinguish between the
different programs being executed by the system. This is accomplished with
the concept of a <EM>process</EM>.<A NAME="1041"></A>
</FONT>
<P>

<H2><A NAME="SECTION00511000000000000000">
4.1.1 Naming conventions</A>
</H2>
<P>
<FONT SIZE="-2">Before talking about process management we shall introduce some of
the names which are in common use. Not all operating systems or books
agree on the definitions of these names. In this chapter we shall
take a liberal attitude  - after all, it is the ideas rather
than the names which count. Try to remember the different terms - they
will be used repeatedly.
</FONT>
<P>

<UL>
<LI><B>Process</B>:
This is a general term for <EM>a program which is 
being executed</EM>. All work done by the CPU contributes to the
execution of processes. Each process has a descriptive information
structure associated with it (normally held by the kernel) called
a <EM>process control block</EM> which keeps track of how far the
execution has progressed and what resources the process holds.<A NAME="1047"></A>

<P>
</LI>
<LI><B>Task</B>:
On some systems processes are called tasks.<A NAME="1049"></A>

<P>
</LI>
<LI><B>Job</B>:<A NAME="1051"></A><A NAME="1052"></A>
Some systems distinguish between <EM>batch</EM> execution and
<EM>interactive</EM> execution. Batch (or queued) processes are often called
jobs. They are like production line processes which start, do something
and quit, without stopping to ask for input from a user. They are
non-interactive processes.

<P>
</LI>
<LI><B>Thread</B>: (sometimes called a <EM>lightweight process</EM>) is different
<A NAME="1057"></A><A NAME="1058"></A>
from process or task in that a thread is not enough to get a whole
program executed. A thread is a kind of <EM>stripped down</EM> process -
it is just one `active hand' in a program - something which the CPU
is doing on behalf of a program, but not enough to be called a
complete process.  Threads remember what they have done separately,
but they share the information about what resources a program is
using, and what state the program is in. A thread is only a <EM>CPU
assignment</EM>. Several threads can contribute to a single task. When
this happens, the information about one process or task is used by
many threads. Each task must have at least one thread in order to do
any work.

<P>
</LI>
<LI><B>CPU burst</B>: A period of uninterrupted CPU activity.
<A NAME="1062"></A>

<P>
</LI>
<LI><B>I/O burst</B>: A period of uninterrupted input/output activity.
<A NAME="1064"></A>

<P>
</LI>
</UL>
<P>

<H2><A NAME="SECTION00512000000000000000">
4.1.2 Scheduling</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1067"></A>
On most multitasking systems, only one process can truly be active at
a time - the system must therefore 
share its time between the execution of many
processes. This sharing is called <EM>scheduling</EM>.
(Scheduling <!-- MATH
 $\leftrightarrow$
 -->
<IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img10.png"
 ALT="$\leftrightarrow$"> time management.)
</FONT>
<P>
<FONT SIZE="-2">Different methods of scheduling are appropriate for different kinds
of execution. A <EM>queue</EM><A NAME="1070"></A> is one form of scheduling in which each
program waits its turn and is executed serially. This is not very
useful for handling multitasking, but it is necessary for
scheduling <EM>devices</EM> which cannot be shared by nature. An example
of the latter is the printer. Each print job has to be completed before
the next one can begin, otherwise all the print jobs would be mixed
up and interleaved resulting in nonsense.
</FONT>
<P>
<FONT SIZE="-2">We shall make a broad distinction between two types of scheduling:
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Queueing.</B> This is appropriate for serial or batch jobs
like print spooling and requests from a server. There are two main ways
of giving priority to the jobs in a queue. One is a <EM>first-come
first-served</EM> (FCFS) basis, also referred to as <EM>first-in first-out</EM>
(FIFO); the other is to process the <EM>shortest job first</EM> (SJF).
<A NAME="1077"></A><A NAME="1078"></A><A NAME="1079"></A><A NAME="1080"></A><A NAME="1081"></A>

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Round-robin.</B> This is the time-sharing approach
<A NAME="1083"></A>
in which several tasks can coexist. The scheduler gives a short time-slice
to each job, before moving on to the next job, polling each task round and
round. This way, all the tasks advance, little by little, on a controlled
basis.
</DD>
</DL><FONT SIZE="-2">
These two categories are also referred to as <EM>non-preemptive</EM>
and <EM>preemptive</EM> respectively, but there is a grey area.
<A NAME="1087"></A>
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Strictly non-preemptive</B> Each program continues
executing until it has finished, or until it must wait for an event (e.g.
I/O or another task). This is like Windows 95 and MacIntosh
system 7.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Strictly preemptive</B> The system decides how time is
to be shared between the tasks, and interrupts each process after its
time-slice whether it likes it or not. It then executes another program
for a fixed time and stops, then the next...etc.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Politely-preemptive??</B> The system decides how
time is to be shared, but it will not interrupt a program if it is in
a <EM>critical section</EM>. Certain sections of a program may be so
important that they must be allowed to execute from start to finish
without being interrupted. This is like UNIX and Windows NT.

<P>
</DD>
</DL>
<P>
<FONT SIZE="-2">To choose an algorithm for scheduling tasks we have to understand what 
it is we are trying to achieve. i.e. What are the criterea for scheduling?
<A NAME="1094"></A>
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>We want to maximize the efficiency of the machine.
i.e. we would like all the resources of the machine to be doing useful
work all of the time - i.e. not be idling during one process, when
another process could be using them. The key to organizing the
resources is to get the CPU time-sharing right, since this is the
central `organ' in any computer, through which almost everything must
happen. But this cannot be achieved without also thinking about how
the I/O devices must be shared, since the I/O devices communicate by
interrupting the CPU from what it is doing.  (Most workstations spend
most of their time idling. There are enormous amounts of untapped CPU
power going to waste all over the world each day.)

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>We would like as many jobs to get finished as quickly
as possible.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Interactive users get irritated if the performance of
the machine seems slow. We would like the machine to appear fast for
interactive users - or have a fast <EM>response time</EM>.<A NAME="1099"></A>
</DD>
</DL>
<P>
<FONT SIZE="-2">Some of these criterea cannot be met simultaneously and we must make
compromises. In particular, what is good for batch jobs is often not
good for interactive processes and vice-versa, as we remark under
<EM>Run levels - priority</EM> below.
</FONT>
<P>

<H2><A NAME="SECTION00513000000000000000">
4.1.3 Scheduling hierarchy</A>
</H2><FONT SIZE="-2">
Complex scheduling algorithms distinguish between short-term and
long-term scheduling. This helps to
deal with tasks which fall into two kinds: those
which are active continuously and
must therefore be serviced regularly, and those which sleep for long
periods. 
</FONT>
<P>
<FONT SIZE="-2">For example, in UNIX the long term scheduler moves
processes which have been sleeping for more than a certain time
out of memory and onto disk, to make space for those which
are active. Sleeping jobs are moved back into memory
only when they wake up (for whatever reason). This is called
<EM>swapping</EM>.
</FONT>
<P>
<FONT SIZE="-2">The most complex systems have several levels of scheduling and
exercise different scheduling polices for processes with
different <EM>priorities</EM>. Jobs can even move from level to
level if the circumstances change.<A NAME="1105"></A>
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="1108"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.1:</STRONG>
Multi-level scheduling.</CAPTION>
<TR><TD><IMG
 WIDTH="455" HEIGHT="394" BORDER="0"
 SRC="img11.png"
 ALT="\begin{figure}\psfig{file=figs/fig4.1.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00514000000000000000">
4.1.4 Runs levels - priority</A>
</H2>
<P>
<FONT SIZE="-2">Rather than giving all programs equal shares of CPU time, most systems
have priorities. Processes with higher priorities are either serviced
more often than processes with lower priorities, or they get longer
time-slices of the CPU.
</FONT>
<P>
<FONT SIZE="-2">Priorities are not normally fixed but vary according to the
performance of the system and the amount of CPU time a process has
already used up in the recent past. For example, processes which
have used a lot of CPU time in the recent past often have their
priority reduced. This tends to favour iterative processes which
wait often for I/O and makes the response time of the system seem
faster for interactive users.
</FONT>
<P>
<FONT SIZE="-2">In addition, processes may be reduced in priority if their total
accumulated CPU usage becomes very large. (This occurs, for example
in UNIX). The wisdom of this approach is arguable, since programs which
take a long time to complete tend to be penalized. Indeed, they take
must longer to complete because their priority is reduced. If the
priority continued to be lowered, long jobs would <EM>never</EM> get
finished. This is called process <EM>starvation</EM> and must be
avoided.
</FONT>
<P>
<FONT SIZE="-2">Scheduling algorithms have to work without knowing how long processes
will take. Often the best judge of how demanding a program will be is
the user who started the program. UNIX allows users to reduce the
priority of a program themselves using the <code>nice</code> command.
`Nice' users are supposed to sacrifice their own self-interest for
the good of others. Only the system manager can increase the
priority of a process.
</FONT>
<P>
<FONT SIZE="-2">Another possibility which is often not considered, is that of
<EM>increasing</EM> the priority of resource-gobbling programs in order
to get them out of the way as fast as possible. This is very difficult
for an algorithm to judge, so it must be done manually by the system
administrator.
</FONT>
<P>

<H2><A NAME="SECTION00515000000000000000">
4.1.5 Context switching</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1115"></A>
Switching from one running process to another running process
incurs a <EM>cost</EM> to the system. The values of all the registers
must be saved in the present state, the status of all open files
must be recorded and the present position in the program must be
recorded. Then the contents of the MMU must be stored for the process
(see next chapter).<A NAME="1117"></A>
Then all those things must be read in for the next process,
so that the state of the system is exactly as it was when the
scheduler last interrupted the process. This is called a
<EM>context switch</EM>. Context switching is a system overhead. It costs
real time and CPU cycles, so we don't want to context switch too often,
or a lot of time will be wasted.
</FONT>
<P>
<FONT SIZE="-2">The state of each process is saved to a 
data structure in the kernel called a <EM>process control block</EM> (PCB).
Here is an example PCB from Mach OS:<A NAME="1120"></A><A NAME="1121"></A>
<A NAME="1122"></A>
</FONT><PRE>
typedef struct machpcb 
   {
   char    mpcb_frame[REGOFF];
   struct  regs mpcb_regs;            /* user's saved registers */
   struct  rwindow mpcb_wbuf[MAXWIN]; /* user window save buffer */
   char    *mpcb_spbuf[MAXWIN];       /* sp's for each wbuf */
   int     mpcb_wbcnt;                /* number of saved windows in pcb_wbuf */
   struct  v9_fpu *mpcb_fpu;          /* fpu state */
   struct  fq mpcb_fpu_q[MAXFPQ];     /* fpu exception queue */
   int     mpcb_flags;                /* various state flags */
   int     mpcb_wocnt;                /* window overflow count */
   int     mpcb_wucnt;                /* window underflow count */
   kthread_t *mpcb_thread;            /* associated thread */
   } 
machpcb_t;
</PRE><FONT SIZE="-2"></FONT>
<P>
<FONT SIZE="-2">Below is a kernel process structure for a UNIX system.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
struct	proc 
   {
   struct  proc *p_link;        /* linked list of running processes */
   struct  proc *p_rlink;
   struct  proc *p_nxt;         /* linked list of allocated proc slots */
   struct  proc **p_prev;       /* also zombies, and free procs */
   struct  as *p_as;            /* address space description */
   struct  seguser *p_segu;     /* "u" segment */
   caddr_t p_stack;             /* kernel stack top for this process */
   struct  user *p_uarea;       /* u area for this process */
   char	   p_usrpri;            /* user-priority based on p_cpu and p_nice */
   char	   p_pri;               /* priority, negative is high */
   char	   p_cpu;               /* (decayed) cpu usage solely for scheduling */
   char	   p_stat;
   char	   p_time;              /* seconds resident (for scheduling) */
   char	   p_nice;              /* nice for cpu usage */
   char	   p_slptime;           /* seconds since last block (sleep) */
   char    p_cursig;
   int     p_sig;               /* signals pending to this process */
   int     p_sigmask;           /* current signal mask */
   int     p_sigignore;         /* signals being ignored */
   int     p_sigcatch;          /* signals being caught by user */
   int     p_flag;
   uid_t   p_uid;               /* user id, used to direct tty signals */
   uid_t   p_suid;              /* saved (effective) user id from exec */
   gid_t   p_sgid;              /* saved (effective) group id from exec */
   short   p_pgrp;              /* name of process group leader */
   short   p_pid;               /* unique process id */
   short   p_ppid;              /* process id of parent */
   u_short p_xstat;             /* Exit status for wait */
   short   p_cpticks;           /* ticks of cpu time, used for p_pctcpu */
   struct  ucred *p_cred;       /* Process credentials */
   struct  rusage *p_ru;        /* mbuf holding exit information */
   int     p_tsize;             /* size of text (clicks) */
   int     p_dsize;             /* size of data space (clicks) */
   int     p_ssize;             /* copy of stack size (clicks) */
   int     p_rssize;            /* current resident set size in clicks */
   int     p_maxrss;            /* copy of u.u_limit[MAXRSS] */
   int     p_swrss;             /* resident set size before last swap */
   caddr_t p_wchan;             /* event process is awaiting */
   long    p_pctcpu;            /* (decayed) %cpu for this process */
   struct  proc *p_pptr;        /* pointer to process structure of parent */
   struct  proc *p_cptr;        /* pointer to youngest living child */
   struct  proc *p_osptr;       /* pointer to older sibling processes */
   struct  proc *p_ysptr;       /* pointer to younger siblings */
   struct  proc *p_tptr;        /* pointer to process structure of tracer */
   struct  itimerval p_realtimer;
   struct  sess *p_sessp;       /* pointer to session info */
   struct  proc *p_pglnk;       /* list of pgrps in same hash bucket */
   short   p_idhash;            /* hashed based on p_pid for kill+exit+... */
   short   p_swlocks;           /* number of swap vnode locks held */
   struct  aiodone *p_aio_forw; /* (front)list of completed asynch IO's */
   struct  aiodone *p_aio_back; /* (rear)list of completed asynch IO's */
   int     p_aio_count;         /* number of pending asynch IO's */
   int     p_threadcnt;         /* ref count of number of threads using proc */
   int     p_cpuid;             /* processor this process is running on */
   int     p_pam;               /* processor affinity mask */
   };
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">UNIX also uses a `user' structure to keep auxiliary information which
is only needed when jobs are not `swapped out' (see next chapter).
</FONT>
<P>

<H2><A NAME="SECTION00516000000000000000">
4.1.6 Interprocess communication</A>
</H2>
<P>
<FONT SIZE="-2">One of the benefits of multitasking is that several processes can be
made to cooperate in order to achieve their ends. To do this, they must
do one of the following.<A NAME="1128"></A><A NAME="1129"></A>
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Communicate</B>. Interprocess communication (IPC)
involves sending information from one process to another. This can be
achieved using a `mailbox' system, a socket (Berkeley) which behaves like
a virtual communications network (loopback), or through the use of `pipes'.
Pipes are a system construction which enables one process to open
another process as if it were a file for writing or reading.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Share data.</B> A segment of memory must be available
to both processes. (Most memory is locked to a single process).
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Waiting.</B> Some processes wait for other processes
to give a signal before continuing. This is an issue of synchronization.

<P>
</DD>
</DL>
<P>
<FONT SIZE="-2">As soon as we open the door to co-operation there is a problem of how to
synchronize cooperating processes. For example, suppose two processes
modify the same file. If both processes tried to write simultaneously
the result would be a nonsensical mixture. We must have a way of
synchronizing processes, so that even concurrent processes must stand in
line to access shared data <EM>serially</EM>.<A NAME="1136"></A>
</FONT>
<P>
<FONT SIZE="-2">Synchronization is a tricky problem in multiprocessor systems, but
it can be achieved with the help of <EM>critical sections</EM> 
and <EM>semaphores</EM>/ <EM>locks</EM>. We shall return to these below.
<A NAME="1140"></A><A NAME="1141"></A>
</FONT>
<P>

<H1><A NAME="SECTION00520000000000000000">
4.2 Creation and scheduling</A>
</H1>
<P>

<H2><A NAME="SECTION00521000000000000000">
4.2.1 Creating processes</A>
</H2>
<P>
<FONT SIZE="-2">The creation of a process requires the following steps. The order in
which they are carried out is not necessarily the same in all cases.
<A NAME="1144"></A>
</FONT>
<P>

<OL>
<LI><B>Name.</B> The name of the program which is to run as the new
process must be known.
</LI>
<LI><B>Process ID and Process Control Block.</B> The system creates a
new process control block, or locates an unused block in an array. 
This block is used to follow the execution of
the program through its course,  keeping track of its resources and
priority. Each process control block is labelled by its PID or process
identifier.
</LI>
<LI><B>Locate the program</B> to be executed 
on disk and allocate memory for the code segment
in RAM.

<P>
</LI>
<LI><B>Load the program</B> into the code segment and initialize the
registers of the PCB with the start address of the program and appropriate
starting values for resources.

<P>
</LI>
<LI><B>Priority.</B> A priority must be computed for the process, using
a default for the type of
process and any value which the user specified as a `nice' value (see <EM>Run levels - priorities</EM> above).
</LI>
<LI><B>Schedule the process for execution.</B>
</LI>
</OL>
<P>

<H2><A NAME="SECTION00522000000000000000">
4.2.2 Process hierarchy: children and parent processes</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1155"></A>
In a democratic system anyone can choose to start a new process, but
it is never users which create processes but other processes! That is because
anyone using the system must already be running a shell or command
interpreter in order to be able to talk to the system, and the command
interpreter is itself a process.
</FONT>
<P>
<FONT SIZE="-2">When a user creates a process using the command interpreter, the new
process become a <EM>child</EM> of the command interpreter. Similarly the
command interpreter process becomes the parent for the child. Processes
therefore form a hierarchy.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="1159"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.2:</STRONG>
Process hierachies</CAPTION>
<TR><TD><IMG
 WIDTH="470" HEIGHT="209" BORDER="0"
 SRC="img12.png"
 ALT="\begin{figure}\psfig{file=figs/hierachy.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">The processes are linked by a tree structure. If a parent is signalled
or killed, usually all its children receive the same signal or are
destroyed with the parent.  This doesn't <EM>have</EM> to be the
case--it is possible to detach children from their parents--but in
many cases it is useful for processes to be linked in this way.
</FONT>
<P>
<FONT SIZE="-2">When a child is created it may do one of two things.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Duplicate the parent process.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Load a completely new program.
</DD>
</DL><FONT SIZE="-2">
Similarly the parent may do one of two things.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Continue executing along side its children.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Wait for some or all of its children to finish before proceeding.

<P>
</DD>
</DL>
<P>

<H2><A NAME="SECTION00523000000000000000">
4.2.3 Unix: fork() and wait()</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1420"></A>
<A NAME="1421"></A>
As an example of process creation, we shall consider UNIX. The following
example program is written in C++ and makes use of the standard
library function <code>fork()</code>. The syntax of <code>fork</code> is
</FONT><PRE>
returncode = fork();
</PRE><FONT SIZE="-2">
When this instruction is executed, the process concerned splits into
two and both continue to execute independently from after the <code>fork</code>
intruction. If fork is successful, it returns <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$0$"> to the child process
and the process identifier or <EM>pid</EM> of the child process to the
parent. It, for some reason, a new process cannot be created it
returns a value of <IMG
 WIDTH="27" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img13.png"
 ALT="$-1$"> to the parent.
</FONT>
<P>
<FONT SIZE="-2">The following example does not check for errors if fork fails.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
//**************************************************************
//*
//*  A brief demo of the UNIX process duplicator fork().
//*
//*  g++ unix.C to compile this.
//*
//**************************************************************

#include &lt;iostream.h&gt;

extern "C" void sleep();
extern "C" int fork();
extern "C" int getpid();
extern "C" void wait();
extern "C" void exit();

void ChildProcess();

//***************************************************************

main ()

{ int pid, cid;

pid = getpid();

cout &lt;&lt; "Fork demo! I am the parent (pid = " &lt;&lt; pid &lt;&lt; ")\n";

if (! fork())
   {
   cid = getpid();
   cout &lt;&lt; "I am the child (cid=" &lt;&lt; cid &lt;&lt; ") of (pid = " &lt;&lt; pid &lt;&lt; ")\n";
   ChildProcess();
   exit(0);
   }


cout &lt;&lt; "Parent waiting here for the child...\n";
wait(NULL);

cout &lt;&lt; "Child finished, parent quitting too!\n";
}

//**************************************************************

void ChildProcess()

{ int i;

for (i = 0; i &lt; 10; i++)
   {
   cout &lt;&lt; i &lt;&lt; "..\n";
   sleep(1);
   }
}
</PRE><FONT SIZE="-2"></FONT>
<P>
<FONT SIZE="-2">Here is the output from the program in a test run. Note
that the parent and child processes share the same output
stream, so we see how they are synchronised from the
order in which the output is mixed.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
Fork demo! I am the parent (pid = 2196)
I am the child (cid=2197) of (pid = 2196)
0..
Parent waiting here for the child...
1..
2..
3..
4..
5..
6..
7..
8..
9..
Child finished, parent quitting too!
</PRE><FONT SIZE="-2"></FONT>
<P>
<FONT SIZE="-2">Note that the child has time to execute its first instruction before
the parent has time to call <code>wait()</code>, so the zero appears
before the message from the parent. When the child goes to sleep for
one second, the parent catches up.
</FONT>
<P>

<H2><A NAME="SECTION00524000000000000000">
4.2.4 Process states</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1181"></A>
In order to know when to execute a program and when not to execute a
program, it is convenient for the scheduler to label programs with
a `state' variable. This is just an integer value which saves the
scheduler time in deciding what to do with a process. Broadly speaking
the state of a process may be one of the following.
</FONT>
<OL>
<LI>New.
</LI>
<LI>Ready (in line to be executed).
</LI>
<LI>Running (active).
</LI>
<LI>Waiting (sleeping, suspended)
</LI>
<LI>Terminated (defunct)
</LI>
</OL><FONT SIZE="-2">
When time-sharing, the scheduler only needs to consider the processes
which are in the `ready' state. Changes of state are made by the
system and follow the pattern in the diagram below.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="1186"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.3:</STRONG>
Process state diagram.</CAPTION>
<TR><TD><IMG
 WIDTH="454" HEIGHT="381" BORDER="0"
 SRC="img14.png"
 ALT="\begin{figure}\psfig{file=figs/fig4.2.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
The transitions between different states normally happen on
interrupts.
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<DIV ALIGN="CENTER"><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">
From state </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2">  Event    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> To state</FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">  
New        </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> Accepted  </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Ready </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Ready      </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> Scheduled / Dispatch </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Running </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Running    </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> Need I/O  </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Waiting </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Running    </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> Scheduler timeout   </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Ready   </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Running    </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> Completion / Error / Killed </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Terminated </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Waiting    </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> I/O completed or wakeup event </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Ready </FONT></TD>
</TR>
</TABLE></DIV>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<P>

<H2><A NAME="SECTION00525000000000000000">
4.2.5 Queue scheduling</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1196"></A>
The basis of all scheduling is the queue structure. A round-robin
scheduler uses a queue but moves cyclically
through the queue at its own speed, instead of waiting for each task
in the queue to complete. Queue scheduling is primarily used for
serial execution.
</FONT>
<P>
<FONT SIZE="-2">There are two main types of queue.
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>First-come first-server</EM> (FCFS), also called <EM>first-in first-out</EM> (FIFO).
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Sorted queue, in which the elements are regularly ordered
according to some rule. The most prevalent example of this is the
<EM>shortest job first</EM> (SJF) rule.
</DD>
</DL><FONT SIZE="-2">
The FCFS queue is the simplest and incurs almost no system overhead. 
The SJF scheme can cost quite a lot in system overhead, since each task in
the queue must be evaluated to determine which is shortest. The SJF
strategy is often used for print schedulers since it is quite
inexpensive to determine the size of a file to be printed (the file
size is usually stored in the file itself).
</FONT>
<P>
<FONT SIZE="-2">The efficiency of the two schemes is subjective: long jobs have to
wait longer if short jobs are moved in front of them, but if the
distribution of jobs is random then we can show that the average
waiting time of any one job is shorter in the SJF scheme, because
the greatest number of jobs will always be executed in the shortest
possible time.
</FONT>
<P>
<FONT SIZE="-2">Of course this argument is rather stupid, since it is only the system
which cares about the average waiting time per job, for its own
prestige. Users who print only long jobs do not share the same clinical
viewpoint. Moreover, if only short jobs arrive after one long job, it
is possible that the long job will never get printed. This is an example of
<EM>starvation</EM>. A fairer solution is required (see exercises below).
</FONT>
<P>
<FONT SIZE="-2">Queue scheduling <EM>can</EM> be used for CPU scheduling, 
but it is quite inefficient.
To understand why simple queue scheduling is not desirable we can begin
by looking at a diagram which shows how the CPU and the devices are
being used when a FCFS queue is used.
We label each process by <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$">, <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$">... etc. A blank space indicates that
the CPU or I/O devices are in an idle state (waiting for a customer).
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<DIV ALIGN="CENTER"><FONT SIZE="-2">Time <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$\rightarrow$">
<BR>&nbsp;
<BR></FONT><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">
CPU     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> - </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
devices </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">  -   </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> </FONT></TD>
</TR>
</TABLE></DIV>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
This diagram shows that <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> starts out with a CPU burst. At some
point it needs input (say from a disk)
and sends a request to the device. While
the device is busy servicing the request from <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$">, the CPU is
idle, waiting for the result. Similarly, when the result returns,
the device waits idle while the next CPU burst takes place. When <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$">
is finished, <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> is started and goes through the same kind of cycle.
</FONT>
<P>
<FONT SIZE="-2">There are many blank spaces in the diagram, where the devices and the
CPU are idle. Why, for example, couldn't the device be searching
for the I/O for <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> while the CPU was busy with <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> and vice versa?
</FONT>
<P>
<FONT SIZE="-2">We can improve the picture by introducing a new rule: every time
one process needs to wait for a device, it gets put to the back of
the queue. Now consider the following diagram, in which we have three
processes. They will always be scheduled in order <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$">, <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$">, <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> until
one or all of them is finished.
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<DIV ALIGN="CENTER"><FONT SIZE="-2">Time <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$\rightarrow$">
<BR>&nbsp;
<BR></FONT><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">
CPU     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$">-finishes </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$">-finishes </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> - </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"></FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
devices </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> - </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> -</FONT></TD>
</TR>
</TABLE></DIV>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
<IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> starts out as before with a CPU burst. But now when it occupies
the device, <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> takes over the CPU. Similarly when <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> has to wait
for the device to complete <I>its</I> I/O, <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> gets executed, and when
<IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> has to wait, <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> takes over again. Now suppose <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> finishes:
<IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> takes over, since it is next in the queue, but now the device
is idle, because <IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$P2$"> did not need to use the device. Also, when
<IMG
 WIDTH="27" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.png"
 ALT="$P1$"> finishes, only <IMG
 WIDTH="27" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$P3$"> is left and the gaps of idle time get bigger.
</FONT>
<P>
<FONT SIZE="-2">In the beginning, this second scheme looked pretty good - both the
CPU and the devices were busy most of the time (few gaps in the
diagram). As processes finished,
the efficiency got worse, but on a real system, someone will always
be starting new processes so this might not be a problem.
</FONT>
<P>
<FONT SIZE="-2">Let us ask - how can we improve this scheme? The resource utilization is
not too bad, but the problem is that it assumes that every program
goes in a kind of cycle
</FONT>
<P>
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
CPU  \leftarrow \rightarrow I/O.
\end{displaymath}
 -->

<IMG
 WIDTH="120" HEIGHT="33" BORDER="0"
 SRC="img19.png"
 ALT="\begin{displaymath}CPU \leftarrow \rightarrow I/O.\end{displaymath}">
</DIV>
<BR CLEAR="ALL">
<P></P>
<P>
<FONT SIZE="-2">If one program spoils this cycle by performing a lot of CPU intensive
work, or by waiting for dozens of I/O requests, then the
whole scheme goes to pieces.
</FONT>
<P>

<H2><A NAME="SECTION00526000000000000000"></A>
<A NAME="1220"></A>
<BR>
4.2.6 Round-robin scheduling
</H2>
<P>
<FONT SIZE="-2">The use of the I/O - CPU burst cycle to requeue jobs improves the
resource utilization considerably, but it does not prevent certain
jobs from hogging the CPU. Indeed, if one process went into an infinite
loop, the whole system would stop dead.
Also, it does not provide any easy way of
giving some processes priority over others.
</FONT>
<P>
<FONT SIZE="-2">A better solution is to ration the CPU time, by introducing
time-slices. This means that 
</FONT>
<P>

<OL>
<LI>no process can hold onto the CPU forever, 
</LI>
<LI>processes which get requeued often (because they
spend a lot of time waiting for devices) come around faster, i.e.
we don't have to wait for CPU intensive processes, and
</LI>
<LI>the length of the time-slices can be varied so as to
give priority to particular processes.
</LI>
</OL>
<P>
<FONT SIZE="-2">The time-sharing is implemented by a hardware timer. 
On each context switch, the
system loads the timer with the duration of its time-slice and hands
control over to the new process. When the timer times-out, it interrupts
the CPU which then steps in and switches to the next process.
</FONT>
<P>
<FONT SIZE="-2">The basic queue is the FCFS/FIFO queue. New processes are added to the
end, as are processes which are waiting.<A NAME="1223"></A><A NAME="1224"></A><A NAME="1225"></A>
</FONT>
<P>
<FONT SIZE="-2">The success or failure of round-robin (RR) scheduling depends on the
length of the time-slice or <EM>time-quantum</EM>. If the slices are too
short, the cost of context switching becomes high in comparision to
the time spent doing useful work. If they become too long, processes
which are waiting spend too much time doing nothing - and in the
worst case, everything reverts back to FCFS.  A rule of thumb is to
make the time-slices large enough so that only, say, twenty percent of all
context switches are due to timeouts - the remainder occur freely
because of waiting for requested I/O.
</FONT>
<P>

<H2><A NAME="SECTION00527000000000000000">
4.2.7 CPU quotas and accounting</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1228"></A><A NAME="1229"></A>
Many multiuser systems allow restrictions to be placed on user activity.
For example, it is possible to limit the CPU time used by any one
job. If a job exceeds the limit, it is terminated by the kernel.
In order to make such a decision, the kernel has to keep detailed information
about the cumulative use of resources for each process. This is called
<EM>accounting</EM> and it can be a considerable system overhead. Most
system administrators would prefer not to use accounting - though 
unfortunately many are driven to it by thoughtless or hostile users.
</FONT>
<P>

<H1><A NAME="SECTION00530000000000000000">
4.3 Threads</A>
</H1>
<P>

<H2><A NAME="SECTION00531000000000000000">
4.3.1 Heavy and lightweight processes</A>
</H2>
<P>
<FONT SIZE="-2"><EM>Threads</EM>, sometimes called <EM>lightweight processes</EM> (LWPs) are
indepedendently scheduled parts of a single program.  We say that a
task is <EM>multithreaded</EM> if it is composed of several independent
subprocesses which do work on common data, and if each of those pieces
could (at least in principle) run in parallel.<A NAME="1236"></A>
</FONT>
<P>
<FONT SIZE="-2">If we write a program which uses
threads - there is only one program, one executable file, one task in
the normal sense.  Threads simply enable us to split up that program
into logically separate pieces, and have the pieces run independently
of one another, until they need to communicate. In a sense, threads
are a further level of <EM>object orientation</EM> for multitasking systems.
<A NAME="1238"></A>
They allow certain <EM>functions</EM> to be executed in parallel with
others.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="1242"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.4:</STRONG>
System and user level threads: suppose we think of a household kitchen
as being a process, then each electrical appliance which contributes
to the work of the kitchen is like a thread. In order to work, a
thread needs power. The power sockets are like kernel threads or
CPUs. A job like making a cake or tidying up might involve several
threads (powered machinery), which might run in parallel or one after
the other.  Since there are more appliances than power points, we have
to schedule the time each appliance gets power so as to share between
all of them.</CAPTION>
<TR><TD><IMG
 WIDTH="453" HEIGHT="377" BORDER="0"
 SRC="img20.png"
 ALT="\begin{figure}\psfig{file=figs/fig4.4.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">On a truly parallel computer (several CPUs) we might imagine parts of
a program (different subroutines) running on quite different
processors, until they need to communicate.  When one part of the
program needs to send data to the other part, the two independent
pieces must be synchronized, or be made to wait for one another.  But
what is the point of this? We can always run independent procedures in
a program as separate <EM>programs</EM>, using the process mechanisms we
have already introduced.  They could communicate using normal
interprocesses communication. Why introduce another new concept?  Why
do we need threads?
</FONT>
<P>
<FONT SIZE="-2">The point is that threads are cheaper than normal processes, and that
they can be scheduled for execution in a user-dependent way, with less
overhead.  Threads are cheaper than a whole process because they do
not have a full set of resources each. Whereas the process control
block for a heavyweight process is large and costly to context switch,
the PCBs for threads are much smaller, since each thread has only a
stack and some registers to manage. It has no open file lists or
resource lists, no accounting structures to update. All of these
resources are shared by all threads within the process.  Threads can
be assigned priorities - a higher priority thread will get put to the
front of the queue.
</FONT>
<P>

<DIV ALIGN="CENTER"><FONT SIZE="-2"><EM>In other words, threads are processes within processes!
<BR>
Threads can only run inside a normal process.
</EM></FONT></DIV>
<P>
<FONT SIZE="-2">Let's define heavy and lightweight processes with the help of a table.
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<DIV ALIGN="CENTER"><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">
Object </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Resources </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Thread (LWP) </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Stack <IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.png"
 ALT="$+$"> set of CPU registers <IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.png"
 ALT="$+$"> CPU time.</FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Task (HWP)   </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> 1 thread <IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.png"
 ALT="$+$"> process control block,</FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
 &nbsp;           </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> program code, memory segment etc.</FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
Multithreaded task </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> n-threads <IMG
 WIDTH="18" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.png"
 ALT="$+$"> process control block,</FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
 &nbsp;           </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> program code, memory segment etc.</FONT></TD>
</TR>
</TABLE></DIV>
<P>
<FONT SIZE="-2">
<BR>
<BR>
<BR>
</FONT>
<P>

<H2><A NAME="SECTION00532000000000000000">
4.3.2 Why use threads?</A>
</H2>
<P>
<FONT SIZE="-2">From our discussion of scheduling, we can see that the sharing of resources 
could have been made more effective if the scheduler had known exactly
what each program was going to do in advance. 
Of course, the scheduling algorithm
can never know this - but the programmer who wrote the program does know.
Using threads it is possible to organize the execution of a program in
such a way that something is always being done, when ever the
scheduler gives the heavyweight process CPU time.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Threads allow a programmer to switch between 
lightweight processes when it is best for the program. (The programmer
has control.)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A process which uses threads does not get more CPU
time than an ordinary process - but the CPU time it gets is used
to do work on the threads. It is possible to write a more efficient
program by making use of threads.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Inside a heavyweight process, threads are scheduled on
a FCFS basis, unless the program decides to force certain threads to
wait for other threads. If there is only one CPU, then only one thread 
can be running at a time.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Threads context switch without any need to involve
the kernel - the switching is performed by a user level library, so
time is saved because the kernel doesn't need to know about the
threads.

<P>
</DD>
</DL>
<P>

<H2><A NAME="SECTION00533000000000000000">
4.3.3 Levels of threads</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1262"></A>
In modern operating systems, there are two levels at which threads
operate: system or kernel threads and user level threads. If the
kernel itself is multithreaded, the scheduler assigns CPU time on a
thread basis rather than on a process basis. A kernel level thread
behaves like a virtual CPU, or a power-point to which user-processes
can connect in order to get computing power.  The kernel has as many
system level threads as it has CPUs and each of these must be shared
between all of the user-threads on the system. In other words, the maximum
number of user level threads which can be active at any one time is
equal to the number of system level threads, which in turn is equal to
the number of CPUs on the system.
</FONT>
<P>
<FONT SIZE="-2">Since threads work ``inside'' a single task, the normal process
scheduler cannot normally tell which thread to run and which not to run
- that is up to the program. When the kernel schedules a process for
execution, it must then find out from that process which is the next
thread it must execute. If the program is lucky enough to have more
than one processor available, then several threads can be scheduled at
the same time.
</FONT>
<P>
<FONT SIZE="-2">Some important implementations of threads are
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The Mach System / OSF1 (user and system level)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Solaris 1 (user level)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Solaris 2 (user and system level)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>OS/2 (system level only)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>NT threads (user and system level)
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>IRIX threads
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>POSIX standardized user threads interface
</DD>
</DL>
<P>

<H2><A NAME="SECTION00534000000000000000">
4.3.4 Symmetric and asymmetric multiprocessing</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1273"></A>
<A NAME="1274"></A>
<A NAME="1275"></A>
<A NAME="1276"></A>
Threads are of obvious importance in connection with parallel 
processing. There are two approaches to scheduling on a multiprocessor
machine:
</FONT>
<UL>
<LI><B>Asymmetric</B>: one CPU does the work of the system,
the other CPUs service user requests.
</LI>
<LI><B>Symmetric</B>: All processors can be used by the system
 and users alike. No CPU is special.
</LI>
</UL><FONT SIZE="-2">

The asymmetric variant is potentially more wasteful, since it is rare
that the system requires a whole CPU just to itself. This approach is more 
common on very large machines with many processors, where the jobs
the system has to do is quite difficult and warrants a CPU to
itself.
</FONT>
<P>

<H2><A NAME="SECTION00535000000000000000">
4.3.5 Example: POSIX pthreads</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1282"></A>
<A NAME="1283"></A>
The POSIX standardization organization has developed a standard
set of function calls for use of user-level threads. This
library is called the <EM>pthread</EM> interface.
</FONT>
<P>
<FONT SIZE="-2">Let's look at an example program which counts the number of
lines in a list of files. This program will serve as an example
for the remainder of this chapter. We shall first present the
program without threads, and then rewrite it, starting
a new thread for each file. The threaded version of the program
has the possibility of reading several of the files in parallel
and is in principle more efficient, whereas the non-threaded
version must read the files sequentially.
</FONT>
<P>
<FONT SIZE="-2">The non-threaded version of the program looks like this:
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
//
//  Count the number of lines in a number of files, non threaded
//  version.
//
////////////////////////////////////////////////////////////////////////

#include &lt;iostream.h&gt;
#include &lt;fstream.h&gt;

const int bufsize = 100;

void ParseFile(char *);

int LINECOUNT = 0;

/**********************************************************************/

main ()

{
cout &lt;&lt; "Single threaded parent...\n";

ParseFile("proc1");
ParseFile("proc2");
ParseFile("proc3");
ParseFile("proc4");

cout &lt;&lt; "Number of lines = %d\n",LINECOUNT;
}

/**********************************************************************/

void ParseFile(char *filename)

{ fstream file;
  char buffer[bufsize];

cout &lt;&lt; "Trying to open " &lt;&lt; filename &lt;&lt; endl;

file.open(filename, ios::in);

if (! file)
   {
   cerr &lt;&lt; "Couldn't open file\n";
   return;
   }

while (!file.eof())
   {
   file.getline(buffer,bufsize);
   cout &lt;&lt; filename &lt;&lt; ":" &lt;&lt;buffer &lt;&lt; endl;
   LINECOUNT++;
   }

file.close();
}
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">
This program calls the function <code>ParseFile()</code> several times
to open and count the number of lines in a series of files.
The number of lines is held in a global variable called
<code>LINECOUNT</code>. A global variable is, by definition, shared
data. This will cause a problem when we try to parallelize
the program using threads.
Here is the threaded version:
</FONT><PRE>
//
//  Count the number of lines in a number of files.
//  Illustrates use of multithreading. Note: run this program
//  several times to see how the threads get scheduled on the system.
//  Scheduling will be different each time since the system has lots
//  of threads running, which we do not see and these will affect the
//  scheduling of our program.
//
//  Note that, on a multiprocessor system, this program has a potential
//  race condition to update the shared variable LINECOUNT, so we
//  must use a mutex to make a short critical section whenever accessing
//  this shared variable.
//
//  This program uses POSIX threads (pthreads)
//
///////////////////////////////////////////////////////////////////////

#include &lt;iostream.h&gt;
#include &lt;fstream.h&gt;
#include &lt;pthread.h&gt;
#include &lt;sched.h&gt;

const int bufsize = 100;
const int maxfiles = 4;

void *ParseFile(char *);      // Must be void *, defined in pthread.h !

int LINECOUNT = 0;
pthread_mutex_t MUTEX = PTHREAD_MUTEX_INITIALIZER;

/**********************************************************************/

main ()

{ pthread_t tid[maxfiles];;
  int i,ret;

// Create a thread for each file

ret = pthread_create(&amp;(tid[0]), NULL, ParseFile,"proc1");
ret = pthread_create(&amp;(tid[1]), NULL, ParseFile,"proc2");
ret = pthread_create(&amp;(tid[2]), NULL, ParseFile,"proc3");
ret = pthread_create(&amp;(tid[3]), NULL, ParseFile,"proc4");

cout &lt;&lt; "Parent thread waiting...\n";

 // If we don't wait for the threads, they will be killed
 // before they can start...

for (i = 0; i &lt; maxfiles; i++)
   {
   ret = pthread_join(tid[i],(void **)NULL);
   }

cout &lt;&lt; "Parent thread continuing\n";
cout &lt;&lt; "Number of lines = " &lt;&lt; LINECOUNT &lt;&lt; endl;
}

/**********************************************************************/

void *ParseFile(char *filename)

{ fstream file;
  char buffer[bufsize];
  int ret;

cout &lt;&lt; "Trying to open " &lt;&lt; filename &lt;&lt; endl;

file.open(filename, ios::in);

if (! file)
   {
   cerr &lt;&lt; "Couldn't open file\n";
   return NULL;
   }

while (!file.eof())
   {
   file.getline(buffer,bufsize);
   cout &lt;&lt; filename &lt;&lt; ":" &lt;&lt;buffer &lt;&lt; endl;

   // Critical section
   
   ret = pthread_mutex_lock(&amp;MUTEX);
   LINECOUNT++;
   ret = pthread_mutex_unlock(&amp;MUTEX);
   
   // Try uncommenting this ....
   // Yield the process, to allow next thread to be run
   // sched_yield();
   }

file.close();
}
</PRE><FONT SIZE="-2"></FONT>
<P>
<FONT SIZE="-2">In this version of the program, a separate thread is spawned
for each file.  First we call the function <code>pthread_create()</code> for
each file we encounter. A new thread is spawned with a pointer
to the function the thread should execute (in this case the same
function for all threads), called <code>ParseFile()</code>, which reads
lines from the respective files and increments the global variable
<code>LINECOUNT</code>. Several things are important here.
</FONT>
<P>
<FONT SIZE="-2">The main program is itself a thread.  It is essential that we tell the
main program to wait for the additional threads to <EM>join</EM> the main
program before exiting, otherwise the main program will exit and kill
all of the child threads immediately. Thread join-semantics are
like wait-semantics for normal processes.
</FONT>
<P>
<FONT SIZE="-2">Each of the threads updates the same global variable. Suppose
now that two threads are running on different CPUs. It is
possible that both threads would try to alter the value
of the variable <code>LINECOUNT</code> simultaneously. This 
is called a <EM>race condition</EM> and can lead
to unpredictable results. For this reason we use a <EM>mutex</EM>
to lock the variable while it is being updated. We shall discuss
this more in the next section.
</FONT>
<P>
<FONT SIZE="-2">A final point to note is the commented out lines in the
<code>ParseFile()</code> function. The call <code>sched_yield()</code>
tells a running thread to give itself up to the scheduler, so
that the next thread to be scheduled can run instead. This
function can be used to switch between several threads.
By calling this function after each line is read from the
files, we can spread the the CPU time evenly between each
thread. Actually, it is difficult to predict precisely
which threads will be scheduled and when, because the threads
in our program here are only a small number, compared to the
total number of threads waiting to be scheduled by the system.
The interaction with disk I/O can also have a complicated
effect on the scheduling. On a single CPU system, threads are
usually scheduled FCFS in a queue. If we yield after every
instruction, it has the effect of simulating round-robin
scheduling.
</FONT>
<P>

<H2><A NAME="SECTION00536000000000000000">
4.3.6 Example: LWPs in Solaris 1</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1293"></A>
Early solaris systems had user-level threads only, which were
called light weight processes. Since the kernel was single threaded,
only one user-level thread could run at any given time.
</FONT>
<P>
<FONT SIZE="-2">To create a threaded process in solaris 1, one simply has to execute
a LWP system call. The `lightweight processes library' then
converts the normal process into a process descriptor plus a thread.
Here is the simplest example
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
/********************************************************************/
/*                                                                  */
/* Creating a light weight process in SunOS 4.1.3                   */
/*                                                                  */
/********************************************************************/

#include &lt;lwp/lwp.h&gt;
#include &lt;lwp/stackdep.h&gt;

#define MINSTACKSZ   1024
#define STACKSIZE    1000 + MINSTACKSZ
#define MAXPRIORITY  10

/*********************************************************************/

stkalign_t stack[STACKSIZE];

/*********************************************************************/
/* Zone 0                                                            */
/*********************************************************************/

main ()

{ thread_t tid;
  int task();

pod_setmaxpri(MAXPRIORITY);               /* This becomes a lwp here */

lwp_create(&amp;tid,task,MAXPRIORITY,0,STKTOP(stack),0);

printf("Done! - Now other threads can run...\n");
}

/*********************************************************************/
/* Zone 1                                                            */
/*********************************************************************/

task ()

{
printf("Task: next thread after main()!\n");
}
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">Here is an example program containing several threads which wait for
each other.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
/********************************************************************/
/*                                                                  */
/* Creating a light weight process in sunos 4.1.3 (Solaris 1)       */
/*                                                                  */
/* Yielding to other processes                                      */
/*                                                                  */
/********************************************************************/

#include &lt;lwp/lwp.h&gt;
#include &lt;lwp/stackdep.h&gt;

#define MINSTACKSZ   1024
#define STACKCACHE   1000
#define STACKSIZE    STACKCACHE + MINSTACKSZ
#define MAXPRIORITY  10
#define MINPRIORITY  1

/*********************************************************************/

stkalign_t stack[STACKSIZE];

/*********************************************************************/
/* Zone 0                                                            */
/*********************************************************************/

main ()

{ thread_t tid_main;
  thread_t tid_prog1;
  thread_t tid_prog2;
  int prog1(), prog2();

lwp_self(&amp;tid_main);                               /* Get main's tid */
lwp_setstkcache(STACKCACHE,3);         /* Make a cache for each prog */

lwp_create(&amp;tid_prog1,prog1,MINPRIORITY,0,lwp_newstk(),0);
lwp_create(&amp;tid_prog2,prog2,MINPRIORITY,0,lwp_newstk(),0);

printf("One ");

lwp_yield(THREADNULL);

printf("Four ");

lwp_yield(tid_prog2);

printf("Six ");

exit(0);
}

/*********************************************************************/
/* Zone 1,2..                                                        */
/*********************************************************************/

prog1 ()

{
printf("Two ");

if (lwp_yield(THREADNULL) &lt; 0)
   {
   lwp_perror("Bad yield");
   return;
   }

printf("Seven \n");
}

/*********************************************************************/

prog2 ()

{
printf("Three ");

lwp_yield(THREADNULL);

printf("Five ");
}
</PRE><FONT SIZE="-2"></FONT>
<P>

<H1><A NAME="SECTION00540000000000000000">
4.4 Synchronization of processes and threads</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="1299"></A>
When two or more processes work on the same data simultaneously
strange things can happen. We have already seen one example in
the threaded file reader in previous section: when two parallel
threads attempt to update the same variable simultaneously, the
result is unpredictable. The value of the variable afterwards
depends on which of the two threads was the last one to change
the value. This is called a <EM>race condition</EM>. The value
depends on which of the threads wins the race to update the
variable.
</FONT>
<P>
<FONT SIZE="-2">What we need in a multitasking system is a way of
making such situations predictable. This is called
<EM>serialization</EM>.
</FONT>
<P>

<H2><A NAME="SECTION00541000000000000000">
4.4.1 Problems with sharing for processes</A>
</H2>
<P>
<FONT SIZE="-2">It is not only threads which need to be synchronized.  Suppose one
user is running a script program and editing the program
simultaneously. The script is read in line by line. During the
execution of the script, the user adds four lines to the beginning of
the file and saves the file.  Suddenly, when the next line of the
executing script gets read, the pointer to the next line points to the
wrong location and it reads in the same line it already read in four
lines ago! Everything in the program is suddenly shifted by four
lines, without the process execting the script knowing about it.
</FONT>
<P>
<FONT SIZE="-2">This example (which can actually happen in the UNIX shell) may or may
not turn out to be serious - clearly, in general, it can be quite
catastrophic. It is a problem of <EM>synchronization</EM> on the part of
the user and the filesystem<A NAME="tex2html166"
  HREF="footnode.html#foot1304"><SUP>4.1</SUP></A>.
</FONT>
<P>
<FONT SIZE="-2">We must consider programs which share data.
</FONT>
<OL>
<LI><EM>When do we need to prevent programs from accessing data
simultaneously?</EM> If there are 100 processes which want to read from
a file, this will cause no problems because the data themselves are
not changed by a read operation. A problem only arises if more than
one of the parties wants to <EM>modify</EM> the data.<A NAME="1308"></A>

<P>
</LI>
<LI><EM>Is it even sensible for two programs to want to modify 
data simultaneously?</EM> Or is it simply a stupid thing to do?  We must
be clear about whether such collisions can be avoided, or whether they
are a necessary part of a program.  For instance, if two independent
processes want to add entries to a database, this is a reasonable
thing to do. If two unrelated processes want to write a log of
their activities to the same file, it is probably not sensible:
a better solution would be to use two separate files.

<P>
</LI>
<LI><EM>How should we handle a collision between processes?</EM> 
Should we signal an error, or try to make the processes wait in turn?
There is no universal answer to this question - in some cases it
might be logically incorrect for two processes to change data at the
same time: if two processes try to change one numerical value then one
of them has to win - which one?  On the other hand, if two processes
try to add something to a list, that makes sense, but we have to be
sure that they do not write their data on top of each other. The
writing must happen serially, not in parallel.

<P>
</LI>
</OL>
<P>

<H2><A NAME="SECTION00542000000000000000">
4.4.2 Serialization</A>
</H2>
<P>
<FONT SIZE="-2">The key idea in process synchronization is <EM>serialization</EM>. This means
that we have to go to some pains to <EM>undo</EM> the work we have put into
making an operating system perform several tasks in parallel. As we
mentioned, in the case of print queues, parallelism is not always
appropriate.<A NAME="1315"></A>
</FONT>
<P>
<FONT SIZE="-2">Synchronization is a large and difficult topic, so we shall only
undertake to describe the problem and some of the principles involved
here. 
</FONT>
<P>
<FONT SIZE="-2">There are essentially two strategies to
serializing processes in a multitasking environment.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The scheduler can be disabled 
for a short period of
time, to prevent control being given to another process during a 
critical action like modifying shared data. This method is very
inefficient on multiprocessor machines, since all other processors have
to be halted every time one wishes to execute a critical section.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A protocol can be introduced which all
programs sharing data must obey. The protocol ensures that processes
have to queue up to gain access to shared data. Processes which
ignore the protocol ignore it at their own peril (and the peril of
the remainder of the system!). This method works on multiprocessor
machines also, though it is more difficult to visualize.
</DD>
</DL>
<P>
<FONT SIZE="-2">The responsibility of serializing important operations
falls on programmers. The OS cannot impose any restrictions on silly
behaviour - it can only provide tools and mechanisms to assist the
solution of the problem.
</FONT>
<P>

<H2><A NAME="SECTION00543000000000000000">
4.4.3 Mutexes: mutual exclusion</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1321"></A>
<A NAME="1322"></A>
Another way of talking about serialization is to use the
concept of mutual exclusion. We are interested in allowing only
one process or thread access to shared data at any given time.
To serialize access to these shared data, we have to exclude
all processes except for one. Suppose two processes A and B are trying
to access shared data, then: if A is modifying the data, B must
be excluded from doing so; if B is modifying the data, A must be
excluded from doing so. This is called <EM>mutual exclusion</EM>.
</FONT>
<P>
<FONT SIZE="-2">Mutual exclusion can be achieved by a system of <EM>locks</EM>. A
mutual exclusion lock is colloquially called a <EM>mutex</EM>.
You can see an example of mutex locking in the multithreaded file
reader in the previous section. The idea is for each thread
or process to try to obtain locked-access to shared data:
</FONT>
<P>
<PRE>
Get_Mutex(m);

// Update shared data

Release_Mutex(m);
</PRE>
<P>
<FONT SIZE="-2">The mutex variable is shared by all parties (e.g. a global variable).
This protocol is meant to ensure that only one process at a time
can get past the function <code>Get_Mutex</code>. All other processes
or threads are made to wait at the function <code>Get_Mutex</code>
until that one process calls <code>Release_Mutex</code> to release
the lock. A method for implementing this is discussed below.
Mutexes are a central part of multithreaded programming.
</FONT>
<P>

<H2><A NAME="SECTION00544000000000000000">
4.4.4 User synchronization: file locks</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1329"></A>
A simple example of a protocol solution, to the locking problem
at the user level, is the so-called <EM>file-lock</EM> in
UNIX. When write-access is required to a file, we try to
obtain a lock by creating a <EM>lock-file</EM> with a special name. 
If another user or process has already obtained
a lock, then the file is already in use, and we are
denied permission to edit the file. If the file is free, a `lock'
is placed on the file by creating the file lock. This
indicates that the file now belongs to the
new user. When the user has finished, the file lock is deleted,
allowing others to use the file.
</FONT>
<P>
<FONT SIZE="-2">In most cases a lock is simply a text file. If we wanted to
edit a file <code>blurb</code>, the lock might be called
<code>blurb.lock</code> and contain the user identifier of the user currently
editing the file. If other users then try to access the file, they find
 that the lock file exists and are denied access. When the user is
finished with the file, the lock is removed.
</FONT>
<P>
<FONT SIZE="-2">The same method of locks can also be used to prevent two instances
of a program from starting up simultaneously. This is often used in
mail programs such as the ELM mailer in UNIX, since it would be unwise
to try to read and delete incoming mail with two instances of the mail 
program at the same time.
</FONT>
<P>
<FONT SIZE="-2">We can implement a lock very easily. Here is an example from UNIX
in which the lock file contains the <EM>process identifier</EM>. This is
useful because if something goes wrong and the editor crashes, the
lock will not be removed. It is then
possible to see that the process the lock referred to no longer exists
and the lock can be safely removed.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
//*********************************************************************
//
// Example of a program which uses a file lock to ensure
// that no one starts more than one copy of it.
//
//*********************************************************************

#include &lt;iostream.h&gt;
#include &lt;fstream.h&gt;

//**********************************************************************
// Include file
//**********************************************************************

extern "C" int getpid();
extern "C" void unlink(char *);

int Locked();
void RemoveLock();

const int true = 1;
const int false = 0;
const int exitstatus=1;

//**********************************************************************
// Main program
//**********************************************************************

main ()

{
if (Locked())
   {
   cout &lt;&lt; "This program is already running!\n";
   return exitstatus;
   }

 // Program here

RemoveLock();
}

//**********************************************************************
// Toolkit: locks
//**********************************************************************

Locked ()

{ ifstream lockfile;
  int pid;

lockfile.open("/tmp/lockfile",ios::in);

if (lockfile)
   {
   return true;
   }

lockfile.open("/tmp/lockfile",ios::out);

if (! lockfile)
   {
   cerr &lt;&lt; "Cannot secure a lock!\n";
   return true;
   }

pid = getpid();
lockfile.out &lt;&lt; pid;

lockfile.close();

return false;
}

//************************************************************************

void RemoveLock()

{
unlink("/tmp/lockfile");
}
</PRE><FONT SIZE="-2"></FONT>
<H2><A NAME="SECTION00545000000000000000">
4.4.5 Exclusive and non-exclusive locks</A>
</H2><FONT SIZE="-2">
To control both read and write access to files, we can use a system
of exclusive and non-exclusive locks.
</FONT>
<P>
<FONT SIZE="-2">If a user wishes to read a file, a non-exclusive lock is used. Other
users can also get non-exclusive locks to read the file simultaneously,
but when a non-exclusive lock is placed on a file, no user may write to it.
</FONT>
<P>
<FONT SIZE="-2">To write to a file, we must get an exclusive lock. When an exclusive
lock is obtained, no other users can read or write to the file.
</FONT>
<P>

<H2><A NAME="SECTION00546000000000000000">
4.4.6 Critical sections: the mutex solution</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1337"></A>
A critical section is a part of a program in which is it necessary to
have <EM>exclusive access</EM> to shared data. Only one process 
or thread may be in a critical section at any one time.
</FONT>
<P>
<FONT SIZE="-2">In the past it was possible to implement this is by generalizing the
idea of interrupt masks, as mentioned in chapter 2. By switching off
interrupts (or more appropriately, by switching off the scheduler) a
process can guarantee itself uninterrupted access to shared data.
This method has drawbacks: i) masking interrupts can be dangerous -
there is always the possibility that important interrupts will be
missed, ii) it is not general enough in a multiprocessor environment,
since interrupts will continue to be serviced by other processors -
so all processors would have to be switched off; iii) it is too
harsh. We only need to prevent two programs from being in their
critical sections simultaneously if they share the same data. Programs
A and B might share different data to programs C and D, so why should
they wait for C and D?
</FONT>
<P>
<FONT SIZE="-2">The modern way of implementing a critical section is to 
use mutexes as we have described above. In 1981 G.L. Peterson
discovered a simple algorithm for achieving mutual exclusion
between two processes with PID equal to 0 or 1. The code goes
like this:
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
int turn;
int interested[2];

void Get_Mutex (int pid)

{ int other;

other = 1 - pid;
interested[pid] = true;
turn = pid;

while (turn == pid &amp;&amp; interested[other])  // Loop until no one
   {                                      // else is interested
   }
}

void Release_Mutex (int pid)

{
interested[pid] = false;
}
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">Where more processes are involved, some modifications are necessary to
this algorithm. The key to serialization here is that, if a second
process tries to obtain the mutex, when another already has it, it
will get caught in a loop, which does not terminate until the other
process has released the mutex. This solution is said to involve <EM>busy waiting</EM>--i.e. the program actively executes an empty loop,
wasting CPU cycles, rather than moving the process out of the
scheduling queue. This is also called a <EM>spin lock</EM>, since the
system `spins' on the loop while waiting.<A NAME="1343"></A><A NAME="1344"></A>
</FONT>
<P>

<H2><A NAME="SECTION00547000000000000000">
4.4.7 Flags and semaphores</A>
</H2>
<P>
<FONT SIZE="-2">Flags are similar in concept to locks.
The idea is that two cooperating processes can synchronize their
execution by sending very simple messages to each other. A typical
behaviour is that one process decides to stop and <EM>wait</EM> until another
process <EM>signals</EM> that it has arrived at a certain place.<A NAME="1348"></A>
<A NAME="1349"></A>
</FONT>
<P>
<FONT SIZE="-2">For example, suppose we want to ensure that <code>procedure1()</code> in
process 1 gets executed before <code>procedure2()</code> in process 2. 
</FONT>
<P>
<PRE>
// Process 1                               // Process 2

   procedure1();                           wait(mysignal);
   signal(mysignal);                       procedure2();
   ...                                     ...
</PRE>
<P>
<FONT SIZE="-2">These operations are a special case of <EM>interprocess communication</EM>.
A semaphore is a flag which can have a more general value than just
true or false. A semaphore is an integer counting variable and is used to solve
problems where there is competition between processes. The idea is that
one part of a program tends to increment the semaphore while another part
tends to decrement the semaphore. The value of the flag variable dictates whether
a program will wait or continue, or whether something special will occur.
There are many uses for semaphores and we shall not go into them here.
A simple example is reading and writing via buffers, where we count
how many items are in the buffer. When the buffer becomes full, the process
which is filling it must be made to wait until space 
in the buffer is made available.
</FONT>
<P>

<H2><A NAME="SECTION00548000000000000000">
4.4.8 Monitors</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="1354"></A>
Some languages (like Modula) have special language class-environments for
dealing with mutual exclusion. Such an environment is called a monitor.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A monitor is a language-device which removes some
of the pain from synchronization. Only one process can be `inside' a
monitor at a time - users don't need to code this themselves, they
only have to create a monitor.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A procedure or function defined under the umbrella of a monitor can
only access those shared memory locations declared within that monitor
and vice-versa.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Wait and signal operations can be defined to
wait for specific condition variables. A process can thus wait until
another process sends a signal or semaphore which changes the
condition variable.
</DD>
</DL>
<P>

<H1><A NAME="SECTION00550000000000000000"></A>
<A NAME="1358"></A>
<BR>
4.5 Deadlock
</H1><FONT SIZE="-2">
Waiting and synchronization is not all sweetness and roses.
Consider the European road rule which says: on minor roads one should always
wait for traffic coming from the right. If four cars arrive simultaneously
at a crossroads (see figure) then, according to the rule all of them
must wait for each other and none of them can ever move. This situation
is called <EM>deadlock</EM>. It is the <EM>stale-mate</EM> of the operating
system world.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="1363"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 4.5:</STRONG>
Deadlock in the European suburbs.</CAPTION>
<TR><TD><IMG
 WIDTH="453" HEIGHT="368" BORDER="0"
 SRC="img22.png"
 ALT="\begin{figure}\psfig{file=figs/fig4.3.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00551000000000000000">
4.5.1 Cause</A>
</H2><FONT SIZE="-2">
Deadlock occurs when a number of processes are waiting for an event
which can only be caused by another of the waiting processes.
</FONT>
<P>
<FONT SIZE="-2">These are the essential requirements for a deadlock:
</FONT>
<OL>
<LI><EM>Circular waiting.</EM> There must be a set of processes <IMG
 WIDTH="53" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img23.png"
 ALT="$P_1..P_n$">
where <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img24.png"
 ALT="$P_1$"> is waiting for a resource or signal from <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$P_2$">, <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$P_2$"> is
waiting for <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img26.png"
 ALT="$P_3$"> ... and <IMG
 WIDTH="25" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img27.png"
 ALT="$P_n$"> is waiting for <IMG
 WIDTH="23" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img24.png"
 ALT="$P_1$">.

<P>
</LI>
<LI><EM>Non-sharable resources.</EM> It is not
possible to share the resources or signals which are
being waited for. If the resource can be shared, there is no reason
to wait.

<P>
</LI>
<LI><EM>No preemption.</EM> The processes can not be forced to give up the
resources they are holding.

<P>
</LI>
</OL>
<P>
<FONT SIZE="-2">There are likewise three methods for handling deadlock situations:
</FONT>
<P>

<OL>
<LI><EM>Prevention</EM>. We can try to design a protocol which ensures
that deadlock never occurs.

<P>
</LI>
<LI><EM>Recovery</EM>. We can allow the system to enter a deadlock state
and then recover.

<P>
</LI>
<LI><EM>Ostrich method.</EM> We can pretend that deadlocks will never occur
and live happily in our ignorance. This is the method used by most
operating systems. User programs are expected to behave properly.
The system does not interfere. This is understandable: it is very hard
to make general rules for every situation which might arise.
</LI>
</OL>
<P>

<H2><A NAME="SECTION00552000000000000000">
4.5.2 Prevention</A>
</H2>
<P>
<FONT SIZE="-2">Deadlock prevention requires a system overhead. 
<A NAME="1377"></A>
</FONT>
<P>
<FONT SIZE="-2">The simplest possibility for avoidance of deadlock is to introduce an
extra layer of software for requesting resources in addition to a
certain amount of accounting.  Each time a new request is made, the
system analyses the allocation of resources before granting or
refusing the resource. The same applies for <code>wait</code> conditions.
</FONT>
<P>
<FONT SIZE="-2">The problem with this approach is that, if a process is not permitted to
wait for another process - what should it do instead? At best the system
would have to reject or terminate programs which could enter deadlock, returning
an error condition.
</FONT>
<P>
<FONT SIZE="-2">Another method is the following. One might
demand that all programs declare what resources they will need in advance.
Similarly all wait conditions should be declared. The system could then
analyse (and re-analyse each time a new process arrives) the
resource allocation and pin-point possible problems.
</FONT>
<P>

<H2><A NAME="SECTION00553000000000000000">
4.5.3 Detection</A>
</H2>
<P>
<FONT SIZE="-2">The detection of deadlock conditions is also a system overhead. At regular
intervals the system is required to examine the state of all processes
and determine the interrelations between them. Since this is quite a
performance burden, it is not surprising that most systems ignore
deadlocks and expect users to write careful programs.
</FONT>
<P>

<H2><A NAME="SECTION00554000000000000000">
4.5.4 Recovery</A>
</H2>
<P>
<FONT SIZE="-2">To recover from a deadlock, the system must either terminate one of the
participants, and go on terminating them until the deadlock is
cured, or repossess the resources which are causing the deadlock from
some processes until the deadlock is cured. The latter method is somewhat
dangerous since it can lead to incorrect program execution. Processes
usually wait for a good reason, and any interruption of that reasoning
could lead to incorrect execution. Termination is a safer alternative.
</FONT>
<P>

<H1><A NAME="SECTION00560000000000000000">
4.6 Summary</A>
</H1>
<P>
<FONT SIZE="-2">In this chapter we have considered the creation and scheduling of
processes. Each process may be described by
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A process identifier.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A process control block which contains status information about the scheduled processes.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A private stack for that process.

<P>
</DD>
</DL><FONT SIZE="-2">
The scheduling of processes takes place by a variety of methods. The aim
is to maximize the use of CPU time and spread the load for the devices. 
</FONT>
<P>
<FONT SIZE="-2">Processes can be synchronized using <EM>semaphores</EM> or flags.
Protocol constructions such as <EM>critical sections</EM> and <EM>monitors</EM>
guarantee that shared data are not modified by more than one process
at a time. 
</FONT>
<P>
<FONT SIZE="-2">If a process has to wait for a condition which can never arise until it
has finished waiting, then a <EM>deadlock</EM> is said to arise. 
The cause of deadlock waiting is often a resource which cannot be shared.
Most
operating systems do not try to prevent deadlocks, but leave the problem
to user programs.
</FONT>
<P>

<H1><A NAME="SECTION00570000000000000000">
Exercises</A>
</H1>
<P>

<OL>
<LI>Explain the difference between a light weight process and a normal
process.
</LI>
<LI>What is meant by the <EM>critical section</EM> of a program?
</LI>
<LI>What is meant by deadlock?
</LI>
<LI>Explain why round-robin scheduling would not be appropriate for
managing a print-queue.
</LI>
<LI>Devise a combination of first-come-first-serve (FCFS) and shortest-job-first (SJF) scheduling which would be the `fairest' solution
to scheduling a print queue.

<P>
</LI>
</OL></FONT>
<H1><A NAME="SECTION00580000000000000000">
Project</A>
</H1><FONT SIZE="-2">
You can learn a lot by solving the following problem.  The idea is
to make a time-sharing system of your own.
</FONT>
<OL>
<LI>Make a fake kernel simulator which, instead of executing processes
in memory, reads instructions from a number of files. 
You should aim to
share the time spent reading each `process' equally between all tasks. The
output of your kernel should show clearly what is being executed and
when. You should give each process a process identifier (pid).
The `command language' you are reading in contains instructions like
`abcd 3', `wait 4' etc. i.e. four letters followed by a number.

<P>
</LI>
<LI>Add process priorities to each task. You can decide how these
are assigned yourself. Keep a record of how long each process
takes to complete and print status information when each
process finishes. You can either call the real system clock to do
this, or increment a counter each time an instruction is read.
This is like counting `fake CPU cycles'.

<P>
</LI>
<LI>The input files contain `<code>wait &lt;number&gt;</code>' instructions.
Modify your program so that when one of the tasks reads an
instruction `wait 5', for instance, it waits for process number 5
to finish before it continues. The output of the kernel should show
this clearly. Hint: use a status variable which indicates whether
the process is `ready' or `waiting'.

<P>
</LI>
<LI>Copy and modify the input files so that a deadlock can occur. 
Explain carefully how it occurs.
For example, make two processes wait for each other. Add to your kernel a simple
test to detect such deadlock situations. Decide for yourself how you
wish to handle this situation. Explain what you have chosen to do in
your solution.

<P>
</LI>
<LI>Some of the input files contain `fork' instructions. Modify
your code so that when such an instruction is detected, the
current process spawns a new copy of itself which begins executing
from the instruction after the fork command. The new process should
have a different pid and should have the same priority as the old one.

<P>
</LI>
</OL>
<P>
<FONT SIZE="-2">Try to make your program as structured as possible. The aim is to write
the clearest program, rather than the most efficient one.
When presenting your results, give a listing of the output of each
part and explain the main features briefly.
</FONT>
<P>

<P>
<FONT SIZE="-2"></FONT>
<P>

<H1><A NAME="SECTION00600000000000000000">
5. Memory and storage</A>
</H1>
<P>
<FONT SIZE="-2">Together with the CPU, the physical memory (RAM) is the most important
resource a computer has. The CPU chip has instructions to manipulate
data only directly in memory, so all arithemtic and logic operations must
take place in RAM.
</FONT>
<P>

<H1><A NAME="SECTION00610000000000000000"></A>
<A NAME="2330"></A>
<A NAME="2331"></A>
<BR>
5.1 Logical and Physical Memory
</H1>
<P>

<H2><A NAME="SECTION00611000000000000000">
5.1.1 Physical Address space</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2333"></A>
Every byte in the memory has an <EM>address</EM> which ranges from zero
up to a limit which is determined by the hardware (see below).
Although bytes are numbered from zero upward, not every address
is necessarily wired up to a memory chip. Some addresses may be 
reserved for
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Memory mapped I/O - individual registers belonging to
other chips and hardware devices.<A NAME="2337"></A>

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The interrupt vector - the CPU itself requires some
workspace. Usually the interrupt vector and sometimes the processor 
stack occupy fixed locations.<A NAME="2339"></A>

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The operating system itself. This takes up a fair chunk of
memory. On most microcomputers this is located in ROM. On multiuser 
systems upgrades are much more frequent and it is always loaded
from disk into RAM.

<P>
</DD>
</DL><FONT SIZE="-2"> 
</FONT>
<P>
<FONT SIZE="-2">The <EM>physical address space</EM> consists of every possible address to which 
memory chips are connected.
</FONT>
<P>

<H2><A NAME="SECTION00612000000000000000">
5.1.2 Word size</A>
</H2>
<P>
<FONT SIZE="-2">A <EM>word</EM> is a small unit of memory, normally just a few bytes. The size
of a word on any system is defined by the size of the registers in the CPU.
This determines both the amount of memory a system can address and the
way in which memory is used.<A NAME="2345"></A>
</FONT>
<P>
<FONT SIZE="-2">Up to about 1985, all CPUs had eight bit (1 byte) registers, except
for the program counter and address registers which were 16 bits. The
largest address which can be represented in a 16 bit number is
<IMG
 WIDTH="102" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img28.png"
 ALT="$2^{16}=65,535$"> or <IMG
 WIDTH="31" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img29.png"
 ALT="$64k$"> bytes, and so these machines could not handle
more memory than this. Similarly, since the accumulator and index
registers were all 8 bits wide, no more than one byte could be
manipulated at a time. (This is why bytes have a special status.)
</FONT>
<P>
<FONT SIZE="-2">After that came a number of 16 bit processors with larger program
counters. Nowadays most CPUs have 32 bit registers. The DEC alpha
machines, together with the OSF/1 operating system are based on 64 bit
technology. The possible address range and internal number
representations are enormous. 64 bit versions of other versions of
unix and NT are also starting to appear.
</FONT>
<P>

<H2><A NAME="SECTION00613000000000000000">
5.1.3 Paged RAM/ROM</A>
</H2>
<P>
<FONT SIZE="-2">The size of the physical address space is limited by the size of the
address registers in the CPU. On early machines this memory was soon
exceeded and it was necessary to resort to tricks to add more memory.
Since it was not possible to address any more than the limit, these
machines temporarily switched out one <EM>bank of memory</EM> with
another. The new memory bank used the same addresses as the old, but
only one could be accessed at a time. This operation is called <EM>paging</EM>.  A special hardware paging chip was used to switch between
banks, containing a register which could choose between <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$"> banks of
memory.<A NAME="2350"></A>
</FONT>
<P>
<FONT SIZE="-2">Paging has obvious disadvantages - not all memory can be used at once
and the method is seldom used nowadays since modern CPUs can address
much larger memory spaces.
As we shall see later, multi-user systems use <EM>paging to disk</EM>.
Instead of switching between hardware banks of memeory, they copy the
old contents to disk and reuse the memory which is already there
for something else.
</FONT>
<P>

<H2><A NAME="SECTION00614000000000000000">
5.1.4 Address binding - coexistence in memory</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2353"></A>
When a high level language program is compiled, it gets converted into
machine code. In machine code there are no procedure names, or
variable names. All references to data or program code are made by
specifying the <EM>address</EM> at which they are to be found. This
immediately begs the question: how do we know what the addresses will
be? How do we know where the program is going to be located in memory?
</FONT>
<P>
<FONT SIZE="-2">On microcomputers, this is very straightforward. A program is compiled
to run starting from some fixed address. The system defines a certain
range of addresses which can be used by user programs (See figure
2.1).  Whenever the program is loaded from disk, it is loaded into the
memory at the same address, so that all of the addresses referred to
in the program are correct every time.
</FONT>
<P>
<FONT SIZE="-2">A problem arises if the system supports several programs resident in
memory simultaneously. Then it is possible that the addresses coded
into one program will already be in use by another. In that case there
are three possible options
</FONT>
<OL>
<LI><EM>Demand</EM> that programs which can coexist be compiled to run at
different addresses. (This means that every program which is to be able
to coexist must know about every other!)
</LI>
<LI><EM>Relative addressing.</EM> Machine code uses addresses 
relative to the start address at which the program was loaded. 
The CPU must then add the start address to every relative address to get
the true address. <A NAME="2358"></A>
This incurs a performance penalty. Also, on some
microprocessors (e.g. intel 6502), the relative addressing instructions 
available are limited to fairly small relative ranges, due to the size
of the CPU registers.

<P>
</LI>
<LI><EM>Use address binding.</EM> Here the idea is that ``dummy" addresses
are used when code is generated. When a program is loaded in, the
true addresses are computed relative to the start of the program and
replaced before execution begins. This requires a special program called
a <EM>loader</EM>.<A NAME="2361"></A>

<P>
</LI>
</OL><FONT SIZE="-2">
Needless to say, it is the last of these methods which is used in
modern systems. It introduces an important distinction between <EM>logical</EM> and <EM>physical</EM> addresses. A user program writes only to
logical addresses, not knowing where the program will end up in the
physical address space. The addresses are converted to physical
addresses automatically.
</FONT>
<P>
<FONT SIZE="-2">Again there is a choice. When should this conversion take place?
</FONT>
<OL>
<LI>When the program is loaded into memory, once and for all?
</LI>
<LI>While the program is being executed?
</LI>
</OL><FONT SIZE="-2">
Initially it would seem that 1. is the better alternative, since 2
incurs a runtime overhead. In fact 2. is the more flexible option for
reasons which will become more apparent when we consider <EM>paging
to disk</EM>. By performing the distinction at runtime, we have the
freedom to completely reorganize the use of physical memory <EM>dynamically</EM> at any time. This freedom is very important in a
multitasking operating system where memory has to be shared
continually.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2371"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.1:</STRONG>
If a program hard codes addresses, there will be collisions
when we try to load a second program into memory. It is therefore
imporant to have a way of allocating addresses dynamically.</CAPTION>
<TR><TD><IMG
 WIDTH="454" HEIGHT="490" BORDER="0"
 SRC="img30.png"
 ALT="\begin{figure}\psfig{file=figs/fig5.10.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00615000000000000000">
5.1.5 Shared libraries</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2374"></A>
<A NAME="2375"></A> 
The concept of shared libraries lies somewhere in the grey zone between
compiling and linking of programs and memory binding. We introduce it
here for want of a better place. The advantages of shared libraries
should be clearly apparent by the end of this section. On windows
systems, shared libraries are called dynamically loaded libraries
or dll's.
</FONT>
<P>
<FONT SIZE="-2">On older systems, when you compile a program, the <EM>linker</EM>
attaches a copy of standard libraries to each program. Because of the
nature of the linker, the whole library has to be copied even though
perhaps only one function is required. Thus a simple program to print
``hello'' could be hundreds or thousands of kilobytes long!  This
wastes considerable amount of disk space, copying the same code for
every program.  When the program is loaded into memory, the whole
library is loaded too, so it is also a waste of RAM.
</FONT>
<P>
<FONT SIZE="-2">The solution is to use a <EM>run-time linker</EM>, which only loads the
shared library into RAM when one of the functions the library is
needed.  The advantages and disadvantages of this scheme are the
following.
</FONT>
<OL>
<LI>Considerable savings in disk space are made, because the standard
library code is never joined to the executable file which is stored on
disk, thus there is only one copy of the shared library on the system.

<P>
</LI>
<LI>A saving of RAM can also be made since the library, once loaded into
RAM can often be shared by several programs. See under <EM>segmentation</EM>
below.

<P>
</LI>
<LI>A performance penalty is transferred from
load-time to run-time, the first time a function is accessed: the
library must be loaded from disk during the execution of the
program. In the long run, this might be outweighed by the time it
would otherwise have taken to load the library for <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> programs, which
now can share it. Also, the amount of RAM needed to support <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$">
programs is now considerably less.
</LI>
</OL>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2383"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.2:</STRONG>
Statically linked files append the entire library to each
compiled program. With shared libraries we can save disk and memory
by linking a program dynamically with a single copy of the library.</CAPTION>
<TR><TD><IMG
 WIDTH="454" HEIGHT="386" BORDER="0"
 SRC="img31.png"
 ALT="\begin{figure}\psfig{file=figs/fig5.9.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00616000000000000000">
5.1.6 Runtime binding</A>
</H2>
<P>
<FONT SIZE="-2">Keeping physical and logical addresses completely separate introduces
a new level of abstraction to the memory concept. User programs know
only about logical addresses. Logical addresses are mapped into real
physical addresses, at some location which is completely transparent
to the user, by means of a conversion table. The conversion can be
assisted by hardware processors which are specially designed to deal
with address mapping. This is much faster than a purely software
solution (since the CPU itself must do the conversion work). The
conversion is, at any rate, performed by the system and the user need
know nothing about it.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2386"></A>
<A NAME="2387"></A>
The part of the system which performs the conversion (be it hardware
or software) is called the <EM>memory management unit</EM> (MMU).  The
conversion table of addresses is kept for each process in its process
control block (PCB) and mmust be downloaded into the MMU during
context switching (this is one reason why context switching is
expensive!).  Each logical address sent to the MMU is checked in the
following way:
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Does the logical address belong to the process? If not, 
generate an ownership error (often called a segmentation fault, as we shall see below). 
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Translate the logical address into a physical address.
</DD>
</DL><FONT SIZE="-2">
The ownership checking is performed at the logical level rather than
the physical level because we want to be able to use the physical
memory in the most general possible way. If we bind physical addresses
to a special user it means that we cannot later reorganize the
physical memory and part of the point of the exercise is lost. On the
other hand, if users are only bound to logical addresses, we can
fiddle as much as we like with the physical memory and the user will
never know.
</FONT>
<P>
<FONT SIZE="-2">One more question must be added to the above. 
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Are the data we want to access actually in the physical
memory? As we shall see later in this chapter, many systems (the most
immediate example of which is UNIX) allow paging to disk.
</DD>
</DL><FONT SIZE="-2">
We shall return to this in the next section.
</FONT>
<P>

<DIV ALIGN="CENTER"><FONT SIZE="-2"><EM>The conversion of logical addresses into physical</EM>
<BR><EM>addresses is familiar in many programming languages</EM>
<BR><EM>and is achieved by the use of </EM></FONT></DIV><FONT SIZE="-2">pointers</FONT>
<DIV ALIGN="CENTER"><FONT SIZE="-2"><EM>.</EM> 
<BR><EM>Instead of referring to data directly, one uses a</EM>
<BR><EM>pointer variable which holds the true address at which</EM>
<BR><EM>the data are kept. In machine language, the same scheme</EM>
<BR><EM>is called ``indirect addressing''.</EM>
<BR><EM>The difference between logical addresses and pointers</EM>
<BR><EM>is that all pointers are user objects, and thus pointers</EM>
<BR><EM>only point from one place in logical memory to another place</EM>
<BR><EM>in logical memory. The mapping from logical to physical is</EM>
<BR><EM>only visible to the designer of the system.</EM>
</FONT></DIV>
<P>
<FONT SIZE="-2"><B>How is the translation performed in practice?</B> To make the translation
of logical to phyical addresses practical, it is necessary to
<EM>coarse grain</EM> the memory. If every single byte-address were independently
converted, then two <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img32.png"
 ALT="$32$"> bit addresses would be required for each 
byte-address in the table and
the storage space for the conversion table would be seven times bigger
than the memory of the system!
</FONT>
<P>
<FONT SIZE="-2">To get around this problem, we have to break up the memory into
chunks of a certain size. Then we only need to map the start
address of each block, which is much cheaper if the blocks are
big enough. There are two schemes for coarse graining the memory
in this way:
</FONT>
<OL>
<LI><B>Give each process/task a fixed amount of workspace</B> (a fixed
size vector) which is estimated to be large enough to meet its needs.
Only the base address of the workspace and the size need to be stored
 i.e. the whole vector in logical memory is mapped into a corresponding
vector in physical memory. We don't know where it lies in the physical
memory, but the mapping is one-to-one.

<P>
The disadvantage with this scheme is that either too much or too little
memory might be allocated for the tasks. Moreover - if only a small
part of the program is actually required in practice, then a large
amount of memory is wasted and cannot be reused.

<P>
<A NAME="2414"></A> 
</LI>
<LI><B>Coarse grain or ``quantize'' the memory in smallish pieces, called</B>
<EM>pages</EM>. Each page is chosen to have the same fixed size
(generally 2-4kB on modern systems), given by some
power of <IMG
 WIDTH="13" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img33.png"
 ALT="$2$"> bits (this varies from system to system). The base address
of each page is then stored in the
conversion table (the length is known, since it is fixed). A unit of
logical memory is called a <EM>page</EM>, whereas a unit of physical
memory is called a <EM>frame</EM>. Apart from the difference in names, they
must of course have the same size.
</LI>
</OL><FONT SIZE="-2">
The second of these possibilities is an attractive propostion for a number
of reasons. By breaking up the memory into smaller pieces, we have
the possibility of reorganizing (reusing) each piece separately. Large
programs need not be entirely in memory if they are not needed. Also, if
two programs use the same code, they can share pages, so two logical
pages map into the same physical frame.
This is advantageous for <EM>shared-libraries</EM>.
</FONT>
<P>

<DIV ALIGN="CENTER"><FONT SIZE="-2"><B>Page numbers and addresses</B>
<BR>&nbsp;
<BR><EM>Page addressing is a simple matter if the size of one page is a</EM>
<BR><EM>power <IMG
 WIDTH="22" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img34.png"
 ALT="$2^n$">. Since addresses are stored in bits, page numbers can be</EM>
<BR><EM>assigned by simply throwing away the lower bits from every address.</EM>
<BR><EM>It is analogous to counting in blocks of a thousand, in regular base <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$10$">.</EM>
<BR><EM>To number blocks of size <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img36.png"
 ALT="$1000$"> in base 10, one simply has to</EM>
<BR><EM>drop the lowest three digits. Thus to store the mapping from</EM>
<BR><EM>logical to physical here, we must cover all addresses from <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="$0000$"></EM>
<BR><EM>to <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$9999$">. Without pages, this would require <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$9999$"> addresses.</EM>
<BR></FONT></DIV><FONT SIZE="-2">with paging</FONT>
<DIV ALIGN="CENTER"><FONT SIZE="-2"><EM> we need only <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$9$"> addresses, since <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img40.png"
 ALT="$7123$"> </EM>
<BR><EM>and <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img41.png"
 ALT="$7663$"> are both in page <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$7$">, for instance.</EM>
<BR></FONT></DIV>
<P>
<FONT SIZE="-2">An important consequence of the mapping of pages, is that what appears
to the user as <IMG
 WIDTH="55" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$10MB$"> of sequential memory may in reality be spread
in some random order just about anywhere in physical memory. The tables
which map logical to physical memory are called the <EM>page table</EM>
and the <EM>frame table</EM>, and are stored per process and loaded
as a part of context switching.<A NAME="2436"></A>
 <A NAME="2437"></A><A NAME="2438"></A>
</FONT>
<P>

<H2><A NAME="SECTION00617000000000000000">
5.1.7 Segmentation - sharing</A>
</H2>
<P>
<FONT SIZE="-2">From the point of view of the system: <EM>sharing</EM>, <EM>process management</EM>
and <EM>efficiency</EM>, it is highly convenient to view the memory for
different processes as being <EM>segmented</EM>.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2444"></A>
A <EM>segment</EM> is a convenient block of <EM>logical memory</EM> which is
assigned to a process when it is executed. The memory given to any
process is divided up into one or more segments which then belong to
that process.  The purpose of segments is to help the system
administrate the needs of all processes according to a simple
paradigm. Each segment of memory is administrated separately and all
of the checks on valid addressing are made on each segment. It is
therefore convenient to use separate segments for logically separate
parts of a program/process.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Code segment - program code
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Data segment - the program stack and dynamically allocated
data.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Arrays can conveniently be placed in a segment of their
own - that way, array bound-checking will be performed automatically
by the hardware of the system.
</DD>
</DL>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="3079"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.3:</STRONG>
The UNIX process model, showing the various segments used
by each process. The stack contains all local (automatic) variables
and the heap is allocated by <TT>malloc()</TT>.</CAPTION>
<TR><TD><IMG
 WIDTH="414" HEIGHT="547" BORDER="0"
 SRC="img44.png"
 ALT="\begin{figure}\psfig{file=figs/fig5.0.eps,width=10cm}\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">The segment idea can all be built on top of the page/frame concept above by
demanding that segments be a whole number of pages. That way, we retain
the advantages of the page system. Segmentation is an additional
overhead which relates to the sharing of logical memory between processes.
The page overhead relates to the mapping of logical to physical addresses.
</FONT>
<P>
<FONT SIZE="-2">Memory addressing with segments is like plotting points in a plane
with coordinates <IMG
 WIDTH="45" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img45.png"
 ALT="$(x,y)$">. Addresses are written <TT>(segment,offset)</TT>.
</FONT>
<P>

<H2><A NAME="SECTION00618000000000000000">
5.1.8 The malloc() function</A>
</H2><FONT SIZE="-2">
<A NAME="3080"></A>
The <IMG
 WIDTH="53" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img46.png"
 ALT="$C++$"> operator <TT>new</TT> which dynamically allocates memory
is a wrapper function for the C library function <TT>malloc()</TT>.
When we use <TT>new</TT>, the compiler translates this into a call
to <TT>malloc()</TT>.
As an example, let's ask what happens when we call the
function <code>malloc()</code>.
<code>malloc</code> is part of the
standard C library on any system, but we shall only be concerned 
with how it is implemented in BSD UNIX. 
The function is used to obtain a pointer to
(the address of) a block of memory <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> bytes long. For example,
</FONT><PRE>
pointer= malloc(n);
</PRE>
<P>
<FONT SIZE="-2">Since <code>malloc</code> is a user-level command, it obtains <EM>logical</EM>
memory for the caller. The acquisition of physical memory is
taken care or by the system on behalf of <code>malloc</code>, by
deeper level kernel commands. 
</FONT>
<P>
<FONT SIZE="-2">In order to obtain <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> bytes of memory, malloc must normally acquire
<EM>too much</EM> memory. This is because the smallest unit of memory
is a page. This when malloc is called, it checks to see if the
data segment of the current process has <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> free bytes. If the
space already exists within the pages already allocated to the
process, malloc uses this space and updates the free-memory list.
If there is not sufficient space, <code>malloc</code> makes a call to
the <code>brk()</code> function, which tries to extend the size of the
data segment. In most cases, not all the memory obtained is required.
The most extreme example would be the allocation of one <code>char</code>
variable (one single byte). Then the remainder of the page is free, and
is added to the free memory list. 
</FONT>
<P>
<FONT SIZE="-2">The next time <code>malloc</code> is
called, it tries to use the remainder of the last allocated page, or
any memory in the same segment which it allocated earlier, but 
has since been freed.
</FONT>
<P>
<FONT SIZE="-2">The fact that <code>malloc</code> divides up pages of logical memory is of
no consequence to the memory management system, since each process
maintains its own free memory list for the data segment. Since 
the segment always consists of a whole number of pages there is
no conflict with the page mapping algorithm.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2520"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.4:</STRONG>
Levels of mapping from user allocation to physical memory.</CAPTION>
<TR><TD><IMG
 WIDTH="537" HEIGHT="221" BORDER="0"
 SRC="img47.png"
 ALT="\begin{figure}\font\thinlinefont=cmr5
\mbox{\beginpicture
\setcoordinatesystem u...
...ectangle corners at 0.444 24.162 and 20.288 16.224
\endpicture}
\par\end{figure}"></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H2><A NAME="SECTION00619000000000000000">
5.1.9 Page size, fragmentation and alignment</A>
</H2>
<P>
<FONT SIZE="-2">The process of allocating memory is really only half the story of
memory management. We must also be able to <EM>de-allocate</EM> or
free memory. When memory is freed from a segment, it leaves a hole
of a certain size, which is added to the <EM>free-list</EM>. 
Eventually, the number of these holes grows quite large and the
memory is said to become <EM>fragmented</EM>. 
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2526"></A>
Fragmentation can lead to wasted resources. We would clearly like
to re-use freed memory as far as possible, but if the holes are not
big enough to fit the data we need to allocate then this is not
possible.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2527"></A>
Another technical problem which leads to fragmentation and 
wastage is <EM>alignment</EM>. Alignment is a technical problem
associated with the word-size and design of the CPU. Certain memory objects
(variables) have to be stored starting from a particular (usually
<EM>even</EM>) address. This is because the multiple-byte registers
of the CPU need to align their ``footprints'' to the addresses of
the memory. Or, by virtue of the word-size of the system, the
CPU regards the addresses as being effectively multiples of the
word-size. In order to meet this requirement, memory sometimes has
to be `padded' out with empty bytes - which are therefore wasted.
</FONT>
<P>
<FONT SIZE="-2">Fragmentation occurs at two levels:
</FONT>
 
<UL>
<LI><EM>Internal fragmentation.</EM> This is space wasted by <code>malloc</code>
in trying to fit data into a segment (logical memory).

<P>
</LI>
<LI><EM>External fragmentation.</EM>  This is space lying between segments
in the physical memory. (There are never holes between segments in logical
memory since we can always just renumber the logical addresses to remove 
them - they are not real anyway.)
</LI>
</UL><FONT SIZE="-2">
See the figure below.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="3095"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.5:</STRONG>
<EM>Fragmentation</EM> occurs because we allocate
memory in blocks of different sizes and then free the blocks.
Fragments are show as the white gaps
between allocated objects. 
Internal fragmentation happens
inside segments of logical memory when programs like <TT>malloc</TT>
divide up the segment space. External fragmentation occurs in
the mapping of logical segments to physical segments when there are
gaps between the segments in physical memory. External 
fragmentation is cured by only mapping <EM>pages</EM> as in figure 5.4.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">Note that external fragmentation is formally eliminated by the
page concept. With pages, every object in physical
memory is always the size of a page or frame, every hole
must also be the size of a page and thus one is guaranteed to be able
to fit a page block into a page hole. To some extent this is a cheat though,
because the problem is only transferred from external to 
internal fragmentation - but such is the nature of definitions.
</FONT>
<P>
<FONT SIZE="-2">Internal fragmentation can be minimized by choosing a smaller page size
for the system. That means that, on average, fewer bytes will be wasted
per page. Of course, the system overhead grows larger as the page size
is reduced, so as usual the size of pages is a tradeoff between two
competing requirements.
</FONT>
<P>
<FONT SIZE="-2">At the user level, it is possible to avoid of the
fragmentation problem when writing programs. For example, if a program
allocates and frees memory objects of random sizes, it will be a
random issue whether or not the holes left over can be used again.
If, on the other hand, a program only allocates memory in fixed size
structures (like C's <code>struct</code> and <code>union</code> variable types),
then every hole will be the same size as every new object created
and (as with pages) it will always be possible to fit new data into old
holes. This is a program design consideration. Unions were designed
for precisely this kind of purpose.
</FONT>
<P>

<H2><A NAME="SECTION006110000000000000000">
5.1.10 Reclaiming fragmented memory (Tetris!)</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2719"></A>
There are two strategies for reclaiming fragmented memory.
</FONT>
<OL>
<LI>Try to fit data into the holes that already exist.
</LI>
<LI>Reorganize the data so that all the holes are regrouped into
one large hole.
</LI>
</OL><FONT SIZE="-2">
The second alternative clearly represents a large system overhead
and is seldom used.
</FONT>
<P>
<FONT SIZE="-2">The first method can be implemented in one of three ways. Given a
<EM>free-list</EM> of available holes, one may choose a space on the
basis of
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>First fit.</B> Choose the first hole which will do.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Best fit.</B> Choose the smallest hole that will do.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Worst fit</B> Choose the largest hole (which in some screwy sense leaves the biggest remainder - for what it's worth).
</DD>
</DL><FONT SIZE="-2">
The first two are preferable, but neither works best in all cases. The
criterea are i) minimization of fragmentation and ii) minimization
of the allocation overhead. The first is perhaps preferable, since it
is fastest.
</FONT>
<P>

<H1><A NAME="SECTION00620000000000000000">
5.2 Virtual Memory</A>
</H1>
<P>

<H2><A NAME="SECTION00621000000000000000">
5.2.1 Paging and Swapping</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2730"></A>
<A NAME="2731"></A>
<A NAME="2732"></A> 
Virtual memory is a way of making the physical memory of a computer
system effectively larger than it really is. Rather than using mirrors,
the system does this by determining which parts of its memory are often
sitting idle, and then makes a command decision to empty their contents
onto a disk, thereby freeing up useful RAM.
</FONT>
<P>
<FONT SIZE="-2">As we noted earlier, it is quite seldom that every byte of every program
is in use all of the time. More often programs are large and contain
sections of code which are visited rarely if ever at all by the majority
of users - so if they are not used, why keep them in RAM?
</FONT>
<P>
<FONT SIZE="-2">Virtual memory uses two methods to free up RAM when needed.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Swapping.</B> An entire process, including code segment
and data segments is expunged from the system memory.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><B>Paging.</B> Only single pages are swapped out.
</DD>
</DL>
<P>
<FONT SIZE="-2">Of course, the simplest way to clear a space in RAM is to terminate some processes, but virtual memory is more subtle than that. The idea is to free RAM only temporarily, with the intention of copying the data back again
later. All of this should happen in such a way that the user of the system
do not realize that it is happening.
</FONT>
<P>
<FONT SIZE="-2">Swapping and paging dump the system memory in special disk caches. Normally
these disk areas are not part of the usual file system structure, since
the overhead of maintaining a file system is inapropriate when only the system needs to use the disk. Instead, the system stores swap files in large
contiguous blocks, sacrificing utilization of space for speed.
Some systems also allow swapping to a special
file in the normal filesystem, which has a reserved size.
</FONT>
<P>
<FONT SIZE="-2">In UNIX, there both methods are available. On BSD systems, normally a
whole disk partition (see next section) is reserved for swapping and
paging. (This is called the swap partition for historical reasons.)
If this fails to provide enough space, under SunOS
the system administrator can
either add other partitions, or use the <code>mkfile</code> command to
create a swap file on a normal in a part of the file system where
there is sufficient space. In the system 5 based HPUX operating
system, the normal swap area is invisible to the user.
Additional swap space can simply be grabbed from some part of the
filesystem, by the kernel, if the system goes short. Eventually
this can lead to a paradoxical situation in which the user sees
nothing on the disk, but the OS declares that the disk is full! 
</FONT>
<P>
<FONT SIZE="-2">Early versions of UNIX used swapping
exclusively when RAM was in short supply. Since BSD 4.3, all systems which
have learned something from the BSD project use paging as their main
method of virtual memory implementation.
</FONT>
<P>

<H2><A NAME="SECTION00622000000000000000"></A>
<A NAME="2738"></A>
<A NAME="2739"></A>
<BR>
5.2.2 Demand Paging - Lazy evaluation
</H2>
<P>
<FONT SIZE="-2">You might ask - if a program has a lot of pages which do not get
used, what is the purpose of loading them in the first place and then
swapping them out? One could simply make a rule that no page should be
brought into memory until it were needed. Such a scheme is possibile,
but few systems allow a program to run if it cannot be loaded fully
into memory on start-up. One argument against this extreme form of
paging is that, it could be dangerous to start a program which was
unable to complete because it was too large to run on the system,
under the conditions of the moment. If it started to run and then
crashed or exited, it could compromise important data. (The BSD UNIX
system allocates sufficient space in its swap area to swap or page out
each entire process as it begins. That way, none of them will ever run
out of swap during execution.)
</FONT>
<P>
<FONT SIZE="-2">On the other hand, if a program can be loaded in, it is most likely safe
- so if we then discover that large parts of the program are never used,
we can page them out and never bother to page them in again.
</FONT>
<P>
<FONT SIZE="-2">This is an example of what is called <EM>lazy evaluation</EM>. A lazy pager
never brings a page back into memory until is <EM>has to</EM> i.e.
until someone wants to use it. This can save a considerable amount of I/O
time. Another name for this is <EM>demand paging</EM>, since it only
occurs on demand from user processes.
</FONT>
<P>
<FONT SIZE="-2">It is now easy to see how the paging concept goes hand in hand with
the logical memory concept: each time the system pages out a frame
of physical memory, it sets a flag in the page table next to the
logical page that was removed. If a process attempts to read from that
page of logical memory the system first examines the flag to see if
the page is available and, if it is not, a <EM>page fault</EM>
occurs. <A NAME="2744"></A>
</FONT>
<P>
<FONT SIZE="-2">A page fault is a hardware or software interrupt (depending on
implementation) which passes control to the operating system. The OS
proceeds to locate the missing page in the swap area and move it
back into a free frame of physical memory. It then binds the addresses
by updating the paging table and, when control returns to the waiting
process, the missing page is automagically restored, as if it had never
been gone.
</FONT>
<P>
<FONT SIZE="-2">Notice, that the location of the physical frame is completely irrelevant to
the user process. A frame does not have to be moved back into the same 
place that it was removed from, because the runtime binding of addresses
takes care of its relocation.
</FONT>
<P>

<H2><A NAME="SECTION00623000000000000000"></A>
<A NAME="2746"></A>
<BR>
5.2.3 Swapping and paging algorithms
</H2>
<P>
<FONT SIZE="-2">How does the system decide what pages or processes to swap out? This is
another problem in scheduling. A multitude of schemes is available. 
Here we shall only consider some examples.
</FONT>
<P>
<FONT SIZE="-2">Consider the UNIX system a moment. Before paging was introduced, 
the only way that memory segments could increase their size was to
</FONT>
<OL>
<LI>Try to look for free memory at the end of the current segment
and add it to the current segment.
</LI>
<LI>Try to allocate a new, larger segment, copy the data to the new
segment and deallocate the old one.
</LI>
<LI>Swap out the process, reallocate and swap in again.
</LI>
</OL><FONT SIZE="-2">
In this use of swap space, it is clear that a process is swapped out
while it is waiting for a suitable hole in to appear in the memory.
This might take a long time and it might be immediate.
Another case for swapping out a job is if it has been idle (sleeping)
for a long time.
</FONT>
<P>
<FONT SIZE="-2">On a BSD-like UNIX system, the first three processes to be started are
) the swapper, <IMG
 WIDTH="13" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img33.png"
 ALT="$2$">) <code>init</code>, the and ) the pagedaemon. The
pagedaemon is responsible for examining the state of the page-table
and deciding which pages are to be moved to disk. Normally the swapper
will not swap out processes unless they have been sleeping for a long
time, because the pager will first strip them of their inactive
pages. It will begin to swap out processes however, if the average
load on the system is very high.  (The <EM>load average</EM> is a number
based on the kernel's own internal accounting and is supposed to
reflect the state of system activity.) This gives `cheap' processes a
chance to establish themselves.  It is the pagedameon which makes the
paging decisions. By copying read-only segments to the swap area at
load time, the running overhead of paging out read-only data is
removed, since the data are always where we need them in swap space
and never change. In modernized versions of UNIX, such as the Solaris
systems by Sun Microsystems, read only pages from the code segment are
thrown away when they are selected for swap out and then read in from
the filesystem if needed again. Moreover, data pages are only
allocated swap space when they are forced out of physical
memory. These optimizations reflect the fact that modern systems have
more physical memory than previously; also disks are getting faster.
</FONT>
<P>
<FONT SIZE="-2">Let us now look more generally at how paging decisions are made.
The most important aspect of paging is that pages can still be accessed
even though they are physically in secondary storage (the disk).
Suppose a page fault occurs and there are no free frames into which
the relevant data can be loaded. Then the OS must select a <EM>victim</EM>:
it must choose a frame and free it so that the new faulted page can
be read in. This is called (obviously) <EM>page replacement</EM>. The success or
failure of virtual memory rest on its abililty to make page replacement
decisions. Certain facts might influence these algorithms. For instance,
if a process is receiving I/O from a device, it would be foolish to
page it out - so it would probably <EM>I/O locked</EM> into RAM.
Here are some viable alternatives for page replacement.
</FONT>
<P>

<H3><A NAME="SECTION00623100000000000000">
5.2.3.1 FIFO - first in first out</A>
</H3>
<P>
<FONT SIZE="-2"><A NAME="2754"></A> 
Consider the figure below. Here we see the frames
in the physical memory of a paging system. The memory is rather small so that we can illustrate the principles of contention for pages most clearly.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="2807"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.6:</STRONG>
Illustration of the FIFO page replacement scheme.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2"> 
</FONT>
<P>
<FONT SIZE="-2">The simplest way of replacing frames is to keep track of their age
(by storing their age in the frame table). This could either be the
date, as recorded by the system clock, or a sequential counter.
When a new page fault occurs,
we can load in pages until the physical memory is full - thereafter, we
have to move out pages. The page which has been in memory longest is then
selected as the first to go.
</FONT>
<P>
<FONT SIZE="-2">This algorithm has the advantage of being very straightforward, but its
performance can suffer if a page is in heavy use for a long period of time.
Such a page would be selected even though it was still in heavy use.
</FONT>
<P>

<H3><A NAME="SECTION00623200000000000000">
5.2.3.2 Second chance</A>
</H3>
<P>
<FONT SIZE="-2"><A NAME="2810"></A>
A simple optimization we can add to the FIFO algorithm is the following.
Suppose we keep a reference bit for each page in the page table. Every
time the memory management unit accesses a page it sets that bit to .
When a page fault occurs, the page replacement algorithm looks at that
bit and - if it is set to  - sets the bit to <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$0$">
but jumps over it and looks for another page.
</FONT>
<P>
<FONT SIZE="-2">The idea is that pages which are frequently use will have their bits set
often and will therefore not get paged out. Of course, this testing
incurs an overhead. In the extreme case that all pages are in heavy use
the page algorithm must cycle through all the pages setting their bits
to zero before finding the original page again. Even then, it might not
find a page to replace, if the bit was set again while it was looking
through the others. In such a case, the paging system simply fails.
</FONT>
<P>

<H3><A NAME="SECTION00623300000000000000">
5.2.3.3 LRU - least recently used</A>
</H3>
<P>
<FONT SIZE="-2"><A NAME="2812"></A>
<A NAME="2813"></A>
The best possible solution to paging would be to replace the page that
will not be used for the longest period of time - but unfortunately,
the system has no way of knowing what that is. 
A kind of compromise solution is to replace the page which has not been
used for the longest period (see the figure below). This does not require a crystal ball, but
it does require some appropriate hardware support to make it worthwhile.
As with all good ideas, it costs the system quite a lot to implement it.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2875"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.7:</STRONG>
LRU page replacement algorithm. When there is a tie, the
algorithm uses FIFO.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">Two possibilities for such an implementation are the following.
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>We record the time
at which each page was last referenced. Unlike the FIFO scheme above, this
means that we have to update the time-stamp every single time memory is
referenced, instead of only each time a page is replaced. If the copying
operation takes, say, five CPU instructions (jump to update routine, locate page table entry,  load system clock time, store system clock time, return), this means - roughly
speaking - that the system is slowed down by a factor of around five. This
is an unacceptable loss, so unless the memory management unit can do something fancy in hardware, this scheme is not worth the system's time.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>We keep a stack of page addresses, so that the page number 
of the most recently accessed page is always on the top of the stack. 
Although this sounds cheaper in principle, since the page replacement 
algorithm never has to search for a replacement - it just looks on top of 
the stack - it still results in a large system overhead to maintain the 
stack. We must update a data stucture which requires <EM>process 
synchronization</EM> and therefore waiting. Again, without special hardware,
this is not economical.
</DD>
</DL><FONT SIZE="-2">
In practice, many systems use something like the second-chance algorithm
above. The UNIX <EM>pagedaemon</EM> uses this approach.
</FONT>
<P>

<H2><A NAME="SECTION00624000000000000000">
5.2.4 Thrashing</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2883"></A> 
Swapping and paging can lead to quite a large system overhead. Compared
to memory speeds, disk access is quite slow - and, in spite of optimized
disk access for the swap area, these operations delay the system
markedly. Consider the sequence of events which takes place
when a page fault occurs:
</FONT>
<OL>
<LI>Interrupt / trap and pass control to the system interrupt handler.
</LI>
<LI>Save the process control block.
</LI>
<LI>Determine cause of interrupt - a page fault.
</LI>
<LI>Consult MMU - is the logical address given inside the process' segment i.e. legal?
</LI>
<LI>Look for a free frame in the frame table. If none is found, free one.
</LI>
<LI>Schedule the disk operation to copy the required page and put the 
process into the waiting state.
</LI>
<LI>Interrupt from disk signals end of waiting.
</LI>
<LI>Update the page table and schedule the process for running.
</LI>
<LI>(On scheduling) restore the process control block and resume 
executing the instruction that was interrupted.
</LI>
</OL>
<P>
<FONT SIZE="-2">Such a sequence of operations could take of the order or milliseconds
under favourable conditions (although technology is rapidly reducing
the timescale for everything).  It is possible for the system to get
into a state where there are so many processes competing for limited
resources that it spends more time servicing page faults and swapping
in and out processes than it does executing the processes. This sorry
state is called <EM>thrashing</EM>.
</FONT>
<P>
<FONT SIZE="-2">Thrashing can occur when there are too many active processes for the
available memory. It can be alleviated in certain cases by making the
system page at an earlier threshold of memory usage than normal. In
most cases, the best way to recover from thrashing is to suspend
processes and forbid new ones, to try to clear some of the others by
allowing them to execute.  The interplay between swapping and paging
is important here too, since swapping effectively suspends jobs.
</FONT>
<P>

<H1><A NAME="SECTION00630000000000000000">
5.3 Disks: secondary storage</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="2888"></A>
The physical memory, as we have already seen, is not large enough to 
accomodate all of the needs of a computer system. Also, it is not
permanent. Secondary storage consists of disk units and tape drives
onto which data can be moved for more permanent storage. Apart from the
actual physical differences between tapes and disks, the principles
involved in controlling them are the same, so we shall only consider
disk management here.
</FONT>
<P>

<H2><A NAME="SECTION00631000000000000000">
5.3.1 Physical structure</A>
</H2>
<P>
<FONT SIZE="-2">Even disks come in different shapes and sizes. The most obvious distinction
is between floppy disks, diskettes and hard-disks. Floppy disks and 
diskettes consist of a single disk of magnetic material, while hard-disks
normally consist of several stacked on top of one another. Hard disks are
totally enclosed devices which are much more finely engineered and therefore
require protection from dust. A hard disk spins at a constant speed, while
the rotation of floppy drives is switched on and off. On the Macintosh
floppy drives have a variable speed operation, whereas most floppy drives
have only a single speed of rotation.
</FONT>
<P>
<FONT SIZE="-2">As hard drives and tape units become more efficient and cheaper to produce,
 the role of the floppy disk is diminishing. We look therefore mainly at hard drives.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="2892"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.8:</STRONG>
Hard disks and floppy disks.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">Looking at the figure, we see that a hard disk is composed of several
physical disks stacked on top of each other. A separate read <EM>head</EM> is provided for each <EM>surface</EM>. Although the disks are made
of continuous magnetic material, there is a limit to the <EM>density</EM>
of information which can be stored on the disk. The heads are
controlled by a <EM>stepper motor</EM> which moves them in fixed-distance
intervals across each surface.  i.e. there is a fixed number of <EM>tracks</EM> on each surface.  The tracks on all the surfaces are aligned,
and the sum of all the tracks at a fixed distance from the edge of the
disk is called a <EM>cylinder</EM>.<A NAME="2900"></A><A NAME="2901"></A>
<A NAME="2902"></A>
</FONT>
<P>
<FONT SIZE="-2">To make the disk access quicker, tracks are usually divided up into
<EM>sectors</EM> - or fixed size regions which lie along tracks. When
writing to a disk, data are written in units of a whole number of
sectors. (In this respect, they are similar to pages or frames in
physical memory.) On some disks, the sizes of sectors are decided by
the manufacturers in hardware. On other systems (often microcomputers)
it might be chosen in software when the disk is prepared for use (<EM>formatting</EM>). Normally sectors are 512 bytes, or half a kilobyte.
<A NAME="2905"></A><A NAME="2906"></A>
</FONT>
<P>
<FONT SIZE="-2">Because the heads of the disk move together
on all surfaces, we can increase read-write efficiency by allocating blocks
in parallel across all surfaces. Thus, if a file is stored in consecutive
blocks, on a disk with <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> surfaces and <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> heads, it could read <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$">
sectors  <EM>sectors-per-track</EM> without any head movement. 
</FONT>
<P>
<FONT SIZE="-2">When a disk is supplied by a manufacturer, the physical properties of
the disk (number of tracks, number of heads, sectors per track, speed
of revolution) are provided with the disk. An operating system must be
able to adjust to different types of disk. Clearly <EM>sectors per
track</EM> is not a constant, nor is necessarily the number of tracks.
The numbers given are just a convention used to work out a consistent
set of addresses on a disk and may not have anything to do with the
hard and fast physical limits of the disk.
</FONT>
<P>
<FONT SIZE="-2">To address any portion of a disk, we need a three component address
consisting of (<EM>surface, track, sector</EM>).
</FONT>
<P>

<H2><A NAME="SECTION00632000000000000000">
5.3.2 Device drivers and IDs</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2911"></A> 
A hard-disk is a <EM>device</EM>, and as such, an operating system must
use a <EM>device controller</EM> to talk to it. Some device controllers
are simple microprocessors which translate numerical addresses into
head motor movements, while others contain small decision making
computers of their own.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2914"></A>
The most popular type of drive for larger personal computers and
workstations is the SCSI drive.  SCSI (pronounced scuzzy) (Small
Computer System Interface) is a protocol and now exists in four
variants SCSI 1, SCSI 2, and fast SCSI 2, SCSI 3.  SCSI disks live on
a <EM>data bus</EM> which is a fast parallel data link to the CPU and
memory, rather like a very short network. Each drive coupled to the
bus identifies itself by a SCSI address () and each SCSI
controller can address up to seven units. If more disks are required,
a second controller must be added. SCSI is more efficient at multiple
access sharing than other disk types for microcomputers.
</FONT>
<P>
<FONT SIZE="-2">In order to talk to a SCSI disk, an operating system must have a SCSI
device driver. This is a layer of software which translates disk requests
from the operating system's abstract command-layer into the language of
signals which the SCSI controller understands. The operating system
generally provides two <EM>logical devices</EM> for each SCSI address:
a <EM>raw device</EM> and a <EM>buffered device</EM>. On BSD UNIX systems these
are referred to as <code>/dev/??</code> and <code>/dev/r??</code>.
</FONT>
<P>

<H2><A NAME="SECTION00633000000000000000">
5.3.3 Checking data consistency and formatting</A>
</H2>
<P>
<FONT SIZE="-2">Hard drives are not perfect: they develop defects due to magnetic dropout
and imperfect manufacturing. On more primitive disks, this is checked when
the disk is <EM>formatted</EM> and these damaged sectors are avoided.
If sector becomes damaged under operation, the structure of the disk
must be patched up by some repair program. Usually the data are lost.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2921"></A>
<A NAME="2922"></A> 
On more intelligent drives, like the SCSI drives, the disk itself keeps
a <EM>defect list</EM> which contains a list of all bad sectors. A new
disk from the manufacturer contains a starting list and this is updated
as time goes by if more defects occur.
</FONT>
<P>
<FONT SIZE="-2">Formatting is a process by which the sectors of the disk are 
</FONT>
<OL>
<LI>(if necessary) created by setting out `signposts' along the
tracks,
</LI>
<LI>labelled with an address, so that the disk controller knows when it
has found the correct sector. 
</LI>
</OL><FONT SIZE="-2"> 
On simple disks used by microcomputers, formatting is done manually. On
other types, like SCSI drives, there is a low-level formatting already
on the disk when it comes from the manufacturer. This is part of the
SCSI protocol, in a sense. High level formatting on top of this is not
necessary, since an advanced enough <EM>filesystem</EM> will be able to
manage the hardware sectors.<A NAME="2927"></A>
</FONT>
<P>
<FONT SIZE="-2"><EM>Data consistency</EM> is checked by writing to disk and reading back
the result. If there is disagreement, an error occurs. This procedure
can best be implemented inside the hardware of the disk - modern disk
drives are small computers in their own right. Another, cheaper way of
checking data consistency is to calculate a number for each sector,
based on what data are in the sector and store it in the sector.  When
the data are read back, the number is recalculated and if there is
disagreement then an error is signalled. This is called a <EM>cyclic
redundancy check</EM> (CRC) or <EM>error correcting
code</EM>.<A NAME="2931"></A><A NAME="2932"></A>
</FONT>
<P>
<FONT SIZE="-2">Some device controllers are intelligent enough to be able to detect
bad sectors and move data to a spare `good' sector if there is an error.
Disk design is still a subject of considerable research and disks are
improving both in speed and reliability by leaps and bounds.
</FONT>
<P>

<H2><A NAME="SECTION00634000000000000000">
5.3.4 Scheduling</A>
</H2><FONT SIZE="-2"> The disk is a resource which has to be
shared. It therefore has to be scheduled for use, according to some
kind of queue system. If a disk only had one customer at a time, a
<EM>first-come first-served</EM> FCFS policy would be adequate. However
- requests both to read and to write may come randomly from any user
process or from the system on a multitasking system and so we must
think carefully about how to service them.<A NAME="2936"></A><A NAME="2937"></A>
</FONT>
<P>
<FONT SIZE="-2">Since a disk is hardware, and involves <EM>mechanical movement</EM>, it
can literally be destroyed by asking it to do too much. One of the
aims of scheduling a disk device is to minimize wear on the disk surface.
Another aim is to maximize the speed of access. If the disk heads are
being asked to go backwards and forwards randomly many times a second,
much time can be lost. <EM>Floppy disks</EM> are particularly susceptible
to errors caused by misalignment between disk and disk head. The more
a hed moves rapidly backwards and forwards, the more likely it is to
miss its intended location and misread data. When this happens the data
have to be read again and the whole process takes much longer.
<A NAME="2940"></A>
</FONT>
<P>
<FONT SIZE="-2">Hard disks are more robust than floppies, but the algorithms for
scheduling the disk nevertheless take into account the physical issue
of movement.
</FONT>
<P>

<H3><A NAME="SECTION00634100000000000000">
5.3.4.1 FCFS</A>
</H3><FONT SIZE="-2">
As always, the simplest option for scheduling is the first-come first-serve
method. This can be thought of in two ways: i) that the first user to 
obtain the disk gets to use it uninterrupted until his or her file
access is finished, or ii) every individual disk access can be sheduled
on a FCFS basis.
On a busy system, ii) can lead to wild thrashing of the disk
heads as different processes first try to move them one way and then another. 
</FONT>
<P>
<FONT SIZE="-2"><A NAME="2942"></A>
The <EM>AmigaDOS</EM> system (at least up to 1.3) suffered from this
problem even if there were only two processes. The system tried to
time-share the disk which resulted in a more than fifty percent loss
in performance. The user could wait for minutes while the system tried
to thrash out a job which could have taken seconds if one job
had been allowed to complete first without interruption.
</FONT>
<P>

<H3><A NAME="SECTION00634200000000000000">
5.3.4.2 SSTF - Shortest seek time first</A>
</H3><FONT SIZE="-2">
To get the fastest response (ignoring mechanical restrictions)
we could try to sort disk requests according to those which will
cause the smallest movements of the disk head. Again, this does
not protect the head from direction reversals, only from large
movements. Also, like all priority scheduling, it could lead
to <EM>starvation</EM> of some requests.<A NAME="2946"></A><A NAME="2947"></A>
<A NAME="2948"></A>
</FONT>
<P>

<H3><A NAME="SECTION00634300000000000000"></A>
<A NAME="2950"></A>
<A NAME="2951"></A>
<A NAME="2952"></A>
<BR>
5.3.4.3 SCAN, C-SCAN and LOOK
</H3><FONT SIZE="-2">
The scanning method is to order requests so that we only move the
disk head in one direction at a time. Since the disk heads only
move if we need to change tracks, all requests are ordered according
to which track they lie on. The heads start at the first track and
move <EM>uni-directionally</EM> to the next request and then the next
etc. When they reach the inside of the disk, they reverse direction
and come back again. This is also called the <EM>elevator</EM> or
<EM>lift</EM> algorithm since this is the way many elevators are
scheduled.
</FONT>
<P>
<FONT SIZE="-2">The C-SCAN or circular scan is a slight variant:
when the heads hit the end track, they come immediately back to the
beginning and start again, so that they always move in the same
direction.
</FONT>
<P>
<FONT SIZE="-2">Of course, neither algorithm needs to go as far as the last track if
there are no requests for data there. The LOOK algorithm is the
same as SCAN or C-SCAN but does not move into areas of the disk
where no requests are waiting.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2958"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.9:</STRONG>
Scanning disk scheduling algorithms.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H3><A NAME="SECTION00634400000000000000">
5.3.4.4 Which method?</A>
</H3>
<P>
<FONT SIZE="-2">The choice of scheduling algorithm depends on the nature of disk usage.
For heavily use disks the SCAN / LOOK algorithms are well suited because
they take care of the hardware and access requests in a reasonable order.
There is no real danger of starvation, especially in the C-SCAN case.
</FONT>
<P>
<FONT SIZE="-2">The arrangement of data on a disk play an important role in deciding the
efficiency of data-retrieval. In the next section we shall look at the
high-level structures which the operating system places on top of sectors.
This determines the level at which we are most used to seeing the disk.
</FONT>
<P>

<H2><A NAME="SECTION00635000000000000000">
5.3.5 Partitions</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="2962"></A>
<A NAME="2963"></A>
For the purposes of isolating special areas of the disk, most operating
systems allow the disk surface to be divided into <EM>partitions</EM>.
A partition (also called a <EM>cylinder group</EM>) is just that: a group
a cylinders which lie next to each other. By defining partitions we
divide up the storage of data to special areas, for convenience.
</FONT>
<P>
<FONT SIZE="-2">For instance, it is quite normal to keep the system software in one
partition and user data in another partition. That way, when one makes
a back-up of the disk, user data can easily be kept separate from
system data. The separation becomes a hardware matter.
</FONT>
<P>
<FONT SIZE="-2">Partitions are supported on MS-DOS, Macintosh, BSD UNIX, AmigaDOS etc.
Remarkably there are versions of system 5 UNIX which do not support
partitions. BSD UNIX partitions are a good example, and since we are
focussing on UNIX we shall discuss its partitions in more detail.
</FONT>
<P>
<FONT SIZE="-2">BSD UNIX uses a special convention for the partitions on each disk.
Each disk may have up to eight logical partitions which are labelled
from <code>a</code> to <code>h</code>. 
<BR>
<BR>
</FONT>
<P>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT"><FONT SIZE="-2">
Partition </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Usage </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    a     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   root and boot partition </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    b     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   swap partition  </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    c     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   the whole disk  </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    d     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   anything </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    e     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   anything </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    f     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   anything </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    g     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   anything </FONT></TD>
</TR>
<TR><TD ALIGN="LEFT"><FONT SIZE="-2"> 
    h     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2">   anything </FONT></TD>
</TR>
</TABLE><FONT SIZE="-2">
<BR>
<BR>
</FONT>
<P>
<FONT SIZE="-2">Each partition is assigned a separate logical device and each
device can only write to the cylinders which are defined as
being its own. Partitions can overlap, because they are just limits.
Thus, if we read from logical device c, which is defined as the whole
disk, we could, in principle read from the whole disk, whereas
if we use logical device b we may only read from the swap partition.
</FONT>
<P>
<FONT SIZE="-2">To use a partition we have to <EM>create a filesystem</EM> on it. This
involves reserving space workspace for the operating system and suitable
markers for navigating over the surface of the disk..
Since partitions are defined for convenience, it does not matter that
they overlap. What is important is that the <EM>filesystems on two
partitions do not overlap!</EM> This is extremely important. If two filesystems
overlap, they will destroy each other!
</FONT>
<P>
<FONT SIZE="-2">In BSD UNIX, partitions are created by editing a table which is downloaded
into the device driver. In Sun's SunOS and Solaris operating systems,
a special command <code>format</code> is used to make partitions.
The <code>newfs</code> command is used to create a filesystem.
</FONT>
<P>
<FONT SIZE="-2">Once a partition has been created, it has to be <EM>mounted</EM> in order to
be reachable from the directory structure of the filesystem. The mount action is analagous to the opening of a file. On the Macintosh and Amiga
operating systems, new disks are immediately sensed by the system and
are mounted. In the Macintosh case (which has only a pictoral graphic user
interface) new partitions or disks are mounted on the desktop at the
root level. Under AmigaDOS, each new partition becomes a logical device
and is given a logical device name which identifies the disk. If the Workbench (graphical user interface) is running, the disks appear together
with their device names on the workbench in the same way as the Macintosh.
Otherwise they appear in the <EM>mountlist</EM>.
</FONT>
<P>
<FONT SIZE="-2">In UNIX a partition is mounted using the command <code>mount</code>. For example
a command like
</FONT><PRE>
mount /dev/sd0g  /user-data
</PRE><FONT SIZE="-2">
would mount partition g on disk number zero onto the directory <code>/user-data</code>. The result would be that all files on that partition would appear
under the directory <code>/user-data</code>. A prerequisite for mounting
a UNIX partition is that the partition must contain a filesystem.
</FONT>
<P>

<H2><A NAME="SECTION00636000000000000000">
5.3.6 Stripes</A>
</H2>
<P>
<FONT SIZE="-2">In recent years some UNIX systems (particularly Hewlett Packard) have 
experimented with <EM>disk striping</EM>. Disk striping is a way of
increasing the disk transfer rate up to a factor of <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$">, by splitting
files across <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$"> different disks. Instead of saving all the data from
a given file on one disk, it is split across many. Since the <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$">
heads can now search independently, the speed of transfer is, in principle,
increased manifold. The disadvantage with disk striping is that, if
one of the <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$"> disks becomes damaged, then the data on all <IMG
 WIDTH="20" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$N$"> disks
is lost. Thus striping needs to be combined with a reliable form of backup
in order to be successful.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="2981"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.10:</STRONG>
Disk striping: files are spread in parallel over several disks.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H1><A NAME="SECTION00640000000000000000">
5.4 Disk Filesystems</A>
</H1>
<P>
<FONT SIZE="-2">A filesystem is a high level interface to the disk, which allows users
of a system to give names to files, organize files in directories and 
separate off special areas using partitions. A filesystem is said
to be <EM>created</EM> on a disk by running a special program. On many systems
this is identified with <EM>formatting</EM> the disk and involves writing
address data to the surface as well as reserving system workspace on the disk.
</FONT>
<P>

<H2><A NAME="SECTION00641000000000000000">
5.4.1 Hierachical filesystems and links</A>
</H2>
<P>
<FONT SIZE="-2">The most popular type of filesystem interface is the hierachical one.
Earlier operating systems like MTS did not have a directory structure.
Each user had a separate login area, but the login area was not able to
hold subdirectories.
<A NAME="2987"></A> 
The hierachical file structure is a very convenient way of organizing data
in directories, sub-directories and so on. But this rigid preoccupation
with a hierachical ordering is not always the most appropriate one.
</FONT>
<P>
<FONT SIZE="-2">Look at the diagram below.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="3104"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.11:</STRONG>
<EM>Links - deviations from a strict hierachical filesystem.</EM>
<TT>/usr/local/bin/prog.exe</TT> is a link to <TT>/usr/local/mysoftware/prog.exe</TT>
and <TT>/local</TT> is a link to <TT>/usr/local</TT></CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">Suppose are in the directory <code>/usr/local/mysoftware</code>, which
contains a complete package of software that we have obtained in all of its
sub-directories. Since the package is a unit, we would like to keep
all of its files together and preserve that unity - but it might also
be necessary for some of the files in the package to be installed in
special places, elsewhere in the file tree. For example, the executable
binaries might have to be placed in <code>/usr/local/bin</code>, and some
configuration files for the system might have to be placed in a special
directory where the operating system can find them. 
</FONT>
<P>
<FONT SIZE="-2">The conflict of interest can be solved by introducing <EM>links</EM>. Links
are objects which appear in the file system and look just like files.
In fact they are pointers to other files which are elsewhere in the strict
hierarchy. Links enable one file to appear to exist at two or more
places at the same time. A link is not a copy of a file,
<EM>it is an alias for the true route to the file through the hierachical system</EM>, but for all intents and purposes it looks like another
instantiation of the file.
The Macintosh filesystem refers to such links as `aliases'.
</FONT>
<P>
<FONT SIZE="-2">The UNIX file system makes a distionction between <EM>hard links</EM>
and <EM>symbolic links</EM>. A symbolic links is literally just a small
file which contains the name of the true file. We can create a symbolic
link to a file which does not exist, and delete the file to which a
symbolic link points. A hard link is more permanent however. In order
to delete a file with hard links, all of the hard links must be removed.
This requires a list of links to be associated with each file.
The special files `.' and `..' are hard links to their parent directories.
</FONT>
<P>
<FONT SIZE="-2">When links jump across different branches of the file tree, the directory
structure is sometimes called an <EM>acyclic graph</EM>.
</FONT>
<P>

<H2><A NAME="SECTION00642000000000000000">
5.4.2 File types and device nodes</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="3002"></A>
<A NAME="3003"></A> 
Extremely elaborate filesystem interfaces can be made, which distinguish
between different types of file and which permit or disallow certain
operations on the basis of file type. The Macintosh operating system
determines whether files are executable or text files. Clicking on
an executable file loads and runs the program, whilst clicking on an
application file loads the application which created it and then tells the
program to load that file.
</FONT>
<P>
<FONT SIZE="-2">MS-DOS distinguishes file types by using <EM>filename extensions</EM>
like .EXE, .COM, .TXT for executable files, relocatable executables and textfiles.
</FONT>
<P>
<FONT SIZE="-2">The UNIX system does not make any particular distinction on the basis
of filenames. Instead it keeps a flag to say whether a file is executable
or not. If a file is not marked as executable, UNIX will not try to run it.
If it <EM>is</EM> marked executable, it will try to execute the file.
If the file is not a valid binary
program, it will fail. Executable binary files must conform 
to a certain protocol
structure which identifies them to the operating system as being fit
for execution. If a text file is marked executable, UNIX will try to
pass the lines of the file to the <EM>command line interpreter</EM>
or <EM>shell</EM>.
</FONT>
<P>
<FONT SIZE="-2">Certain files in the UNIX operating system are not really files at
all but `handles' to devices. They are called <EM>device nodes</EM>.
A device node is a way `into' a device through a filesystem
interface. It is convenient to be able to use normal filing
commands to access devices. Not all devices can be accessed in this
way, but the interface is useful for those that can. 
In the Solaris 2 operating system, the kernel process list is
represented as such a directory of pseudo-files. 
</FONT>
<P>
<FONT SIZE="-2">For user convenience, the <code>file</code> command attempts to guess the
contents of UNIX files, but this is not used by the system.
</FONT>
<P>

<H2><A NAME="SECTION00643000000000000000">
5.4.3 Permissions and access</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="3010"></A>
<A NAME="3011"></A>
On multi-user systems we must have a mechanism to prevent one user
from freely modifying the files of another user - while at the same
time, keeping enough flexibility to enable groups of users to share
certain files. It is also advantaegous to be able to lock files so
that they cannot be deleted - even by their owner.  This is normally
done by giving files <EM>permissions</EM> or <EM>protection</EM> bits.
</FONT>
<P>
<FONT SIZE="-2">Files must be <EM>readable</EM> and or <EM>writable</EM> only to very
specific users. In some operating system, like the Apollo Domain OS
and the Andrew file system, there are very intricate schemes for
protecting files, consisting of lists of users who are allowed or
disallowed access to them. Here we shall briefly sketch out the simple
system used by UNIX as an example.
</FONT>
<P>
<FONT SIZE="-2">Each file has one <EM>owner</EM> and belongs to one <EM>group</EM>. The owner
of the file is the only one (apart from the system administrator) 
who can decide whether others can read or write to
the file and to which group it belongs. 
If the owner wishes, he or she may open the file for
reading or writing to i) the other members of the group to which the
file belongs, or ii) anyone. Since only the system administrator
can add users to a group, the file is secure, provided the user
sets the correct protection bits. 
</FONT>
<P>
<FONT SIZE="-2">When a new file is created by a given user, that user is automatically
the owner of the file. The group ownership is determined differently
for BSD and system 5 UNIX. In BSD, the group is normally set to a
default group for that user, called the <EM>login group</EM>. In system
5, the file inherits the group ownership from the directory it is
created in. (This can also be arranged in BSD by setting
the `sticky bit'.)
</FONT>
<P>
<FONT SIZE="-2"><A NAME="3019"></A>
<A NAME="3020"></A>
More modern UNIX systems and other operating systems now provide
<EM>access control lists</EM> or ACLs. This generalizes the notion of
file owner and group by allowing a file to be accessible to a named
list of users and a named list of groups, rather than just a single
user or a single group. ACLs were first introduced in the DOMAIN
operating system by Apollo and were later adopted by HPUX and then
Solaris. Novell systems (based on Apollo NCS) also provide ACLs.
Modern filesystems like NFS 3, AFS and DFS also provide ACL support,
but there is currently no standard implementation and the different
systems are not compatible.
</FONT>
<P>

<H2><A NAME="SECTION00644000000000000000">
5.4.4 File system protocols</A>
</H2>
<P>
<FONT SIZE="-2">To read or write to a file, all operating systems require that users
formally <EM>open</EM> the file. When finished, they must <EM>close</EM> the
file. This formal procedure has several purposes. It allows us to
</FONT>
<OL>
<LI>see whether the file is inaccessible, because we do not have permission to open it.
</LI>
<LI>see whether the file is inaccessible because it is being used by another user. 
When we open a file for writing, a lock is placed on
the file to prevent others from writing to it simultaneously. This
lock is removed by the <code>close</code> operation.
</LI>
<LI>obtain pointers to where the file exists physically within the
secondary storage and set up a data structure called a <EM>filehandle</EM>
which the system will use to describe the state of the file as we use it.
</LI>
<LI>set up any cached data which might be used by the OS.
</LI>
</OL>
<P>
<FONT SIZE="-2">Once a file is open, the system must present the user with a consistent
picture of the filesystem. When a user program reads lines from a file,
a pointer should be advanced so that every line is read exactly once.
An <EM>end of file</EM> condition should be signalled when the
file is read (this is usually achieved by storing an <code>EOF</code> character
at the end of the file) etc. These are all aspects of an agreed protocol
defined by the filesystem.
</FONT>
<P>
<FONT SIZE="-2">A more complex situation is the following. Suppose one user is reading a
file and another user wants to write to it.
</FONT>
<OL>
<LI>Should the user be allowed to write to the file while someone is reading it?
</LI>
<LI>If so, should the user be able to see the changes made to the file
until after they have closed it?
</LI>
</OL><FONT SIZE="-2">
There are two possibilities - either all users see changes
immediately, or only users opening files after the changes were made
see the changes. Both versions of this are in use by different
filesystem implementations. In the latter case, the OS has to keep
several copies of the file until all file handles are released and
everyone agrees about the contents of the file.
</FONT>
<P>
<FONT SIZE="-2">It is difficult to say that one or the other type of behaviour is
more correct. This is largely a subjective issue. What is important is that
the filesystem defines its behaviour and sticks to it consistently.
The behaviour of the filesystem is often called <EM>filesystem semantics</EM>.
</FONT>
<P>

<H2><A NAME="SECTION00645000000000000000">
5.4.5 Filesystem implementation and storage</A>
</H2>
<P>
<FONT SIZE="-2">Although a sector is the smallest unit of allocation for the physical
disk, most filesystems create logical structures on top of sectors in
order to optimize disk access.  These are called <EM>blocks</EM>. A block
can in principle be any size. Usually they are from 512 bytes (the
same size as a sector) up to 8k. The larger the block size, the more
efficient file transfers will be.<A NAME="3034"></A><A NAME="3035"></A>
</FONT>
<P>
<FONT SIZE="-2">If we want to save a file which is only three bytes long,
we normally have to allocate a whole block and
the remainder of the block is wasted. Some systems, notably
BSD UNIX's ufs filesystem, from release 4.2, solve this
problem by using two block sizes: major blocks and fragments.
A file is allocated in large blocks except for the last one
which is allocated as a fragment. Typical sizes for large
blocks are 4kB to 8kB, and a typical size for fragments is from
512 bytes to 1kB (eighths).
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="3038"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.12:</STRONG>
Blocks and fragments</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">We must now address the issue of how the blocks are allocated. This
is the analogous problem to that of memory allocation in RAM.
The principal difference is that disk memory is considerably larger
than primary memory, so problems can be encountered in addressing
all of the blocks on the disk. We shall briefly mention some
general strategies below - and then look more closely at the UNIX
ufs filesystem.
</FONT>
<P>
<FONT SIZE="-2">To use the space on a disk, we must make a choice about whether we wish
files to be stored <EM>contiguously</EM>, or whether we wish to use a scheme
of logical and physical addresses, as we did in primary memory
and allow files to be spread liberally any on the disk. The problem
with contiguous allocation is, of course, fragmentation. We have
a much better chance of being able to fit files into the spaces
om a disk if we can allocate space in small blocks. On the other hand,
we know that large blocks are more efficient, since we can read or
write a file in fewer operations in the block size is large.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="3041"></A>
Contiguous allocation is seldom used (except in the swap area)
for filesystems because of the fragmentation problem. Instead
files are divided up into blocks and each file consists of a list
of blocks which may be scattered anywhere on the disk. Our problem
is then to identify files amongst all of the blocks. There are
three ways of doing this:
</FONT>
<OL>
<LI><B>Linked lists.</B> Each block of data includes a pointer to
the next block of data in a linked list. The difficulty with this
method is that each block must be read in the correct order and
the blocks might be spread randomly over the disk. Thus the retrieval
of a file could require a lot of disk head movement which is slow.

<P>
</LI>
<LI><B>Linked table.</B> A linked list of blocks for each file is
stored in a <EM>file allocation table</EM>. All of the pointers for every file
are collected together in one place. This table could also be cached
in RAM for faster access. This method is used by MS-DOS and a number
of other microcomputer operating systems.

<P>
</LI>
<LI><B>Indexing.</B> Each file has an index containing a list of blocks
which contain the file itself. This index might be stored anywhere in
principle. Space for it is normally allocated on the disk itself,
inside reserved disk blocks, and partly inside an index table 
which is built when the filesystem is created.  The index
blocks are grouped in one place for convenient access.  This system is
used in UNIX. Since the index table must contain pointers to disk
blocks, a way of storing the pointers must be found. If the list is
small and is held in a filesystem block, then most of the block will
be wasted. This is a drawback of the index method, but the main
advantage of this method is that it has few limitations.
</LI>
</OL>
<P>

<H2><A NAME="SECTION00646000000000000000">
5.4.6 The UNIX <EM>ufs</EM> filesystem</A>
</H2>
<P>
<FONT SIZE="-2">A file system under UNIX is created using the <code>newfs</code> command.  A
separate filesystem must be created on each separate partition of the
disk. To define a filesysytem we have to define the blocksize and
numerous other parameters. Each system has its own defaults which
inexperienced users - and most often experienced users are wise to
use.<A NAME="3049"></A>
</FONT>
<P>
<FONT SIZE="-2">Two structures are created when a file system is created: <EM>inodes</EM>
and <EM>superblocks</EM>. These are the most important objects in the
filesystem. Both of these objects are information structures, in the
sense of the C language and they are defined under the <code>/usr/include/ufs</code> directory in files <code>fs.h</code> and
<code>inode.h</code>. It is instructive to look at these files. This is where
the default blocksize etc will be defined on your system!
</FONT>
<P>
<FONT SIZE="-2">The blocksize is variable, but a minimum block size of  bytes
i.e. 4kB is stipulated so that the system can address 
bytes of memory without using three level indirection (see below).
Also, the last block of a file can be allocated as a fragment
of a block whose size is recorded in the inode. (It might be
a half, a quarter or an eighth of a block.)
</FONT>
<P>
<FONT SIZE="-2">A <EM>superblock</EM> contains the information on the boundaries of the
partition (cylinder groups) and information about where the <EM>inode</EM>
table is and where datablocks start. If the superblock is lost or
damaged, the whole filesystem would be unreadable. It is so important
that, when a file system is created, superblock backups are made at regular
intervals throughout a partition. Thus if one block is detroyed, another
can be used to repair the damage. The UNIX filesystem check program
<code>fsck</code> can do this. <code>fsck</code> is run automatically on every boot
of the system in case the system went down uncleanly. (UNIX uses
buffered and cached I/O so data are not always written to the filesystem
immediately. The program <code>sync</code> is run the the OS at regular intervals
in order to synchronize the disk structure with the present state of the
cache. If the system crashes or goes down without synchronizing the
filesystems, the superblock will be invalid and will have to be repaired.)
</FONT>
<P>
<FONT SIZE="-2">Partition `a'on disk zero is special. This is the default boot device.
On power up, the boot program (in ROM) looks to the first few sectors
of this partition for a boot block. Sectors  contain the
boot-block. Sector 16 marks the start of the superblock.
</FONT>
<P>
<FONT SIZE="-2">An <EM>inode</EM> or index node is the data structure which holds the specific
data about a particular file. Regardless of how large a file is, there is
exactly one inode per file. The elements of an inode are drawn in the
figure below.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="3060"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.13:</STRONG>
UNIX inodes.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">When file system is created, it creates a fixed number of inodes. It is
not possible to create more files on the system than the number of inodes,
so a limit is built into each file system. Usually the limit is no problem
in practice - and anyway, it can always be changed by changing the
parameters given to <code>newfs</code>. 
</FONT>
<P>
<FONT SIZE="-2">Inodes which are not in use, are kept in a doubly linked list called
the free-list. Filenames are stored in a directory structure, not
in the inodes themselves, with pointers to the appropriate inodes for
the start of the file. Each inode contains a plethora of information
about the file: the device on which the file resides, the type of file
and its protection bits, the user id and group id of the owner,
timestamps indicating the last time the file was written to etc, 
the size of the file and of course pointers to the actual blocks
of data.
</FONT>
<P>
<FONT SIZE="-2">Data blocks are (of course) addressed by indexing. As an attempt
at optimizing the index, inodes use three separate ways of addressing
data on the disk (in fact four different ways are built in to the
inodes, but only three are used). The inode contains a list of twelve
32bit pointers to blocks on the disk. For small files this would be
enough. Since the minimum blocksize is kB these pointers can address
up to  bytes i.e. kB.
</FONT>
<P>
<FONT SIZE="-2">For larger files, a system of <EM>indirect addressing</EM> is used. There are three
levels of indirect addressing, though only two are used currently.
In single-indirect addressing, the inode has a pointer which points
to a file block (not another inode). This file block has room for 4kB 
at least. Those 4kb are used to store a sequential array of 32bit
pointers to other data-blocks which contain the true data. Using
this method, we have space for  four-byte pointers in the
address block - and each pointer can point to  bytes (4kB),
thus we have space for <!-- MATH
 $4096 / 4 \times 4096 = 4194304$
 -->
 bytes per file.
This must then be added to the 48kB of direct pointers.
</FONT>
<P>
<FONT SIZE="-2">In double-indirect addressing, the inode pointer points to a block
of pointers (as before), but now these pointers point to blocks
which also contain pointers - i.e. the pointers to the real data.
The total space accessible per file is now multiplied by 
- i.e. the number of 32 bit pointers which will fit into the
minimum block size, since every fourth byte of the single-indirect
memory above now forms a pointer to a block of 4kB. The total
size is  bytes, which is roughly 4 giga-bytes.
This should, again, be added to the single-indirect and direct
memory above.
</FONT>
<P>
<FONT SIZE="-2">Although the inodes can span an address space which is larger than 
bytes, internal pointers in the file structures are still <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img32.png"
 ALT="$32$"> bit
(except in OSF/1) and so a limitation to  bytes is imposed by the
word size of the system hardware.
</FONT>
<P>

<H1><A NAME="SECTION00650000000000000000">
Exercises</A>
</H1>
<P>

<OL>
<LI>Go back and think about shared libraries, in view of what you
have learned about logical, physical and virtual memory. What are
the advantages and disadvanteges of shared libraries?

<P>
</LI>
<LI>Write programs to code the page replacement algorithms discussed
in above.

<P>
</LI>
</OL>
<P>

<H1><A NAME="SECTION00660000000000000000">
Project</A>
</H1>
<P>
<FONT SIZE="-2">Write a program to model the behaviour of a hard disk.
A disk drive contains a stepper motor which pushes the head one
track at a time. You can model the tracks 
and segments of the disk as an array.
</FONT><PRE>
const int tracks = 20;
const int sectors_per_track = 20;
const int heads = 2;
const int bytes_per_sector = 64;

char harddisk[tracks][sectors_per_track][heads][bytes_per_sector];
</PRE><FONT SIZE="-2">
Write a device-driver program which moves the head of the disk
according to the LOOK scheme. You can choose yourself whether you
base it upon SCAN or CSCAN.
</FONT>
<P>
<FONT SIZE="-2">Why is this array not exactly like a disk? (Hint: think geometry.)
</FONT>
<P>
<FONT SIZE="-2">Suppose you have four short files of data, two short and one long.
Design a simple filesystem so that you can do the following:
</FONT>
<OL>
<LI>Save the two short files onto your `virtual disk' from the real
disk.
</LI>
<LI>Retrieve the files again. Make sure that
you can retrieve the files by name, as many times as you like.
</LI>
<LI>Delete the first file.
</LI>
<LI>Save the longer file now, using the space that was freed when
you deleted the shorter file in .
</LI>
<LI>Plot the head movement of your disk on the screen using
track number for the horizontal axis against time vertically, so
that the output looks something like the following.
<PRE>
      Track -&gt;
1 2 3 4 5 6 7 8 9 ...
*
  *    
    *
      *
        *
          *
            *
          *
        *
          *
            *
              *
</PRE>
Time is measured in units of one head movement - one click
of the stepper motor.
Show how the head moves when you save and retrieve your files.
Hint: use separate output files to print the result of the
head movement and the result of retrieving a file.

<P>
</LI>
</OL><FONT SIZE="-2">
Note that you will have to design a `protocol' for saving the
data into the array. The disk array is just an array of
characters, you if you want to save a file, you need to know
what is data corresponding to which file. 
</FONT>
<P>
<FONT SIZE="-2">Hint: you might want to limit the filename size to, say, eight
characters to make the problem easier, like in DOS.
</FONT>
<P>
<FONT SIZE="-2">Explain carefully how you locate files on your disk, and
what scheme your filesystem uses to recover files in the correct
order.
</FONT>
<H1><A NAME="SECTION00700000000000000000">
6. Networks: Services and protocols</A>
</H1>
<P>
<FONT SIZE="-2">In this section we shall consider how to use the concepts we have
considered so far to make the task of implementing network
communication as straightforward as possible.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="4777"></A>
Consider a large company or a university with thousands of users, many
of whom have workstations or terminals on their desks - all of whom
are connected to a network. In this situation it is natural to share
certain resources so that they can be accessed from anywhere on the
network, without having to be reproduced on every machine:
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The printer,
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>User authentification data (password database),
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Disks holding user data,
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A reference clock which can be used to set the local
clocks on all systems,
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Addresses and telephone numbers.
</DD>
</DL><FONT SIZE="-2">
To some extent, this idea of sharing was the idea behind multi-user
systems. Not everyone can afford their own - so we share.
What big multiuser mainframe machines have tought us, however, is that a
single monolithic computer with <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> terminals is not a good solution.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Users demand more and more CPU power every day.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Scheduling the CPU, even if efficient on paper, can be
spoiled in practice for most users by a few
greedy users. Everyone wants their own private CPU.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Interactive I/O places a big load, proportional to
the number of users. A large machine with a hundred keyboards attached
to it can quickly become overwhelmed by keyboard I/O.
More and more programs are interactive and the
I/O overhead is much larger since mice and windows came along.
</DD>
</DL><FONT SIZE="-2">
The solution which is popular at present is to give everyone a smaller
machine with their own CPU, keyboard and screen. 
Although perhaps wasteful in theoretical terms,
in practice it is one of those little luxuries, like owning a big car,
which improves the quality of life for those who have it. What's more,
since computing power has generally increased, software has grown to
absorb that power - so it is not wasted for long.
</FONT>
<P>
<FONT SIZE="-2">By giving everyone their own machine, linked together by a network
we
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Spread the interactive I/O load over all the machines.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Allow machines to have public and private
resources.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Introduce a new overhead: the network software.
</DD>
</DL>
<P>

<H1><A NAME="SECTION00710000000000000000"></A>
<A NAME="4796"></A>
<BR>
6.1 Services: the client-server model
</H1><FONT SIZE="-2">
To share public resources on a network, we introduce the concept
of a <EM>service</EM>. A service is simply a job done by one part of
a system on behalf of another. The service is provided by a <EM>server</EM>
on behalf of a <EM>client</EM>. This is what is known as the client
server model<A NAME="tex2html267"
  HREF="footnode.html#foot4800"><SUP>6.1</SUP></A>.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="4942"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 6.1:</STRONG>
<EM>The client server model.</EM> The client and the server need not
be on the same machine when there is a network present.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
We have already encountered this kind of behaviour before in
connection with system calls. The system kernel is a kind of server,
which provides I/O services for all the processes on a system.  Also
<EM>daemons</EM>, in the UNIX terminology, are servers which answer
requests or perform some house-keeping on behalf of other processes.
The key idea is that there are always two elements: clients and
servers.
</FONT>
<P>
<FONT SIZE="-2">On a network, we would like to arrange things so that the server and
the client might be anywhere - on the same machine or on different
machines.  We would like a flexible system for sending out requests
for services into a network and getting an answer without having to
know too much about where the services are coming from.
</FONT>
<P>
<FONT SIZE="-2">To achieve these aims, we need:
</FONT>
<P>
<DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Interprocess communication</EM> which works across
machine boundaries.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Protocols</EM> - agreed systems of behaviour -
for requesting services.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Services need to have names or numbers which identify
them uniquely.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Network services need to be <EM>multi-threaded</EM>,
since several clients might request services simultaneously. We don't want
to keep clients waiting.
</DD>
</DL>
<P>

<H1><A NAME="SECTION00720000000000000000">
6.2 Communication and protocol</A>
</H1>
<P>
<FONT SIZE="-2">There are two ways of making a client-server
pair. One is to use Berkeley <EM>sockets</EM> directly and the other is
to use RPC - or <EM>Remote procedure call</EM> software package. 
</FONT>
<P>
<FONT SIZE="-2">A `socket' is a communications link from one process to another.
Sockets work over a network using the internet protocol set
(see next chapter).<A NAME="4826"></A>
Opening a `socket' to another machine is like opening a file
to read from or write to. Data are transferred as streams 
or packets of raw, non-interpreted bytes. 
The interpretation of the data once they arrive
at their detsination is a problem for the user to deal with.
</FONT>
<P>
<FONT SIZE="-2">RPC, on the other hand, is a<A NAME="4827"></A><A NAME="4828"></A>
high level software package which works on top of sockets
and allows programs to send <EM>typed data</EM> using a protocol
known as XDR - <EM>external data representation</EM>. It also
has high level tools called <EM>protocol compilers</EM> which
help programmers to write the code to interpret data at both
ends of a client-server connection.
</FONT>
<P>
<FONT SIZE="-2">There are two main implementations of this software:
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Sun Microsystems' RPC

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Apollo's NCS system.
</DD>
</DL>
<P>
<FONT SIZE="-2">Most of the software was developed for the UNIX-like operating systems, but
has since been adapted to all the popular systems in use. All of the
software runs on top of the TCP/IP network protocol which we shall
discuss in the next chapter.
</FONT>
<P>

<H1><A NAME="SECTION00730000000000000000">
6.3 Services and Ports</A>
</H1>
<P>
<FONT SIZE="-2">Services are a <EM>high level</EM> concept. When we ask for a service, we
are not interested in how the message gets to the server over a network.
We just want to be able to call some function <code>DoService(myservice)</code>
and have the result performed by some invisible part of the system.
To make this happen, a system of `handles' is used. It is rather
like opening a file - but now we want to open a service. The
terminology is also different.
<A NAME="4838"></A>
</FONT>
<P>
<FONT SIZE="-2">To obtain a service, we do not request a file handle but a <EM>port</EM>.
A port is a software concept - it should not be confused with
the hardware connector which couples your machine to the network
(which is also called a port on
some systems). It is a number which an operating system uses to
figure out which service a client wants.
</FONT>
<P>

<DIV ALIGN="CENTER"><FONT SIZE="-2">We say that a particular service lives at port <EM>xxx</EM>.
</FONT></DIV>
<P>
<FONT SIZE="-2">Here is some important terminology.
</FONT>
<P>
<DL COMPACT>
<DT></DT>
<DD><EM>Well-known ports.</EM> Every computer, all over the world has
to agree on the port numbers for different services. A well-known
port is a port number ()
which is reserved for a well-known service
like <code>ftp</code> or <code>telnet</code>. It
has been registered in a world-wide register.
<A NAME="4845"></A><A NAME="4846"></A><A NAME="4847"></A>

<P>
</DD>
<DT></DT>
<DD><EM>RPC program numbers.</EM> Historically, we distinguish between
<EM>services</EM> and RPC, although the effect of the two is the same.
The system of calling RPC services is
different to normal services - it uses program numbers first, and
works out port numbers for itself.
</DD>
</DL>
<P>

<H1><A NAME="SECTION00740000000000000000">
6.4 UNIX client-server implementation</A>
</H1>
<P>
<FONT SIZE="-2">It is useful to describe how UNIX deals with services, since this
is the model which has been adapted for other systems.
</FONT>
<P>

<H2><A NAME="SECTION00741000000000000000">
6.4.1 Socket based communication</A>
</H2>
<P>
<FONT SIZE="-2">To send data to a server using sockets, we need to know the
<EM>port number</EM> at which the server lives. Port numbers are
listed in the file <code>/etc/services</code>, which looks like this.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
#
# Network services, Internet style
# This file is never consulted when the NIS are running
#
tcpmux		1/tcp				# rfc-1078
echo		7/tcp
echo		7/udp
...
ftp		21/tcp
telnet		23/tcp
smtp		25/tcp		mail
time		37/tcp		timserver
time		37/udp		timserver
name		42/udp		nameserver
whois		43/tcp		nicname		# usually to sri-nic
domain		53/udp
domain		53/tcp
hostnames	101/tcp		hostname	# usually to sri-nic
sunrpc		111/udp
sunrpc		111/tcp
...
login		513/tcp
shell		514/tcp		cmd		# no passwords used
printer		515/tcp		spooler		# line printer spooler
courier		530/tcp		rpc		# experimental
uucp		540/tcp		uucpd		# uucp daemon
biff		512/udp		comsat
who		513/udp		whod
syslog		514/udp
talk		517/udp
route		520/udp		router routed
ingreslock      1524/tcp
bootpc          68/udp                          # boot program client
bootp           67/udp          bootps          # boot program server
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">The file maps <EM>named services</EM> into port numbers and <EM>protocol</EM> type.
The protocol type is also an agreed standard which is defined
in the file <code>/etc/protocols</code>, which looks like this:
</FONT><PRE>
#
# Internet (IP) protocols
# This file is never consulted when the NIS are running
#
ip	0	IP	# internet protocol, pseudo protocol number
icmp	1	ICMP	# internet control message protocol
igmp	2	IGMP	# internet group multicast protocol
ggp	3	GGP	# gateway-gateway protocol
tcp	6	TCP	# transmission control protocol
pup	12	PUP	# PARC universal packet protocol
udp	17	UDP	# user datagram protocol
hmp     20      HMP     # host monitoring protocol
xns-idp 22      XNS-IDP # Xerox NS IDP
rdp     27      RDP     # "reliable datagram" protocol
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2">In order to open a socket, we must
know the name of the host on which the server lives. If we don't know
this information in advance, we can
send a <EM>broadcast</EM> request to all hosts, hoping
that one of them will reply with their correct address (see next
chapter).
</FONT>
<P>
<FONT SIZE="-2">Also, when the message arrives at a host which runs the server process,
there are two possibilities.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The server process is always running.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The server process gets started when the request
arrives.
</DD>
</DL><FONT SIZE="-2">
Both methods are used in practice. If a server is expected to receive
a lot of requests, it should be running all the time. If it spends
long periods sleeping it should probably started when a request
arrives.
</FONT>
<P>
<FONT SIZE="-2">The second of these possibilities is handled by a yet another server
called the <EM>internet daemon</EM> or <code>inetd</code>. This is a kind
of public server which works on behalf of any service. <TT>inetd</TT>
reads a configuration file called
<code>/etc/inetd.conf</code>. Here are a few typical lines from this file.
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
#
# Configuration file for inetd(8).  See inetd.conf(5).
#
# Internet services syntax:
#  &lt;service_name&gt; &lt;socket_type&gt; &lt;proto&gt; &lt;flags&gt; &lt;user&gt; &lt;server_pathname&gt; &lt;args&gt;
#
# Ftp and telnet are standard Internet services.
#
ftp     stream  tcp     nowait  root    /usr/etc/in.ftpd        in.ftpd
telnet  stream  tcp     nowait  root    /usr/etc/in.telnetd     in.telnetd
#
# Shell, login, exec, comsat and talk are BSD protocols.
#
shell   stream  tcp     nowait  root    /usr/etc/in.rshd        in.rshd
login   stream  tcp     nowait  root    /usr/etc/in.rlogind     in.rlogind
exec    stream  tcp     nowait  root    /usr/etc/in.rexecd      in.rexecd
comsat  dgram   udp     wait    root    /usr/etc/in.comsat      in.comsat
talk    dgram   udp     wait    root    /usr/etc/in.talkd       in.talkd
</PRE><FONT SIZE="-2"></FONT><FONT SIZE="-2"><EM>inetd</EM> listens on the network for service requests for all of
the daemons which are in its configuration file, and - if such a
request arrives - it starts the server for the duration of the
request.
</FONT>
<P>
<FONT SIZE="-2">Notice the field `wait' and `nowait'. This tells <code>inetd</code> what
to do if another request arrives while one request is being
processed - should it wait for the first request to finish (single
threaded) or should it start several processes (multi-threaded)
to handle the requests<A NAME="tex2html276"
  HREF="footnode.html#foot4870"><SUP>6.2</SUP></A>.
</FONT>
<P>

<H2><A NAME="SECTION00742000000000000000">
6.4.2 RPC services</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="4872"></A>
In the RPC way of doing things, we called a service based on a
<EM>program number</EM>, a <EM>procedure number</EM> and a <EM>version number</EM>.
There is now an extra step in the chain of events - yet another
common server which must be consulted. This is called the
<EM>portmapper</EM>.
When an RPC server starts up on its host, it registers itself
with the portmapper, telling it which port it is listening
to and what program number it is using.
</FONT>
<P>
<FONT SIZE="-2">When an RPC client wants a service, it sends a request to the
portmapper on the server host asking for a server which can deal
with program number (service) <EM>xxx</EM>. The portmapper replies
by giving the port on which the RPC server is listening.
</FONT>
<P>
<FONT SIZE="-2">The advantage of this scheme is that RPC applications do not have
to run on <EM>well-known ports</EM>. A suitable free port can be
found at start-up.
On the other hand, each type of server program must have a unique
<EM>program number</EM>, which must be obtained from Sun Microsystems.
The program numbers are stored in <code>/etc/rpc</code>.
</FONT>
<P>
<FONT SIZE="-2">The real benefit of the RPC packages is the high level concepts which
they handle on behalf of the programmer. The protocol compilers
and XDR protocols provide a set of `frequently need subroutines'
which enhance the system of communication across a network.
</FONT>
<P>

<H1><A NAME="SECTION00750000000000000000">
6.5 The telnet command</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="4881"></A>The telnet command, as opposed to the telnet service, does not
only contact the well-known port number , but can also be
used to send a message to any port.
For example, instead of the command
</FONT><PRE>
finger mark@mymachine
</PRE><FONT SIZE="-2">
to get information on user <EM>mark</EM> from the <EM>finger</EM>
database, we could contact the well-known port on host `mymachine'
as follows:
</FONT><PRE>
anyon% telnet anyon finger
Trying 129.240.22.14 ...
Connected to anyon.
Escape character is '^]'.
mark
Login name: mark                        In real life: Mark Burgess
Directory: /mn/anyon/u2/mark            Shell: /local/bin/tcsh
On since Aug 14 11:59:39 on ttyp1 from :0.0
17 minutes Idle Time
Mail last read Sun Aug 14 14:27:02 1994
No Plan.
</PRE><FONT SIZE="-2">
Or had finger not been in <code>/etc/services</code>, we could have written
</FONT><PRE>
telnet hostname 79
</PRE><FONT SIZE="-2">
Not all services accept textual input in this way, but <code>telnet</code> will
try to contact their ports nevertheless.
</FONT>
<P>

<H1><A NAME="SECTION00760000000000000000">
6.6 X11</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="4891"></A>
<A NAME="4892"></A>
The X11 window system, used by Unix, is a client-server based application. A user's
workstation runs a server process called <EM>X</EM>, whose job it is
to display windows on the user's <EM>display</EM>. Each application
the user wishes to run is a <EM>client</EM> which must contact the
server in order to have its output displayed on the X-display.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="4927"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 6.2:</STRONG>
The X windowing system.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">By making this simple client-server abstraction, it makes no
difference whether applications are running on the same host as the
X-display, or whether they are running over the network.  X uses its
own system of protocols which is layered on top of socket
communication. Strangely, X and Sun's variant News are the only window
systems which have understood the point of networking. All other window
systems require you to run programs on the computer at which
you are sitting.
</FONT>
<P>

<H1><A NAME="SECTION00770000000000000000">
6.7 html: hypertext markup language</A>
</H1>
<P>
<FONT SIZE="-2">A further example of a protocol is the world wide web hypertext 
markup (formatting) language (html). This insists upon simple
rules for formatting pages and references.
</FONT>
<P>

<H1><A NAME="SECTION00780000000000000000">
Exercises</A>
</H1>
<P>

<OL>
<LI>Explain what `protocol' means.
</LI>
<LI>Describe briefly the client-server model.
</LI>
<LI>What role do d&#230;mons play in with respect to the unix kernel?
Why are servers daemons?
</LI>
</OL>
<P>

<H1><A NAME="SECTION00790000000000000000">
Project</A>
</H1>
<P>
<FONT SIZE="-2">Make a simple client-server model which commuicates via unix files. 
The server should be sent an arithmetic problem to solve, for 
example: . The client 
should send this request to the server, and the server should send back
the answer. The client
must be able to exit gracefully if the server
does not answer for any reason. (Hint: you could use the `sleep' command
to wait for the server to reply.) 
</FONT>
<P>
<FONT SIZE="-2">You will need to think of the following:
</FONT>
<OL>
<LI>What filenames should you use to send messages from the client to
the server and from the server to the client? 
</LI>
<LI>Since the client
and the server are independent processes, you need to find a way of
discovering when the client and the server have finished writing
their replies, so that you don't read only half of the answer by
mistake.
</LI>
<LI>The server should loop around and around, waiting
for maultiple requests, while the client sends only one request
and exits when it gets a reply.
</LI>
</OL><FONT SIZE="-2">
</FONT>
<H1><A NAME="SECTION00800000000000000000">
7. TCP/IP Networks</A>
</H1>
<P>
<FONT SIZE="-2">In the last chapter we looked at some of the <EM>high level</EM> considerations
for enabling transparent communication over a network. The next thing
to look at is how such a scheme of protocols is achieved in practice.
</FONT>
<P>

<H1><A NAME="SECTION00810000000000000000">
7.1 The protocol hierarchy</A>
</H1>
<P>

<H2><A NAME="SECTION00811000000000000000">
7.1.1 The OSI model</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5305"></A>
<A NAME="5306"></A>
We begin by returning to the `most important idea in computing' - namely
hierarchies. As we have noted before, the most practical way 
of solving complicated problems is to create `layers of detail'. At any
level in a hierarchy, the details of the lower levels are invisible
- so we never see the irrelevant pieces of the computing puzzle we
are trying to solve.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="5307"></A>
The International Standards Organization (ISO) has defined a 
standard model for describing communications across a network, called
the OSI model, for <EM>Open Systems Interconnect (reference model)</EM>.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="5309"></A>
The OSI model is a seven layered monster. It
does not have to be taken literally - it might not be natural
to separate all of these parts in every single program - but
it is useful as a way of discussing the logically distinct parts of
network communication. The layers are described as follows.
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
</FONT><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="CENTER"><FONT SIZE="-2">
7</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Application layer  </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Program which sends data</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
6</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Presentation layer </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> XDR or user routines</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
5</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Session layer      </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> RPC / sockets</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
4</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Transport layer    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> tcp or udp</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
3</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Network layer      </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> IP internet protocol</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
2</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Data link layer    </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> ethernet (protocols)</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
1</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Physical layer     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> ethernet (electronics)</FONT></TD>
</TR>
</TABLE><FONT SIZE="-2">
<BR>
<BR>
</FONT>
<P>
<FONT SIZE="-2">At the lowest level, the sending of data between two machine takes
place by manipulating voltages along wires. This means we need a
device driver for the signaller, and something to receive the
data at the other end - a way of converting the signals into bytes;
then we need a way of structuring the data so that they make sense.
Each of these elements is achieved by a different level of abstraction.
</FONT>
<P>

<OL>
<LI><EM>Physical layer.</EM> This is the problem of sending a signal
along a wire, amplifying it if it gets weak, removing noise etc.
If the type of cable changes (we might want to reflect signals off a
satellite or use fibre optics) we need to convert one kind of signal
into another. Each type of transmission might have its own accepted
ways of sending data (i.e. protocols).<A NAME="5317"></A>

<P>
</LI>
<LI><EM>Data link layer.</EM> This is a layer of checking which makes
sure that what as sent from one end of a cable to the other actually
arrived. This is sometimes called <EM>handshaking</EM>.<A NAME="5320"></A>
<A NAME="5321"></A>

<P>
</LI>
<LI><EM>Network layer.</EM> This is the layer of software which remembers
which machines are talking to other machines. It establishes
connections and handles the delivery of data by manipulating the
physical layer. The network layer needs to know something about
addresses - i.e. where the data are going, since data might flow
along many cables and connections to arrive where they are going.
<A NAME="5323"></A>

<P>
</LI>
<LI><EM>Transport layer.</EM> We shall concentrate on this layer for
much of what follows. The transport layer builds `packets'
or `datagrams' so that the network layer knows what is data and
how to get the data to their destination. Because many machines
could be talking on the same network all at the same time, data
are broken up into short `bursts'. Only one machine can talk over
a cable at a time so we must have <EM>sharing</EM>. It is easy to
share if the signals are sent in short bursts. This is analogous
to the sharing of CPU time by use of time-slices.
<A NAME="5326"></A>

<P>
</LI>
<LI><EM>Session layer</EM> This is the part of a host's operating
system which helps a user program to set up a connection. This
is typically done with <EM>sockets</EM> or the RPC.<A NAME="5329"></A>
<A NAME="5330"></A>

<P>
</LI>
<LI><EM>Presentation layer.</EM> How are the data to be sent by the
sender and interpreted by the receiver, so that there is no doubt
about their contents? This is the role played by the external
data representation (XDR) in the RPC system.<A NAME="5332"></A>

<P>
</LI>
<LI><EM>Application layer.</EM> The program which wants to send data.
<A NAME="5334"></A>

<P>
</LI>
</OL>
<P>
<FONT SIZE="-2">As always, the advantage of using a layered structure is that we can
change the details of the lower layers without having to change the
higher layers. Layers  to  are those which involve the transport
of data across a network. We could change all of these without doing
serious damage to the upper layers - thus as new technology arrives,
we can improve network communication without having to rewrite
software.
</FONT>
<P>
<FONT SIZE="-2">Most of these layers are quite static - only the physical layer is
changing appreciably.
</FONT>
<P>

<H2><A NAME="SECTION00812000000000000000">
7.1.2 Data encapsulation</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5337"></A>
Each time we introduce a new layer of protocol into network
transport, we need to `package in' the information in some agreed
format. This is called <EM>data encapsulation</EM>. Often when data are
encapsulated, each `packet' (to use the word loosely) is given
a few bytes of `header information'. This is information which includes,
for example, what the information is for, where it is going and
which piece of the total information the current packet represents.
</FONT>
<P>
<FONT SIZE="-2">At the level of the network layer, data might be divide up into
numbered packets, each of which contain the address of the sender and
receiver, the length of the packet and so on.
</FONT>
<P>
<FONT SIZE="-2">Suppose now that we were to `unpack' these data, removing their
headers and reassembling the data. We might find that the data are
structured at a higher level, namely the transport layer.  The form of
the data might be a sequence of <EM>messages</EM>, each of which has a
header of its own containing a <EM>port number</EM> or <EM>RPC program
number</EM> of the receiver application program, the length of the message
and so on.<A NAME="5342"></A><A NAME="5343"></A>
</FONT>
<P>
<FONT SIZE="-2">Notice the parallels between this and the system of segments and pages
in the virtual memory concept of chapter 5. Each layer of abstraction
we introduce requires a small overhead (the header) which gets added
to the data so that the receiver can make sense of them. This is the
essence of implementing a protocol in practice.
</FONT>
<P>

<H1><A NAME="SECTION00820000000000000000">
7.2 The internet protocol family</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="5345"></A>
The set of protocols currently used on most networks is called the
<EM>internet protocol family</EM>. This is divided into four layers
which correspond roughly to a coarse OSI model.
</FONT>
<P>
<FONT SIZE="-2">
<BR>
<BR>
</FONT><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="CENTER"><FONT SIZE="-2">
4</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Application layer  </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> user program </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> 6,7 </FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
3</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Host to host transport </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> higher level data encapsulation  </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2">  3,4,5</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
2</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Internet layer </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> lower level datagram transport </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> 2</FONT></TD>
</TR>
<TR><TD ALIGN="CENTER"><FONT SIZE="-2"> 
1</FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Physical layer     </FONT></TD>
<TD ALIGN="LEFT"><FONT SIZE="-2"> Network </FONT></TD>
<TD ALIGN="CENTER"><FONT SIZE="-2"> 1</FONT></TD>
</TR>
</TABLE><FONT SIZE="-2">
<BR>
<BR>
</FONT>
<P>
<FONT SIZE="-2">At the internet layer, we have the IP or <EM>internet protocol</EM> which
includes a specification of addresses and basic units of data transmission.
The official name for the lowest level data `packages' in the 
internet protocol is <EM>datagrams</EM>. Each datagram consists
of a number of 32 bit words. The first six of these words consists of
the IP header.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="5386"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.1:</STRONG>
IP datagram format</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2"><A NAME="5388"></A>
<A NAME="5389"></A>
The size of datagrams may be altered by the transport agents during
the process of being sent. If a <EM>router</EM> transmits datagrams from
one physical network to another, and the second network uses a smaller
packet size, it will divide datagrams up into smaller datagrams called
<EM>fragments</EM>.<A NAME="5392"></A>  The above header is then reproduced in each fragment
together with a `fragment offset' which determines the order in which
the fragments should be reconstructed at their final destination.
The packet size on different physical networks is part of the
low-level protocol definition. This is chosen when the physical layer
is designed, based on the efficiency and speed of the network.
On a slow network, a small packet size would be used so that the multiuser
sharing of network time is more equitable, i.e. a greater number
of packets per unit time can be sent if the packets are smaller.
On the other hand, if the packet size is too small, the overhead
becomes a significant portion of the total packet size and the
transfer is inefficient.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="5393"></A><A NAME="5394"></A>
At the next level (the transport layer), there are two standard protocol
types provided. These are called <EM>tcp</EM> for <EM>transmission
control protocol</EM> and <EM>udp</EM> for <EM>user datagram protocol</EM>.
They are sometimes called <EM>connection-oriented</EM> and
<EM>connectionless</EM> protocols respectively, or <EM>reliable</EM> and
<EM>unreliable</EM>. We shall explain these names below.
<A NAME="5403"></A>
<A NAME="5404"></A>
<A NAME="5405"></A>
<A NAME="5406"></A>
</FONT>
<P>

<H2><A NAME="SECTION00821000000000000000">
7.2.1 udp</A>
</H2>
<P>
<FONT SIZE="-2">The user datagram protocol is called <EM>unreliable</EM> because when an
application chooses this protocol, the best it can do is to `throw its
data out to the wind' and hope that it will arrive. When we use udp
transport, there is no guarantee that data will arrive at the
destination and no confirmation of receipt is sent by the receiver.
</FONT>
<P>
<FONT SIZE="-2">It is called <EM>connectionless</EM> because the messages are sent one by
one, without any concept of there being an on-going connection between
the sender and receiver. <EM>This is like sending a letter in the
post.</EM>
</FONT>
<P>
<FONT SIZE="-2">Udp is the simpler of the two transport layer protocols, since it
requires no handshaking by the system. It is useful for applications
which either need or want to provide their own form of handshaking.
For example, it would be natural to use the udp protocol for a
`question-answer' type of client-server system. The client knows that
its question arrived if it gets an answer from the server, so asking
the network protocols to guarantee it would be a waste of time.
</FONT>
<P>
<FONT SIZE="-2">A single `message' of udp encapsulated datagrams is 
officially called a <EM>packet</EM> and is
given a small
header as shown in the figure below.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="5426"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.2:</STRONG>
udp packet header</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
Notice that this header contains no ordering information - so the order
in which the packets arrive at their destination is not guaranteed
by the protocol itself. Only the integrity of the data are checked, using
a checksum.
</FONT>
<P>

<H2><A NAME="SECTION00822000000000000000">
7.2.2 tcp</A>
</H2>
<P>
<FONT SIZE="-2">A single message of the transmission control protocol is called a
<EM>segment</EM>. The tcp protocol
is called reliable or connection-oriented
because sufficient handshaking is provided to guarantee the arrival
and the ordering of the segments at their destination. 
The ordering of each message implies a concept of two machines being 
continual contact with one another. 
<EM>This is like a telephone
conversation: both parties are in contact all the time.</EM>
</FONT>
<P>
<FONT SIZE="-2">TCP connections are useful for sending data to servers, where no
particular reply is required. For example, it would be used to send
print jobs to a printer queue across a network. The sender receives
no reply from the print spooler, and wants every single line
of data to arrive in the correct order without having to worry.
</FONT>
<P>
<FONT SIZE="-2">Each tcp segment has a header as shown in the figure below.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="5461"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.3:</STRONG>
TCP segment header</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>

<H1><A NAME="SECTION00830000000000000000">
7.3 The physical layer</A>
</H1>
<P>
<FONT SIZE="-2">As an example of a physical layer, we can take a brief look
at the ethernet. Ethernet is one form of cabling which
is in common use. Other kinds of cable include fibre
optics (FDDI) <A NAME="5464"></A>, 10BaseT or ISDN.<A NAME="5465"></A>
</FONT>
<P>

<H2><A NAME="SECTION00831000000000000000">
7.3.1 Network connectivity</A>
</H2><FONT SIZE="-2">
To send messages from one computer to another, we have to
connect computers together. One way of doing this would be
connect every machine to every other machine in some
bizarre `cat's cradle' of wiring. This would require
<IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> network connections per machine if there were <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> machines.
It's pretty clear that this is not a good solution.
</FONT>
<P>
<FONT SIZE="-2">Another solution is to chain machines together (see figure below)
or put them in a ring. This requires only two connections per
machine.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="5485"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.4:</STRONG>
Chains and rings.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
The disadvantage with this scheme is that each machine has to send
signals forward to the next one, until they arrive at the correct
machine, which costs time and resources.<A NAME="5487"></A> FDDI
fibre optic transmission works like this. It is called a <EM>token
ring</EM>.
</FONT>
<P>
<FONT SIZE="-2">Modern ethernet uses neither method. Instead it uses a combination of two
solutions. A basic ethernet network consists of a single cable or bus. Every
machine listens into the same cable with one interface connector (see
figure).
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="5497"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.5:</STRONG>
Ethernet</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>
<FONT SIZE="-2">
Since all machines share the same cable, only one machine
can be talking at once. Each machine waits its turn to 
transmit data. Each host flashes its signals to all the
hosts on the cable like sending Morse code with a torch.
Every host sees every message but only the host with the
destination address bothers to accept the message.
</FONT>
<P>
<FONT SIZE="-2">Ethernet comes in three flavours: <EM>thick ethernet</EM>,
a fat yellow cable with black markings, <EM>thin ethernet</EM>
a coaxial (usually black) cable a few millimetres thick
and <EM>twisted pair ethernet</EM>. The latter comes out of
an ISDN telephone connector, whereas the older types use
coaxial and D-pin connectors. Twisted pair ethernet
is usually structured in <EM>star formation</EM>. That is,
at strategic places on a master cable (usually thick
ethernet) a `hub' is attached. This is a device
which converts one connection into many. From the
hub there is one twisted pair wire to each machine.
If there are many machines, we require many hubs, since
the number of connections is limited to ten or so.
</FONT>
<P></P>
<DIV ALIGN="CENTER"><A NAME="5516"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.6:</STRONG>
Star base networks</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">A similar arrangement can be achieved with thin ethernet
using a <EM>multiport repeater</EM>, rather than a hub.
A <EM>repeater</EM> is simply an amplifier, which is used
over long stretches of cable. A multiport repeater
combines amplification with dividing up a thin
ethernet cable into <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> branches.
</FONT>
<P>
<FONT SIZE="-2">The twisted pair solution is the most modern of these
solutions.
</FONT>
<P>

<H2><A NAME="SECTION00832000000000000000">
7.3.2 Ethernet addresses</A>
</H2>
<P>
<FONT SIZE="-2">An ethernet address is a number which is wired into
every ethernet interface card. It is unique for
every machine in the world. 
The first few hexadecimal digits of the ethernet address
identify the manufacturer of the interface.
</FONT>
<P>
<FONT SIZE="-2">The ethernet address is the only piece of information a machine has
before it is configured. It is only used by diskless machines and some
x-terminals as part of an ARP/RARP ((Reverse) Address resolution
protocol) request to get an IP address.
<A NAME="5521"></A>
<A NAME="5522"></A>
</FONT>
<P>

<H1><A NAME="SECTION00840000000000000000">
7.4 Internet Addresses and Routing</A>
</H1>
<P>

<H2><A NAME="SECTION00841000000000000000">
7.4.1 IP addresses, networks and domain names</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5525"></A>
The internet is, by now, a world-wide network. As of today, it
is version 4 (IPV4)<A NAME="5526"></A> of the internet protocol which is in common
use. Every host on the internet has to have a unique address
so that network communication is unambiguous.
This is given by a 4-byte word of the form
</FONT><PRE>
xxx.yyy.zzz.mmm
</PRE><FONT SIZE="-2">
where <code>xxx</code> etc can be numbers from <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$0$"> to 
(Certain addresses are reserved).
In addition to a numerical address, each host has a name.
For example, the following are valid internet addresses
and the names they correspond to.
</FONT>
<P>
<PRE>
129.240.22.14  anyon.uio.no
128.39.89.10   nexus.iu.hioslo.no
192.48.96.9    ftp.uu.net
</PRE>
<P>
<FONT SIZE="-2">The addressing scheme is based on a hierarchical splitting
of networks, subnets and hosts. To arrive correctly at
its destination an IP packet has to know exactly which
network a host is connected to. This information is
correctly coded into the numerical address, but is
not contained directly in the textual name form.
</FONT>
<P>
<FONT SIZE="-2">In the textual form, each machine belongs to a <EM>logical domain</EM>
which has a name. The address takes the form
</FONT>
<DIV ALIGN="CENTER"><FONT SIZE="-2"><EM>machine.domain-name</EM>
</FONT></DIV><FONT SIZE="-2">
Thus in the above examples, `anyon', `nexus' and `ftp' are
host names and `uio.no', `iu.hioslo.no' and `uu.net' are domain
names.
</FONT>
<P>
<FONT SIZE="-2">The numerical form is strictly speaking a combination of a
<EM>network</EM> address and a host address. The textual
form is a combination of a hostname and a domain name.
</FONT>
<P>
<FONT SIZE="-2">There is a subtle difference between these.  Given a numerical IP
address, datagrams can find their way precisely to the correct network
and machine. The textual information is not sufficient however
because, while the hostname is unique, the remainder of the address
(the domain name) is usually a generic name for a group of networks -
and we don't know how to choose the right one.
</FONT>
<P>
<FONT SIZE="-2">A logical domain, like the above examples, can encompass
any number of different networks. For example, the domain
name `uio.no' encompasses all of the subnets under
the address <code>129.240.*.*</code>. The IP packets
need to know which subnet the machine is on in order to
get to their destination, because the text name only
says that they should to to <code>120.240.*.host</code>.
The <code>*</code> is unknown.
</FONT>
<P>
<FONT SIZE="-2">To complete this information, we need a database which maps internet
domain names to internet addresses.  This mapping is performed by the
Domain Name Service (DNS) or Berkeley Internet Name Domain (BIND)
which we shall discuss below.
<A NAME="5536"></A><A NAME="5537"></A><A NAME="5538"></A>
</FONT>
<P>

<H2><A NAME="SECTION00842000000000000000">
7.4.2 Netmask and broadcast address</A>
</H2>
<P>
<FONT SIZE="-2">Each address consists of two parts: a <EM>network address</EM> and a <EM>host address</EM>.  A system variable called the <EM>netmask</EM> decides how
IP addresses are interpreted locally.
<A NAME="5543"></A>
<A NAME="5544"></A>
</FONT>
<P>
<FONT SIZE="-2">The netmask decides the boundary between how many bits of the IP
address will be kept for hosts and how many will be kept for the
network location name. There is thus a trade off between the number of
allowed domains and the number of hosts which can be coupled to each
subnet. Subnets are usually separated by routers, so the question is
how many machines do we want on one side of a router?
</FONT>
<P>
<FONT SIZE="-2">The netmask only has a meaning as a binary number.  When you look at
the netmask, you have to ask yourself - which bits are ones and which
are zeroes? The bits which are <EM>ones</EM> decide which bits can be
used to specify the domain and the subnets within the domain. The bits
which are zeroes decide which are hostnames on each subnet.  The local
network administrator decides how the netmask is to be used.
</FONT>
<P>

<P></P>
<DIV ALIGN="CENTER"><A NAME="5622"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 7.7:</STRONG>
<EM>The netmask sets the division between network
address and host address in the 4-byte IP address.</EM></CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV><P></P>

<P>
<FONT SIZE="-2">The most common situation is that the first three numbers
<code>xxx.yyy.zzz</code> represent the domain and the last number
<code>mmm</code> represents the machine. In this case the
netmask is <code>255.255.255.0</code>, leaving the last byte for
machine addresses.
It is only possible to have 254 different machines in the
domain with address <code>xxx.yyy.zzz</code> with this netmask.
If we wanted more, we would have to introduce a different
domain name for the extra hosts! </FONT>
<P>
<FONT SIZE="-2">If we wanted more machines on each subnet, we would have to change the
netmask and the definitions of the domain address.  By making the
netmask <code>255.255.248.0</code>, as in the figure above, we add an extra
bit to the host part. Thus a total of </FONT>
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
2^{11}-2
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P><FONT SIZE="-2"> hosts could use
the same domain name.
</FONT>
<P>
<FONT SIZE="-2">One address is always reserved by the internet protocol, namely the
<EM>broadcast address</EM>. This is an address which is used like a
wildcard - to refer to all machines in a given domain
simultaneously. Another address is reserved as an address for the <EM>network</EM> itself. Usually <code>xxx.yyy.zzz.0</code> is the network address,
and <code>xxx.yyy.zzz.255</code> is the broadcast address, but on older
networks the address
<code>xxx.yyy.zzz.0</code> was used for both of these.
</FONT>
<P>

<H2><A NAME="SECTION00843000000000000000">
7.4.3 Routers and gateways</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5628"></A>
<A NAME="5629"></A>
A router is a device which connects two physically different
segments of network. A router can be an ordinary workstation,
or it can be a dedicated piece of machinery. If a router
joins <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> different networks, it has <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> different network
interfaces and forwards datagrams between them. The router
must be able to understand internet addresses in order to do
this - since it must know where packets want to go.
</FONT>
<P>
<FONT SIZE="-2">A <EM>gateway</EM> is another name for a router. Some authors
distinguish between gateways which forward packets with
different network protocols, and routers which just isolate
different segments of network of the same type.
</FONT>
<P>
<FONT SIZE="-2">Roughly speaking, the network on the short end of a router is
called a <EM>local area network</EM> (LAN) and the greater network
on the long end is a <EM>wide area network</EM> (WAN), though these
names are normally used as it suits.
</FONT>
<P>

<H1><A NAME="SECTION00850000000000000000">
7.5 Network Naming services</A>
</H1>
<P>

<H2><A NAME="SECTION00851000000000000000">
7.5.1 The Domain Name Service</A>
</H2>
<P>
<FONT SIZE="-2">Although the system of textual internet addresses is very convenient
from a user point of view, it creates a problem. Users, on the one
hand, would like to use <EM>names</EM> rather than numbers to talk about
network hosts, but the name form is not sufficient in itself as an
exact specification of a network and host addresses.
<A NAME="5636"></A><A NAME="5637"></A>
</FONT>
<P>
<FONT SIZE="-2">The solution to this problem is the <EM>domain name service</EM> or DNS. 
This is a service which takes a textual internet address of the form
</FONT><PRE>
host.domain
</PRE><FONT SIZE="-2">
and returns the numerical form of the IP address for that host. 
This is called <EM>resolving</EM> the name.<A NAME="5642"></A>
<A NAME="5643"></A>
Notice
that no two machines in the same domain may have the same name, otherwise
the DNS would not be able to resolve the IP address from the textual form.
</FONT>
<P>
<FONT SIZE="-2">The DNS also performs the reverse service, converting numbers into names
and stores extra information about which hosts are mail-exchangers etc.
The UNIX program <EM>nslookup</EM> can be used to browse in the Domain Name
Service.
</FONT>
<P>
<FONT SIZE="-2">The domain name service is a daemon, called a <EM>nameserver</EM>, which
runs on some chosen host (usually a UNIX machine, since the software
was written for UNIX) and looks up names in a database. The host on
which the nameserver runs is often called a nameserver too.<A NAME="5646"></A>
</FONT>
<P>
<FONT SIZE="-2">Each server covers only the list of hosts in its local domain, not
those of other domains - but it has a knowledge of other nameservers
which can answer queries in other domains.  If a nameserver receives a
request to resolve a name which is not in its own domain, it <EM>forwards</EM> the request to the official nameserver for that domain.
</FONT>
<P>
<FONT SIZE="-2">Nameservers update each other's information constantly about what
official nameservers addresses are so that the data are always up to
date. Each new network which is set up on the internet has to register
its nameserver centrally so that this information is complete.
</FONT>
<P>
<FONT SIZE="-2">Every host on a network must know the name of its local nameserver
in order to send requests for name resolution.
</FONT>
<P>
<FONT SIZE="-2">The DNS software which is in most widespread use is the Berkeley BIND
software (Berkeley Internet Name Domains). Microsoft have their own
implementation called WINS (Windows internet nameservice) as their own
commercial solution but this will soon be abandoned in favour of
DNS, since it lacks adequate functionality and security.
</FONT>
<P>

<H2><A NAME="SECTION00852000000000000000">
7.5.2 Network Information Service</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5649"></A>
<A NAME="5650"></A>
The DNS is not the only database service which is in use on the
internet. The Network Information Service (NIS), written by Sun
Microsystems is another service which provides information on the
network. NIS was formerly called the Yellow Pages, until Sun
Microsystems were politely informed that Yellow Pages was a trademark
of British Telecom.  Many people still refer to NIS as YP.
<A NAME="5651"></A>
<A NAME="5652"></A>
</FONT>
<P>
<FONT SIZE="-2">NIS was designed for the UNIX operating system. It is nevertheless
used by DOS and Macintosh machines which run software to communicate
with UNIX servers on TCP/IP networks. The data it stores are
commonly required configuration files for UNIX. 
</FONT>
<P>
<FONT SIZE="-2">For example, the user registration database is contained in NIS, as is
the list of all hosts on the local network. The <EM>hosts</EM>
information actually reproduces the information which is stored in the
DNS, but the information is not complete - since only host names are
mapped to IP addresses - no domain names are included. A number of
other databases are held in NIS, such as network-wide mail aliases and
information about groups of users.
</FONT>
<P>
<FONT SIZE="-2">The advantage of NIS is that each user on a network can have the
same login name and password on all of the machines which use the 
network information service - because they all read the same
database. This NIS is simply a way of sharing the information which
would otherwise have to be typed in separately to each machine.
</FONT>
<P>
<FONT SIZE="-2">Wheras each host must know the name of its nameserver, no host has to
know the name of the local NIS server - that is because NIS uses the
<EM>broadcast</EM> system. The software which connects clients to the
server sends out a request to the <EM>broadcast address</EM>. The message
is received by every host on the network that is listening.  When a
NIS server receives the messages, it replies to the sender with its IP
address, so that the sender knows which host to query for NIS
information. It will continue to use that address for a while (even
though the server may crash in the mean time) and then it broadcasts
its query again.<A NAME="5656"></A>
</FONT>
<P>
<FONT SIZE="-2">If no servers are available, a client may never get its information!
Most networks have backup servers in case on should fail. That way
if one doesn't answer, hopefully the other one will.
</FONT>
<P>
<FONT SIZE="-2">The advantage of the system is that a client always ends up asking the 
server which can answer quickest - and which, presumeably, has the least
to do, so the load of answering the service is spread around.
</FONT>
<P>

<H1><A NAME="SECTION00860000000000000000">
7.6 Distributed Filesystems</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="5658"></A>
Probably the first thing we are interested in doing with a network is
making our files available to all hosts, so that - no matter where in
our corporate empire we happen to be sitting - we always have access
to our files.
</FONT>
<P>
<FONT SIZE="-2">The concept of a <EM>distributed filesystem</EM> is about sharing disks
across a network. Many operating systems have 
</FONT>
<P>
<FONT SIZE="-2">There are three main contenders for such a system in the UNIX world.
Only one of these is in widespread use.
</FONT>
<P>

<H2><A NAME="SECTION00861000000000000000">
7.6.1 NFS - the network filesystem</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5661"></A> 
<A NAME="5662"></A>
NFS was historically the first distributed filesystem to be implemented,
by Sun Microsystems. All manufacturers now support Sun's NFS.
</FONT>
<P>
<FONT SIZE="-2">NFS is based on Sun's own RPC system (Remote procedure call).  The
idea behind NFS is to imitate UNIX filesystem semantics as closely as
possible from across a network. NFS works by implementing a number of
servers which run on UNIX machines.<A NAME="5663"></A>
</FONT>
<P>
<FONT SIZE="-2">One problem with a network file system is what to do about machine
crashes. Suppose we are in the middle of writing or retrieving a file and the
server machine supplying the file crashes. We need some way of remembering
where we were, so that when the machine comes back up, the
operation can continue where it left off. In fact this is almost
impossible to achieve in practice - NFS's solution works in many cases,
but not in all.
</FONT>
<P>
<FONT SIZE="-2">In the UNIX filesystem, a user must obtain a <EM>lock</EM> on a file in
order to read or write to it. In NFS, the same system applies.  A lock
is obtained from a <EM>lock server</EM> on the host where the real disk
filesystem lies and the state of the filesystem is communicated by a
<EM>state server</EM>. NFS is sometimes called a <EM>stateless</EM>
protocol, but this is a misleading title. The state of the filesystem
on the server is maintained on the server which owns the
filesystem. If there is a crash, the server tries to reestablish the
locks it held before the crash. If this is not possible because the
filesystem has changed in the meantime or because of unfortunate
timing, the result is a `stale NFS filehandle' - an unrecoverable
error. The state information has to be cleared and restarted.
</FONT>
<P>
<FONT SIZE="-2">NFS is called stateless because the server does not record the
requests which the client makes (except for locks).  The server
processes requests without caring about which client it is serving, or
about what it has done in previous requests. It doesn't know how much
of a file the client has read.  In other words, it is the client's
responsibility to keep track of what requests it sends to the server
and whether or not it gets a reply.
</FONT>
<P>
<FONT SIZE="-2">NFS version 3 is now in use by some vendors and includes a number of
improvements (and a few new bugs) over NFS. These include better
caching, access control lists (ACLs) etc.
</FONT>
<P>

<H2><A NAME="SECTION00862000000000000000">
7.6.2 AFS - the andrew filesystem</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="5669"></A>
<A NAME="5670"></A>
Another filesystem which is increasingly discussed, is the Andrew file
system. The CERN high energy physics (HEP) group use the AFS as a
global filesystem and many other institutions are starting to follow
suit. Whereas NFS tries to reproduce UNIX-like file semantics across a
network, AFS is a different filesystem altogether. AFS solves the
problem of user authentification between different sites. A problem in
sharing files between different sites around the world is that
usernames and passwords are local to each site. It is possible (though
perhaps unlikely) that very different users around the world might
have the same user ID and login name, and even the same password.
Thus AFS has to take into account the username problem. AFS also has
more advanced caching features to speed up file access and access
control lists (ACLs).  It is in many ways superior to NFS, but whereas
NFS is free software, AFS is a commercial product maintained
by Transarc <A NAME="5671"></A>and is therefore
not in widespread use.
</FONT>
<P>
<FONT SIZE="-2">An improved version of AFS, called DFS has been incorporated into Digital's
Distributed computing environment.
</FONT>
<P>
<FONT SIZE="-2"><A NAME="5672"></A>
<A NAME="5673"></A>
</FONT>
<H2><A NAME="SECTION00863000000000000000">
7.6.3 DCE - the distributed computing environment</A>
</H2>
<P>
<FONT SIZE="-2">The Digital Equipment Corporation's <EM>Distributed Computing
Environment</EM> is, in fact, as complete substitute for Sun's NFS system
from RPC up.  Instead of using Sun's RPC software, DCE uses software
originally developed for the Apollo Domain operating system, called
NCS.  DCE works on top of Domain sockets.
</FONT>
<P>
<FONT SIZE="-2">The open software foundation (OSF) has adopted DCE as its official
network solution, though its on operating system NSF1 still supports
NFS.  One of the features of the DCE system is the concept of <EM>multiple backups</EM> of files. If one server fails, DCE allows another
server to take over. This requires several servers to have disk-copies
of the same files.  This system is efficient on a <EM>read mostly</EM>
filesystem. When a write is made to such a filesystem it must be made
synchronously to <IMG
 WIDTH="15" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$n$"> disks.  Maintaining these copies requires complex
algorithms and a time-consuming copying overhead. DFS/DCE is also now
licensed by Transarc.
</FONT>
<H1><A NAME="SECTION00900000000000000000">
8. Security: design considerations</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="6508"></A>
System security can mean several things. To have system security
we need to protect the system from corruption and we need to
protect the data on the system. There are many reasons why
these need not be secure.
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Malicious users may try to hack into the system to destroy it.
 
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Power failure might bring the system down.
 
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A badly designed system may allow a user to accidentally
destroy important data.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>A system may not be able to function any longer 
because one user
fills up the entire disk with garbage.
</DD>
</DL><FONT SIZE="-2">
Although discussions of security usually concentrate on the first of
these possibilities, the latter two can be equally damaging to the
system in practice.  One can protect against power failure by using
un-interruptable power supplies (UPS). These are units which detect
quickly when the power falls below a certain threshhold and switch to
a battery. Although the battery does not last forever - the UPS gives
a system administrator a chance to halt the system by the proper
route.
</FONT>
<P>
<FONT SIZE="-2">The problem of malicious users has been hightened in recent years by
the growth of international networks.  Anyone connected to a network
can try to log on to almost any machine.  If a machine is very
insecure, they may succeed. In other words - we are not only looking
at out local environment anymore, we must consider potential threats
to system security to come from any source.
</FONT>
<P>
<FONT SIZE="-2">The final point can be controlled by enforcing quotas on how much disk
each user is allowed to use.
</FONT>
<P>

<H1><A NAME="SECTION00910000000000000000">
8.1 Who is responsible?</A>
</H1><FONT SIZE="-2">
System security lies with
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The user.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The system administrator.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>The system designer.
</DD>
</DL><FONT SIZE="-2">
Many would prefer to write this list upside down - but we must be
practical. Usually we are not in a position to ring to the system
designer and say `Hey, that system modeule you wrote is not secure, fix it!'.
The response would at any rate take some time. Rather, we have to learn
to take the system as it comes (pending improvements in later releases)
and make the best of it. All users of the system should be aware of
security issues.
</FONT>
<P>
<FONT SIZE="-2">Ideally, if all users were friendly and thoughtful, everyone would
think about the welfare of the system and try to behave in a
system-friendly way. Unfortunately some users are not friendly, and
accidents can happen even to friendly users.
</FONT>
<P>

<H1><A NAME="SECTION00920000000000000000">
8.2 Passwords and encryption</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="6522"></A>
<A NAME="6523"></A>
The first barrier to malicious users is the password. Every user on a
multiuser system must have a password in order to log on. Passwords
are stored in a coded or <EM>encrypted</EM> form so that other users
cannot read them directly.  Nevertheless, on very many systems, the
coded passwords are readable to all users. Moreover, the algorithm
which encrypts passwords is usable by all users.  This means that
anyone can try to crack the passwords by guessing.
</FONT>
<P>

<H2><A NAME="SECTION00921000000000000000">
8.2.1 UNIX passwords</A>
</H2><FONT SIZE="-2">
In most UNIX systems, passwords and login information are stored in the file
<code>/etc/passwd</code>. This files looks something like this:
</FONT>
<P>
<PRE>
root:99UaPHtxon3uk:0:1:Operator:/:/bin/csh
sundiag:*:0:1:System Diagnostic:/usr/diag/sundiag:/usr/diag/sundiag/sundiag
sysdiag:*:0:1:Old System Diagnostic:/usr/diag/sysdiag:/usr/diag/sysdiag/sysdiag
daemon:*:1:1::/:
sys:*:2:2::/:/bin/csh
bin:*:3:3::/bin:
uucp:*:4:8::/var/spool/uucppublic:
news:*:6:6::/var/spool/news:/bin/csh
audit:*:9:9::/etc/security/audit:/bin/csh
nobody:*:65534:65534:::
+@NISgroup::0:0:::
</PRE><FONT SIZE="-2">
The fields of the file are:
</FONT><PRE>
login name : password : user id: group id : full name : directory : shell
</PRE><FONT SIZE="-2">
i.e. the encrypted password is readable as the second field. The UNIX
standard library command <TT>crypt()</TT> converts a text string into
this coded form.<A NAME="6616"></A>
</FONT>
<P>
<FONT SIZE="-2">When a user types in his or her password, the system does not try to
decrypt the password, but rather <EM>en</EM>crypts the password and
compares the coded forms. The reason for this is that there is no
(publicly) known algorithm for decoding passwords encrypted using
<TT>crypt()</TT>. Just to reverse the process would take hundreds of
thousands of years of CPU time. <TT>crypt</TT> was designed to this way.
</FONT>
<P>
<FONT SIZE="-2">To encrypt a password, <TT>crypt</TT> takes the password string and a
random number, known as a <EM>salt</EM>. 
</FONT>
<P>
<PRE>
code_passwd = crypt (passwd_string,salt);
</PRE><FONT SIZE="-2">
The salt ends up being
the first two characters of the encrypted form of the password.
(If we didn't know the salt, it would be impossible to compute
the same encrypted form more than once!)
</FONT>
<P>
<FONT SIZE="-2">To try to guess passwords automatically, all we have to do is to
send a whole list of guesses as <code>passwd_string</code>, take the
first two characters of the encrypted password as the salt, and
compare the result of the <code>crypt</code> function with the
encrypted form from the password file.
</FONT>
<P>
<FONT SIZE="-2">Elaborate programs have been written to try to crack passwords in this
way. Such programs are useful tools for the system administrator
who should keep an eye on which users have poor passwords. It is
better that the system administrator finds a bad password before a
malicious user does.
</FONT>
<P>
<FONT SIZE="-2">On newer UNIX systems, passwords are stored in a 
<EM>shadow password file</EM>
which is not <code>/etc/passwd</code> but a different non-readable file. Since
normal users cannot read this file, they can only try to
log onto other users' accounts by trial and error.
They cannot compare an encrypted list of their own to the password file.
</FONT>
<P>

<H2><A NAME="SECTION00922000000000000000">
8.2.2 Bad passwords</A>
</H2>
<P>
<FONT SIZE="-2">Surveys of user passwords show that very many users choose extremely
simple passwords. Passwords should be a combination of large and
small letters, numbers
and special symbols like <code>!@#$%^&amp;*</code> etc. Passwords should <EM>not</EM>
be
</FONT>
<OL>
<LI>Your name or anyone else's name (your dog's name!)
</LI>
<LI>Names from books, place names or the name of your computer.
</LI>
<LI>Names of famous people like Einstein, Marx.
</LI>
<LI>Your phone number.
</LI>
<LI>Your birthday.
</LI>
<LI>Your car registration plate
</LI>
<LI>Any personal information which is easily obtained.
</LI>
<LI>Your login name!!
</LI>
<LI>Any word in an English or foreign dictionary.
</LI>
<LI>A keyboard sequence like qwerty.
</LI>
<LI>Any of the above spelled backwards.
</LI>
</OL><FONT SIZE="-2">
Some enhanced
systems take the view that users should not be able to choose
an insecure password, and prevents them from doing so. Most
commercial operating systems don't care whether users have no passwords
at all.
</FONT>
<P>

<H1><A NAME="SECTION00930000000000000000">
8.3 Super-user, or system administrator</A>
</H1>
<P>
<FONT SIZE="-2">The super-user is a <EM>trusted user</EM>. The super-user has unlimited
access to files on a system. He/she is the only user who can halt
the system and is the only user who can make backups of system data.
</FONT>
<P>
<FONT SIZE="-2">Clearly such a user is required:
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>To maintain the system and deal with special circumstances
which arise.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>To create and destroy new and old users.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>To make backups of the system.
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>To install software and system upgrades.
</DD>
</DL><FONT SIZE="-2">
Often system administrators end up doing a lot more than this.
What is important to understand is that the superuser has a highly
responsible position which must not be compromised. The administrator's
account must not be used authorized users. The password is of
crucial importance. The designer of an operating system
must be acutely aware of the need to preserve the security of 
privileged access.
</FONT>
<P>
<FONT SIZE="-2">Under the UNIX system, the superuser is called <code>root</code>.
</FONT>
<P>

<H2><A NAME="SECTION00931000000000000000">
8.3.1 Network administration</A>
</H2>
<P>
<FONT SIZE="-2">Networks make it possible to link computer systems in an unprecedented
way. We can `mount' (see chapter 5) filesystems from one computer
onto another computer across a network and log in to systems all around
the world (if we have an account!). We must ask: what is the role of
the superuser in a networked environment?
</FONT>
<P>
<FONT SIZE="-2">Consider the following. Suppose the administrator of one machine in 
Oslo gets permission from a system in California to access a filesystem
on the Californian machine. When the Oslo administrator mounts
the filesystem on his machine
(without needing to give a password), he sees the files as 
though they were
a part of his system. Now, since root has the rights to all files, it
might seem natural that he would be able to read <EM>and modify</EM>
the files of all users in California. But surely, this is wrong - the
superuser of a machine in Oslo cannot be regarded as a <EM>trusted</EM>
user for a system in California!
</FONT>
<P>
<FONT SIZE="-2">UNIX gets around this problem by mapping the user <code>root</code>
(which has user id <IMG
 WIDTH="13" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$0$"> and all rights) to the user <code>nobody</code>
(which has user id <IMG
 WIDTH="27" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img13.png"
 ALT="$-1$"> and no rights) across a network. This
means that the superuser has rights only on the local machine.
To get rights on another machine, across a network, either special
permission must be given by the remote machine - or the user
must be able to log onto the machine by knowing the <code>root</code>
password.
</FONT>
<P>
<FONT SIZE="-2">As another example of network security - or lack of it - 
let us consider also the X-windows system. 
X is a windowing system which is designed to work transparently over
a network. X works by connecting to a server, anywhere on the network.
Normally the X-server only allows the machine on which it is running
to access the display, but in a network situation it is not unusual
to find users logged in on several different machines. Such a
user wants all the windows to appear on his or her workstation,
so the X server allows certain other named hosts to open windows
on its display.
</FONT>
<P>
<FONT SIZE="-2">Before
the introduction of the <EM>xauthority</EM> mechanism, all security was
based on the <EM>xhost</EM> program. This was <EM>host based</EM> meaning
that anyone using a named host could open windows on the server.
Many users do not understand the X system (which is quite complex) and
simply disable access control by calling <TT>xhost +</TT>. This
allows <EM>any host</EM> in the world to connect to the user's server.
In practice, this means that anyone in the world can view the
picture on such a user's screen. 
</FONT>
<P>
<FONT SIZE="-2">Many programs have not adopted the <EM>xauthority</EM> system which
is <EM>user based</EM>, and so the <EM>xhost</EM> problem is still widespread,
</FONT>
<P>

<H2><A NAME="SECTION00932000000000000000">
8.3.2 Setuid programs in unix</A>
</H2>
<P>
<FONT SIZE="-2"><A NAME="6564"></A>
The superuser <code>root</code> is the only privileged user in UNIX. All other
users have only restricted access to the system. Usually this is desirable,
but sometimes it is a nuisance.
</FONT>
<P>
<FONT SIZE="-2">A set-uid program is a program which has its <EM>setuid-bit</EM> set. 
When such a program is executed by a user, it is run as though that user
were the owner of the program. All of the commands in the program are
executed by the owner and not by the user-id of the person who ran
the program. If the owner of the setuid program id <code>root</code>
then the commands in the program are run with <EM>root privileges</EM>!
</FONT>
<P>
<FONT SIZE="-2">Setuid programs are clearly a touchy security issue. When giving
away one's rights to another user (especially those of <code>root</code>)
one is tempting hackers. Setuid programs must be <EM>secure</EM>.
</FONT>
<P>
<FONT SIZE="-2">A setgid program is almost the same, but only the group id is set to
that of the owner of the file. Often the effect is the same.
</FONT>
<P>
<FONT SIZE="-2">An example of a setuid program is the <code>ps</code> program. <code>ps</code>
lists all of the processes running in the kernel. In order to
do this it needs permission to access the private data structures
in the kernel. By making <code>ps</code> setgid root, it allows ordinary
users to be able to read as much as the writers of <code>ps</code>
thought fit, but no more.
</FONT>
<P>
<FONT SIZE="-2">Naturally, only the superuser can make a file setuid or setgid root.
</FONT>
<P>
<FONT SIZE="-2">Next, we have the problem of what to do with setuid programs which are
read across the network.
If we mount a filesystem across a network, we have no control over
what goes into the file. Suppose then a stupid system administrator,
angry at the world and dying for revenge, made a setuid <EM>root</EM>
program which executed every command every user gave to it - then
suddenly everybody who accessed this file over 
the network would have root access on their local machine!
</FONT>
<P>
<FONT SIZE="-2">Clearly careless setuid programs can be a security risk,
so network-based filesystems give the option of disallowing
setuid programs.
</FONT>
<P>

<H1><A NAME="SECTION00940000000000000000"></A>
<A NAME="6570"></A>
<BR>
8.4 Backups
</H1>
<P>
<FONT SIZE="-2">Accidents happen even to the most careful users. Users delete files
without meaning to, power failure leads to disk corruption, software
bugs can delete files, system administrators can make mistakes - and
of course someone might actually steal your computer!
</FONT>
<P>
<FONT SIZE="-2">User data are the most important part of a computer system - anything
else can be replaced. New disks can be bought, software can be loaded
in afresh - but once user data are gone, they are gone. It is therefore
important to backup user data regularly. From a network vantage
point, it is useful to be able to take backups centrally. In BSD
UNIX, this can be done using the <EM>rdump</EM> command.
</FONT>
<P>
<FONT SIZE="-2">Backing up data is expensive - both in terms of man-hours and in the
cost of storage media. Some systems use secondary disks to keep backups
of important data. The cheaper alternative is to use tape.  Tape comes
in many forms. the most common in use today are
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>Standard -inch tape cartidges.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>EXABYTE 8mm (video tape!)

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD>DAT (Digital audio tape)
</DD>
</DL><FONT SIZE="-2">
Larger systems may also use half-inch tape. Tape machines are becoming
more intelligent and often include compression software in their device
drivers which packs more information into the same space on the tape.
</FONT>
<P>
<FONT SIZE="-2">An EXABYTE video tape with normal compression can hold up to 5GB of data.
Newer drives support 10GB, but device drivers are not easy to come by.
</FONT>
<P>
<FONT SIZE="-2">Depending on how often users actually use the system, it is worth
considering making backups
</FONT><DL COMPACT>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Every night.</EM> The most important data should be backed up at least as often as significant changes are made.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Every week.</EM> Less important data might only be worth
backing up once a week.

<P>
</DD>
<DT><IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$\bullet$"></DT>
<DD><EM>Every month.</EM> For convenience you might want to record
the setup of your system software once in a while - even though this
can be loaded in again from source.
</DD>
</DL><FONT SIZE="-2">
Backup software is usually intelligent enough to be able to extract
only files which have been modified since the last backup, so
daily backups need not copy every file every night.
</FONT>
<P>
<FONT SIZE="-2">How long should you keep a backup?
It might take some time to discover that a file is gone. How long you
keep backup tapes depends on how long you value your data. A year
is not an unreasoable length of time.
</FONT>
<P>

<H1><A NAME="SECTION00950000000000000000">
8.5 Intruders: Worms and Viruses</A>
</H1>
<P>
<FONT SIZE="-2">Worms and viruses are intruder programs which enter a system
illegally and take hold of the system in some way. <A NAME="6584"></A>
<A NAME="6585"></A>
</FONT>
<P>
<FONT SIZE="-2">A <EM>virus</EM> is a piece of code which attaches itself to another program
in order to get executed surreptitiously.
</FONT>
<P>
<FONT SIZE="-2">A <EM>worm</EM> is a program which propagates from computer to computer,
without necessarily changing anything. 
</FONT>
<P>
<FONT SIZE="-2">Other kinds of intruders are <EM>Trojan horses</EM> i.e. programs which
masqeuerade as something they are not, <EM>bacteria</EM>, which
simply copy themselves in order to overwhelm the system and <EM>logic
bombs</EM> which go off when some condition is met. Multiuser systems
are generally harder to affect with intruders than microcomputers
since the operating system exercises a much greater level of
control.
</FONT>
<P>

<H2><A NAME="SECTION00951000000000000000"></A><A NAME="6592"></A><A NAME="6593"></A>
<BR>
8.5.1 Back doors
</H2><FONT SIZE="-2">
Back doors or Trojan horses are faults in the system software, which
devious programs can use to gain access to the system from outside. In
most cases these are network based programs. Most intruders enter via
a network, but on small computers which use floppy disks or diskettes,
they can also enter on disk.
</FONT>
<P>
<FONT SIZE="-2">Some program have become well-known backdoors in the UNIX world.
<EM>sendmail</EM> is one. Many backdoors are setuid root programs which
contain bugs that can be exploited by clever users, so that
these users can gain privileged access.
</FONT>
<P>
<FONT SIZE="-2">How do we know when an intruder is on the system? This is an extremely
difficult problem - there are many ways to hide intruders, so that -
if one is not specificaly thinking about the possibility of threats,
it is easy to miss them. 
</FONT>
<P>
<FONT SIZE="-2">On UNIX inspired systems, the command <TT>netstat</TT> shows a list of
machines which are connected to the system. It gives a listing
as follows:
</FONT>
<P>
<FONT SIZE="-2"></FONT><PRE>
Active Internet connections
Proto Recv-Q Send-Q  Local Address       Foreign Address        (state)
tcp        0      0  saga.1147           xantos-7.6000          ESTABLISHED
tcp        0      0  saga.1146           xantos-7.6000          ESTABLISHED
tcp        0      0  saga.1145           xantos-7.6000          ESTABLISHED
tcp        0      0  saga.1144           xantos-7.6000          ESTABLISHED
tcp        0      0  saga.1143           njal.6000              ESTABLISHED
tcp        0      0  saga.1141           njal.6000              ESTABLISHED
tcp        0      0  saga.1138           njal.6000              ESTABLISHED
tcp        0      0  saga.1132           xantos-2.6000          ESTABLISHED
tcp        0      0  saga.1130           xantos-2.6000          ESTABLISHED
tcp        0      0  saga.1125           128.39.89.24.6000      FIN_WAIT_1
tcp        0      4  saga.1120           128.39.89.24.6000      FIN_WAIT_1
tcp        0      0  saga.1022           anyon.uio.no.login     ESTABLISHED
tcp        0      0  saga.1094           xantos-7.6000          ESTABLISHED
tcp        0      0  saga.1086           xantos-4.6000          ESTABLISHED
tcp        0      0  saga.1023           anyon.uio.no.login     ESTABLISHED
tcp        0      0  saga.1080           xantos-4.6000          ESTABLISHED
</PRE><FONT SIZE="-2"></FONT>
<P>
<FONT SIZE="-2">This gives an indication of who is currently connected. Of course, intruders
could connect when you are not watching, so another thing to do is to
monitor all the connections made to your machine
continuously and dump the result to a file. This requires a
considerable amount of storage and some skill in interpreting the data.
The program <TT>tcpdump</TT> will do this. Sun have their own version
called <EM>etherfind</EM>.
</FONT>
<P>
<FONT SIZE="-2">On the other hand, we cannot live in a
perpetual state of paranoia, thinking that everyone is out to get us.
A balance must be struck by <EM>taking all reasonable precautions</EM>
and <EM>being aware of the problem</EM>. Finally, the super-user should
never install software which is of suspicious or unknown origin.
</FONT>
<P>

<H1><A NAME="SECTION00960000000000000000">
8.6 Firewall</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="6603"></A>One way of designing a network to protect it
from attack is to use a machine as a ``firewall''. That is - a
barrier to stop the spread of network threats. The idea is to isolate
important machines by placing another highly secure machine between
the outside world and the local network.  The firewall is the only
machine which is connected to a wide area network. It is also
connected to the local area network, but it does not forward packets
to the local network and vice versa. Thus sensitive data can be hidden
behind the firewall, where they can be shared on the local network but
not by the external network.
</FONT>
<P>

<H1><A NAME="SECTION00970000000000000000">
8.7 Public and Private Keys</A>
</H1>
<P>
<FONT SIZE="-2"><A NAME="6605"></A>
<A NAME="6606"></A>
A clever intruder could always behave as an imposter - arranging it so
that it appeared that a network request came from a trusted machine,
when in fact it came from the intruder's machine. Moreover,
one could easily make a device which collected all the information
which was sent over a network and analyzed it to find out what was
being said - and to whom.
</FONT>
<P>
<FONT SIZE="-2">To try to prevent such problems from occurring, we can use a system
of data encryption (coding). The idea is to encode all data using a special
key. Both the sender and the receiver need to know the key - the
encryption and decryption algorithms are publicly known.
</FONT>
<P>
<FONT SIZE="-2">The problem is then to agree on a key. This can be achieved using
<EM>public and private keys</EM>. 
</FONT>
<P>
<FONT SIZE="-2">Two parties wish
to communicate with one another in private, so they encrypt the data
they send over the network. Each host has a <EM>private key</EM> which
is a large number which is encrypted with the user's password and stored
in a database. 
Each user also
has a public key, which anyone can look up in a database. 
</FONT>
<P>
<FONT SIZE="-2">In order to exchange information, both the sender and the receiver need
to have the correct key. 
The ingeneous part is that, both parties combine their private keys
with the others' public keys and end up with a <EM>conversation key</EM>
which they both agree on. To decode a message they only need the
conversation key and their own private key. The coding algorithm is
based on some inspired mathematics of modulo arithmetic.
</FONT>
<P>
<FONT SIZE="-2">Party A knows that party B is who he claims to be because
</FONT>
<OL>
<LI>The message sent to A was encrypted using the conversation key.
</LI>
<LI>The only way that B could generate the conversation key would be
by knowing A's public key and B's private key.
</LI>
<LI>To know B's private key, B's password is needed.
</LI>
</OL>
<P>
<FONT SIZE="-2">Because the key encryption is quite time consuming and difficult, it
is only used to establish an initial connection and conversation key.
Once the conversation key is known, normal <code>crypt()</code> type
encryption is used for passing data.
This key encryption scheme is the basis of secure communication
links like SSL (Secure socket layer)<A NAME="6612"></A> and PGP (Pretty
Good Privacy).
</FONT>
<P>

<H1><A NAME="SECTION001000000000000000000">
Where next?</A>
</H1>
<P>
<FONT SIZE="-2">There are many topics which have only been covered superficially
in this introduction. A deeper understanding of networks
and system administration can be found in
</FONT>
<P>
<PRE>
  http://www.iu.hioslo.no/~mark/lectures
</PRE>
<P>
<FONT SIZE="-2"></FONT>
<P>

<H1><A NAME="SECTION001010000000000000000">
Glossary</A>
</H1>
<P>

<UL>
<LI><B>Assembler</B>: An assembler is a program which converts assembly language
into machine code. Assembly language is a mnemonic (symbolic) form of
the numerical machine code. Each instruction corresponds to one machine code
instruction.

<P>
</LI>
<LI><B>Bits</B>: Binary-digits. 1's and 0's.

<P>
</LI>
<LI><B>Buffer</B>: Waiting area for data. A buffer is used to synchronize the
arrival of data from a device with the eventual reading of the data by a
program.

<P>
</LI>
<LI><B>Clock cycles</B>: The system clock is an inmportant part of the hardware
of a computer. The clock works like a pump, driving the CPU to execute
intstructions. On earlt microprocessors, each instruction tool several
cycles of the system clock. Newer RISC processors can execute a whole
instruction per clock cycle, and some can even perform several instructions
per clock cycle, by ingeneous design of the hardware.

<P>
</LI>
<LI><B>Compiler</B>: A program which converts a high level language into machine
code.

<P>
</LI>
<LI><B>Concurrent.</B>: This is distinct from parallel. Processes which have
the appreance of being executed simultaneously, because the system
can perform time-sharing, are called concurrent processes.

<P>
</LI>
<LI><B>CPU</B>: Central processor unit. This is the chip which adds numbers together
and moves data around in the memory. Parallel computers have several CPUs.

<P>
</LI>
<LI><B>Fragmentation</B>: Data are said to be fragmented when parts of the
data exist in very different locations, joined together by pointers. Fragmentation occurs because the OS must find a free space whereever it
can. Ideally, data would alway be stored in contiguous blocks, but
in practice files may be deleted, leaving holes in the data which must
then be filled up by the OS.

<P>
</LI>
<LI><B>Handshaking</B>: A system of signals between two processes/computers
which allows them to tell each other when to start and stop sending
information.

<P>
</LI>
<LI><B>Host</B>: A machine, computer.

<P>
</LI>
<LI><B>ID</B>: Identifier. A name or number which refers to something -
often a process or a user.

<P>
</LI>
<LI><B>I/O</B>: Input/output.

<P>
</LI>
<LI><B>IPC</B>: Inter-process communication. A mechanism by which unix processes
can exchange data with one another. See also RPC.

<P>
</LI>
<LI><B>kernel</B>: The core of a multitasking operating system which deals
with the basic system resources. The kernel drives physical devices
and handles I/O, memory management and process scheduling.

<P>
</LI>
<LI><B>Loopback</B>: The loopback device is a pseudo network device in
the UNIX operating system which, rather than sending data out onto a 
physical network, sends packets straight back into the system. The
protocols for talking to the loopback device are the same as those for
the physical network, so programs employing interprocess communication
have only to hold to a single standard, regardless of whether the
processes are on the same machine, or on different machines.

<P>
</LI>
<LI><B>Machine code</B>: The basic numerical language of codes which
the CPU understands. Compilers and assemblers convert programs into
machine code.

<P>
</LI>
<LI><B>Multiplex</B>: To switch between several activities or devices.

<P>
</LI>
<LI><B>Multi-user system</B>: An operating system where several users can use
the system simultaneously.

<P>
</LI>
<LI><B>OS</B>: Operating system.

<P>
</LI>
<LI><B>Parallel</B>: Parallel processes are not merely timeshared (concurrent)
but actually run simultaneously on different CPUs.

<P>
</LI>
<LI><B>Pixel</B>: A single dot on the screen. This is one `grain' - or the
object of maximum resolution.

<P>
</LI>
<LI><B>Primary memory</B>: RAM internal memory (see secondary memory).

<P>
</LI>
<LI><B>Primitive</B>: A very low level function or routine. A basic element
in a library of functions.

<P>
</LI>
<LI><B>RISC</B>: Reduced instruction set chip. This is part of a new philosophy
to make microprocessors faster by giving them fewer (less complicated)
instructions which are optimized to run very fast. Usually each instruction
completes in a single clock cycle.

<P>
</LI>
<LI><B>RPC</B>: Remote Procedure Call. This is a mechanism for executing
tasks on remote machines across the network. The RPC protocol makes
use of the XDR (external data representation) protocol for passing
data. It is a relatively high level interface between networked machines.

<P>
</LI>
<LI><B>Secondary memory</B>: Disk or tape storage.

<P>
</LI>
<LI><B>Semantics</B>: This term is used to describe the `method
of operation' of a particular system. The prescribed way in which
a particular system is supposed to behave. The logic of operation
of the system.

<P>
</LI>
<LI><B>Single-user system</B>: A system in which only one user can use the
system at a time.

<P>
</LI>
<LI><B>Starvation</B>: A process is said to starve if it never gets a share
of the CPU. This can occur is there are errors or deadlocks in scheduling.

<P>
</LI>
<LI><B>Transparently</B>: This word is often used to mean that something happens
without anyone needing to know the details about <EM>how</EM> it happens.
For example, the OS handles timesharing transparently - i.e. without
users needing to know about how it happens.

<P>
</LI>
<LI><B>Vector</B>: An array of data or a segment of memory.

<P>
</LI>
<LI><B>Virtual</B>: Almost, a likeness of, simulated.
</LI>
</UL><FONT SIZE="-2">
</FONT>
<P>
<FONT SIZE="-2"></FONT>
<BR>

<H2><A NAME="SECTION001100000000000000000">
Index</A>
</H2>
<DL COMPACT>
<DD><DT><A NAME="tex2html351"
 HREF="os.html#6616"><STRONG><TT>crypt()</TT></STRONG></A>
<DT><A NAME="tex2html143"
 HREF="os.html#1420"><STRONG><TT>fork()</TT></STRONG></A>
<DT><A NAME="tex2html204"
 HREF="os.html#3080"><STRONG><TT>malloc()</TT></STRONG></A>
<DT><A NAME="tex2html144"
 HREF="os.html#1421"><STRONG><TT>wait()</TT></STRONG></A>
<DT><A NAME="tex2html258"
 HREF="os.html#3020"><STRONG>Access control lists</STRONG></A>
<DT><A NAME="tex2html153"
 HREF="os.html#1229"><STRONG>Accounting</STRONG></A>
<DT><A NAME="tex2html66"
 HREF="os.html#549"><STRONG>Accumulator</STRONG></A>
<DT><A NAME="tex2html257"
 HREF="os.html#3019"><STRONG>ACL</STRONG></A>
<DT><A NAME="tex2html183"
 HREF="os.html#2333"><STRONG>Address</STRONG></A>
<DT><A NAME="tex2html189"
 HREF="os.html#2353"><STRONG>Address binding</STRONG></A>
<DT><A NAME="tex2html332"
 HREF="os.html#5643"><STRONG>Address resolution</STRONG></A>
<DT><A NAME="tex2html343"
 HREF="os.html#5669"><STRONG>AFS</STRONG></A>
<DT><A NAME="tex2html207"
 HREF="os.html#2527"><STRONG>Alignment</STRONG></A>
<DT><A NAME="tex2html16"
 HREF="os.html#57"><STRONG>AmigaDOS</STRONG></A>
<A NAME="tex2html240"
 HREF="os.html#2942">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html344"
 HREF="os.html#5670"><STRONG>Andrew file system</STRONG></A>
<DT><A NAME="tex2html294"
 HREF="os.html#5334"><STRONG>Application layer</STRONG></A>
<DT><A NAME="tex2html317"
 HREF="os.html#5521"><STRONG>ARP</STRONG></A>
<DT><A NAME="tex2html160"
 HREF="os.html#1275"><STRONG>ASMP</STRONG></A>
<DT><A NAME="tex2html161"
 HREF="os.html#1276"><STRONG>Asymmetric multiprocessing</STRONG></A>
<DT><A NAME="tex2html81"
 HREF="os.html#601"><STRONG>Asynchronous I/O</STRONG></A>
<DT><A NAME="tex2html18"
 HREF="os.html#60"><STRONG>AT&amp;T</STRONG></A>
<DT><A NAME="tex2html86"
 HREF="os.html#783"><STRONG>Authentication</STRONG></A>
<DT><A NAME="tex2html356"
 HREF="os.html#6592"><STRONG>Back door</STRONG></A>
<DT><A NAME="tex2html353"
 HREF="os.html#6570"><STRONG>Backups</STRONG></A>
<DT><A NAME="tex2html114"
 HREF="os.html#1052"><STRONG>Batch</STRONG></A>
<DT><A NAME="tex2html24"
 HREF="os.html#71"><STRONG>Be Box</STRONG></A>
<DT><A NAME="tex2html321"
 HREF="os.html#5536"><STRONG>BIND</STRONG></A>
<DT><A NAME="tex2html12"
 HREF="os.html#51"><STRONG>BIOS</STRONG></A>
<DT><A NAME="tex2html29"
 HREF="os.html#82"><STRONG>Black boxes</STRONG></A>
<DT><A NAME="tex2html262"
 HREF="os.html#3041"><STRONG>Block allocation</STRONG></A>
<DT><A NAME="tex2html261"
 HREF="os.html#3035"><STRONG>Blocks</STRONG></A>
<DT><A NAME="tex2html337"
 HREF="os.html#5652"><STRONG>British Telecom</STRONG></A>
<DT><A NAME="tex2html338"
 HREF="os.html#5656"><STRONG>Broadcast address</STRONG></A>
<A NAME="tex2html326"
 HREF="os.html#5544">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html19"
 HREF="os.html#61"><STRONG>BSD unix</STRONG></A>
<DT><A NAME="tex2html77"
 HREF="os.html#596"><STRONG>Buffer</STRONG></A>
<DT><A NAME="tex2html173"
 HREF="os.html#1343"><STRONG>Busy
waiting</STRONG></A>
<DT><A NAME="tex2html245"
 HREF="os.html#2951"><STRONG>C-SCAN algorithm</STRONG></A>
<DT><A NAME="tex2html40"
 HREF="os.html#115"><STRONG>C-shell resources</STRONG></A>
<DT><A NAME="tex2html41"
 HREF="os.html#119"><STRONG>Caching</STRONG></A>
<DT><A NAME="tex2html45"
 HREF="os.html#127"><STRONG>CISC</STRONG></A>
<DT><A NAME="tex2html102"
 HREF="os.html#844"><STRONG>CLI</STRONG></A>
<DT><A NAME="tex2html266"
 HREF="os.html#4796"><STRONG>Client server model</STRONG></A>
<DT><A NAME="tex2html44"
 HREF="os.html#126"><STRONG>Clock cycles</STRONG></A>
<DT><A NAME="tex2html4"
 HREF="os.html#33"><STRONG>Command language</STRONG></A>
<DT><A NAME="tex2html33"
 HREF="os.html#96"><STRONG>Communication</STRONG></A>
<DT><A NAME="tex2html307"
 HREF="os.html#5405"><STRONG>Connection oriented socket</STRONG></A>
<DT><A NAME="tex2html308"
 HREF="os.html#5406"><STRONG>Connectionless socket</STRONG></A>
<DT><A NAME="tex2html130"
 HREF="os.html#1115"><STRONG>Context switching</STRONG></A>
<A NAME="tex2html198"
 HREF="os.html#2436">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html101"
 HREF="os.html#839"><STRONG>Core</STRONG></A>
<DT><A NAME="tex2html42"
 HREF="os.html#122"><STRONG>CPU</STRONG></A>
<DT><A NAME="tex2html115"
 HREF="os.html#1062"><STRONG>CPU burst</STRONG></A>
<DT><A NAME="tex2html235"
 HREF="os.html#2931"><STRONG>CRC</STRONG></A>
<DT><A NAME="tex2html172"
 HREF="os.html#1337"><STRONG>Critical sections</STRONG></A>
<DT><A NAME="tex2html236"
 HREF="os.html#2932"><STRONG>Cyclic redundancy check</STRONG></A>
<DT><A NAME="tex2html226"
 HREF="os.html#2901"><STRONG>Cylinder</STRONG></A>
<DT><A NAME="tex2html249"
 HREF="os.html#2963"><STRONG>Cylinder groups</STRONG></A>
<DT><A NAME="tex2html103"
 HREF="os.html#848"><STRONG>Daemons</STRONG></A>
<DT><A NAME="tex2html288"
 HREF="os.html#5321"><STRONG>Data links layer</STRONG></A>
<DT><A NAME="tex2html35"
 HREF="os.html#98"><STRONG>Data types</STRONG></A>
<DT><A NAME="tex2html300"
 HREF="os.html#5388"><STRONG>Datagram</STRONG></A>
<DT><A NAME="tex2html178"
 HREF="os.html#1358"><STRONG>Deadlock</STRONG></A>
<DT><A NAME="tex2html180"
 HREF="os.html#1377"><STRONG>Deadlock prevention</STRONG></A>
<DT><A NAME="tex2html233"
 HREF="os.html#2922"><STRONG>Defect list</STRONG></A>
<DT><A NAME="tex2html212"
 HREF="os.html#2738"><STRONG>Demand paging</STRONG></A>
<DT><A NAME="tex2html51"
 HREF="os.html#139"><STRONG>Device driver</STRONG></A>
<DT><A NAME="tex2html230"
 HREF="os.html#2911"><STRONG>Device ID's</STRONG></A>
<DT><A NAME="tex2html49"
 HREF="os.html#134"><STRONG>Devices</STRONG></A>
<DT><A NAME="tex2html346"
 HREF="os.html#5672"><STRONG>DFS</STRONG></A>
<DT><A NAME="tex2html83"
 HREF="os.html#605"><STRONG>Direct memory access</STRONG></A>
<DT><A NAME="tex2html260"
 HREF="os.html#3034"><STRONG>Disk blocks</STRONG></A>
<DT><A NAME="tex2html238"
 HREF="os.html#2937"><STRONG>Disk scheduling</STRONG></A>
<DT><A NAME="tex2html225"
 HREF="os.html#2900"><STRONG>Disk surface</STRONG></A>
<DT><A NAME="tex2html347"
 HREF="os.html#5673"><STRONG>Distributed file system (DFS)</STRONG></A>
<DT><A NAME="tex2html339"
 HREF="os.html#5658"><STRONG>Distributed file systems</STRONG></A>
<DT><A NAME="tex2html194"
 HREF="os.html#2375"><STRONG>DLLs</STRONG></A>
<DT><A NAME="tex2html82"
 HREF="os.html#604"><STRONG>DMA</STRONG></A>
<DT><A NAME="tex2html322"
 HREF="os.html#5537"><STRONG>DNS</STRONG></A>
<A NAME="tex2html329"
 HREF="os.html#5636">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html323"
 HREF="os.html#5538"><STRONG>Domain name service</STRONG></A>
<A NAME="tex2html330"
 HREF="os.html#5637">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html10"
 HREF="os.html#49"><STRONG>DOS</STRONG></A>
<DT><A NAME="tex2html295"
 HREF="os.html#5337"><STRONG>Encapsulation of data</STRONG></A>
<DT><A NAME="tex2html350"
 HREF="os.html#6523"><STRONG>Encryption</STRONG></A>
<DT><A NAME="tex2html5"
 HREF="os.html#35"><STRONG>Entry points to OS code</STRONG></A>
<DT><A NAME="tex2html56"
 HREF="os.html#147"><STRONG>Exceptions</STRONG></A>
<DT><A NAME="tex2html149"
 HREF="os.html#1223"><STRONG>FCFS</STRONG></A>
<A NAME="tex2html237"
 HREF="os.html#2936">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html123"
 HREF="os.html#1080">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html311"
 HREF="os.html#5464"><STRONG>FDDI</STRONG></A>
<DT><A NAME="tex2html150"
 HREF="os.html#1224"><STRONG>FIFO</STRONG></A>
<A NAME="tex2html217"
 HREF="os.html#2754">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html79"
 HREF="os.html#598">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html122"
 HREF="os.html#1079">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html171"
 HREF="os.html#1329"><STRONG>File locks</STRONG></A>
<DT><A NAME="tex2html256"
 HREF="os.html#3011"><STRONG>File permissions</STRONG></A>
<DT><A NAME="tex2html253"
 HREF="os.html#3002"><STRONG>File types</STRONG></A>
<DT><A NAME="tex2html254"
 HREF="os.html#3003"><STRONG>Filename extensions</STRONG></A>
<DT><A NAME="tex2html234"
 HREF="os.html#2927"><STRONG>Filesystem</STRONG></A>
<A NAME="tex2html59"
 HREF="os.html#186">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html358"
 HREF="os.html#6603"><STRONG>Firewall</STRONG></A>
<DT><A NAME="tex2html124"
 HREF="os.html#1081"><STRONG>First come first served</STRONG></A>
<DT><A NAME="tex2html78"
 HREF="os.html#597"><STRONG>First in first out</STRONG></A>
<DT><A NAME="tex2html239"
 HREF="os.html#2940"><STRONG>Floppy disks</STRONG></A>
<DT><A NAME="tex2html232"
 HREF="os.html#2921"><STRONG>Formatting</STRONG></A>
<A NAME="tex2html229"
 HREF="os.html#2906">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html206"
 HREF="os.html#2526"><STRONG>Fragmentation</STRONG></A>
<DT><A NAME="tex2html302"
 HREF="os.html#5392"><STRONG>Fragments (network)</STRONG></A>
<DT><A NAME="tex2html199"
 HREF="os.html#2437"><STRONG>Frame table</STRONG></A>
<DT><A NAME="tex2html275"
 HREF="os.html#4847"><STRONG>Ftp</STRONG></A>
<DT><A NAME="tex2html328"
 HREF="os.html#5629"><STRONG>Gateway</STRONG></A>
<DT><A NAME="tex2html287"
 HREF="os.html#5320"><STRONG>Handshaking</STRONG></A>
<DT><A NAME="tex2html22"
 HREF="os.html#64"><STRONG>Hewlett Packard</STRONG></A>
<DT><A NAME="tex2html252"
 HREF="os.html#2987"><STRONG>Hierarchical filesystems</STRONG></A>
<DT><A NAME="tex2html27"
 HREF="os.html#77"><STRONG>High level</STRONG></A>
<DT><A NAME="tex2html116"
 HREF="os.html#1064"><STRONG>I/O burst</STRONG></A>
<DT><A NAME="tex2html31"
 HREF="os.html#90"><STRONG>I/O sharing</STRONG></A>
<DT><A NAME="tex2html67"
 HREF="os.html#550"><STRONG>Index register</STRONG></A>
<DT><A NAME="tex2html299"
 HREF="os.html#5345"><STRONG>Internet protocol</STRONG></A>
<DT><A NAME="tex2html136"
 HREF="os.html#1129"><STRONG>Interprocess communication</STRONG></A>
<DT><A NAME="tex2html185"
 HREF="os.html#2339"><STRONG>Interrupt vector</STRONG></A>
<A NAME="tex2html76"
 HREF="os.html#591">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html13"
 HREF="os.html#53"><STRONG>Interrupts</STRONG></A>
<A NAME="tex2html75"
 HREF="os.html#587">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html54"
 HREF="os.html#145">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html319"
 HREF="os.html#5525"><STRONG>IP address</STRONG></A>
<DT><A NAME="tex2html135"
 HREF="os.html#1128"><STRONG>IPC</STRONG></A>
<DT><A NAME="tex2html320"
 HREF="os.html#5526"><STRONG>IPV4</STRONG></A>
<DT><A NAME="tex2html312"
 HREF="os.html#5465"><STRONG>ISDN</STRONG></A>
<DT><A NAME="tex2html284"
 HREF="os.html#5307"><STRONG>ISO</STRONG></A>
<DT><A NAME="tex2html113"
 HREF="os.html#1051"><STRONG>Job</STRONG></A>
<DT><A NAME="tex2html100"
 HREF="os.html#838"><STRONG>Kernel</STRONG></A>
<DT><A NAME="tex2html72"
 HREF="os.html#573"><STRONG>Last in first out</STRONG></A>
<DT><A NAME="tex2html213"
 HREF="os.html#2739"><STRONG>Lazy evaluation</STRONG></A>
<DT><A NAME="tex2html221"
 HREF="os.html#2813"><STRONG>Least recently used algorithm</STRONG></A>
<DT><A NAME="tex2html71"
 HREF="os.html#572"><STRONG>LIFO</STRONG></A>
<DT><A NAME="tex2html110"
 HREF="os.html#1058"><STRONG>Lightweight process</STRONG></A>
<DT><A NAME="tex2html164"
 HREF="os.html#1293"><STRONG>Lightweight processes</STRONG></A>
<DT><A NAME="tex2html23"
 HREF="os.html#70"><STRONG>Linux</STRONG></A>
<DT><A NAME="tex2html191"
 HREF="os.html#2361"><STRONG>Loader</STRONG></A>
<DT><A NAME="tex2html138"
 HREF="os.html#1140"><STRONG>Locks</STRONG></A>
<DT><A NAME="tex2html50"
 HREF="os.html#136"><STRONG>Logical device</STRONG></A>
<DT><A NAME="tex2html181"
 HREF="os.html#2330"><STRONG>Logical memory</STRONG></A>
<DT><A NAME="tex2html246"
 HREF="os.html#2952"><STRONG>LOOK algorithm</STRONG></A>
<DT><A NAME="tex2html28"
 HREF="os.html#79"><STRONG>Low level</STRONG></A>
<DT><A NAME="tex2html220"
 HREF="os.html#2812"><STRONG>LRU</STRONG></A>
<DT><A NAME="tex2html134"
 HREF="os.html#1122"><STRONG>Mach</STRONG></A>
<DT><A NAME="tex2html15"
 HREF="os.html#55"><STRONG>MacIntosh</STRONG></A>
<A NAME="tex2html14"
 HREF="os.html#54">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html196"
 HREF="os.html#2387"><STRONG>Memory management unit</STRONG></A>
<DT><A NAME="tex2html70"
 HREF="os.html#553"><STRONG>Memory map</STRONG></A>
<DT><A NAME="tex2html184"
 HREF="os.html#2337"><STRONG>Memory mapped I/O</STRONG></A>
<DT><A NAME="tex2html131"
 HREF="os.html#1117"><STRONG>MMU</STRONG></A>
<A NAME="tex2html195"
 HREF="os.html#2386">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html95"
 HREF="os.html#813"><STRONG>Monitor mode</STRONG></A>
<DT><A NAME="tex2html177"
 HREF="os.html#1354"><STRONG>Monitors</STRONG></A>
<DT><A NAME="tex2html17"
 HREF="os.html#58"><STRONG>MTS</STRONG></A>
<DT><A NAME="tex2html84"
 HREF="os.html#779"><STRONG>Multi tasking OS</STRONG></A>
<DT><A NAME="tex2html7"
 HREF="os.html#39"><STRONG>Multi user mode</STRONG></A>
<DT><A NAME="tex2html106"
 HREF="os.html#859"><STRONG>Multiple processors</STRONG></A>
<DT><A NAME="tex2html9"
 HREF="os.html#43"><STRONG>Multitasking system</STRONG></A>
<DT><A NAME="tex2html169"
 HREF="os.html#1321"><STRONG>Mutex</STRONG></A>
<DT><A NAME="tex2html170"
 HREF="os.html#1322"><STRONG>Mutual exclusion</STRONG></A>
<DT><A NAME="tex2html333"
 HREF="os.html#5646"><STRONG>Name
server</STRONG></A>
<DT><A NAME="tex2html325"
 HREF="os.html#5543"><STRONG>Netmask</STRONG></A>
<DT><A NAME="tex2html341"
 HREF="os.html#5662"><STRONG>Network filesystem</STRONG></A>
<DT><A NAME="tex2html335"
 HREF="os.html#5650"><STRONG>Network information service</STRONG></A>
<DT><A NAME="tex2html289"
 HREF="os.html#5323"><STRONG>Network layer</STRONG></A>
<DT><A NAME="tex2html340"
 HREF="os.html#5661"><STRONG>NFS</STRONG></A>
<DT><A NAME="tex2html334"
 HREF="os.html#5649"><STRONG>NIS</STRONG></A>
<DT><A NAME="tex2html25"
 HREF="os.html#72"><STRONG>NT</STRONG></A>
<DT><A NAME="tex2html156"
 HREF="os.html#1238"><STRONG>Object orientation</STRONG></A>
<DT><A NAME="tex2html3"
 HREF="os.html#29"><STRONG>Operating system</STRONG></A>
<DT><A NAME="tex2html285"
 HREF="os.html#5309"><STRONG>OSI</STRONG></A>
<DT><A NAME="tex2html38"
 HREF="os.html#111"><STRONG>Overhead</STRONG></A>
<DT><A NAME="tex2html214"
 HREF="os.html#2744"><STRONG>Page fault</STRONG></A>
<DT><A NAME="tex2html200"
 HREF="os.html#2438"><STRONG>Page table</STRONG></A>
<DT><A NAME="tex2html197"
 HREF="os.html#2414"><STRONG>Pages</STRONG></A>
<DT><A NAME="tex2html215"
 HREF="os.html#2746"><STRONG>Paging algorithms</STRONG></A>
<DT><A NAME="tex2html187"
 HREF="os.html#2350"><STRONG>Paging memory banks</STRONG></A>
<DT><A NAME="tex2html210"
 HREF="os.html#2731"><STRONG>Paging to disk</STRONG></A>
<DT><A NAME="tex2html105"
 HREF="os.html#858"><STRONG>Parallelism</STRONG></A>
<DT><A NAME="tex2html248"
 HREF="os.html#2962"><STRONG>Partitions</STRONG></A>
<DT><A NAME="tex2html349"
 HREF="os.html#6522"><STRONG>Passords</STRONG></A>
<DT><A NAME="tex2html132"
 HREF="os.html#1120"><STRONG>PCB</STRONG></A>
<DT><A NAME="tex2html255"
 HREF="os.html#3010"><STRONG>Permissions and access on files</STRONG></A>
<DT><A NAME="tex2html286"
 HREF="os.html#5317"><STRONG>Physical layer</STRONG></A>
<DT><A NAME="tex2html182"
 HREF="os.html#2331"><STRONG>Physical memory</STRONG></A>
<DT><A NAME="tex2html297"
 HREF="os.html#5343"><STRONG>Port number</STRONG></A>
<DT><A NAME="tex2html272"
 HREF="os.html#4838"><STRONG>Ports</STRONG></A>
<DT><A NAME="tex2html162"
 HREF="os.html#1282"><STRONG>POSIX threads</STRONG></A>
<DT><A NAME="tex2html125"
 HREF="os.html#1087"><STRONG>Preemptive multitasking</STRONG></A>
<DT><A NAME="tex2html293"
 HREF="os.html#5332"><STRONG>Presentation layer</STRONG></A>
<DT><A NAME="tex2html46"
 HREF="os.html#130"><STRONG>Primary memory</STRONG></A>
<DT><A NAME="tex2html129"
 HREF="os.html#1105"><STRONG>Priorities</STRONG></A>
<DT><A NAME="tex2html360"
 HREF="os.html#6606"><STRONG>Private key</STRONG></A>
<DT><A NAME="tex2html91"
 HREF="os.html#795"><STRONG>Privileged user</STRONG></A>
<DT><A NAME="tex2html111"
 HREF="os.html#1047"><STRONG>Process</STRONG></A>
<A NAME="tex2html108"
 HREF="os.html#1041">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html133"
 HREF="os.html#1121"><STRONG>Process control block</STRONG></A>
<DT><A NAME="tex2html140"
 HREF="os.html#1144"><STRONG>Process creation</STRONG></A>
<DT><A NAME="tex2html142"
 HREF="os.html#1155"><STRONG>Process hierarchy</STRONG></A>
<DT><A NAME="tex2html146"
 HREF="os.html#1181"><STRONG>Process states</STRONG></A>
<DT><A NAME="tex2html265"
 HREF="os.html#4777"><STRONG>Protocol</STRONG></A>
<A NAME="tex2html36"
 HREF="os.html#109">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html283"
 HREF="os.html#5306"><STRONG>Protocols</STRONG></A>
<A NAME="tex2html34"
 HREF="os.html#97">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html163"
 HREF="os.html#1283"><STRONG>Pthreads</STRONG></A>
<DT><A NAME="tex2html359"
 HREF="os.html#6605"><STRONG>Public key</STRONG></A>
<DT><A NAME="tex2html119"
 HREF="os.html#1070"><STRONG>queue</STRONG></A>
<DT><A NAME="tex2html147"
 HREF="os.html#1196"><STRONG>Queue scheduling</STRONG></A>
<DT><A NAME="tex2html152"
 HREF="os.html#1228"><STRONG>Quotas</STRONG></A>
<DT><A NAME="tex2html47"
 HREF="os.html#131"><STRONG>RAM</STRONG></A>
<DT><A NAME="tex2html318"
 HREF="os.html#5522"><STRONG>RARP</STRONG></A>
<DT><A NAME="tex2html65"
 HREF="os.html#548"><STRONG>Register</STRONG></A>
<DT><A NAME="tex2html190"
 HREF="os.html#2358"><STRONG>Relative addressing</STRONG></A>
<DT><A NAME="tex2html305"
 HREF="os.html#5403"><STRONG>Reliable protocol</STRONG></A>
<DT><A NAME="tex2html331"
 HREF="os.html#5642"><STRONG>Resolving addresses</STRONG></A>
<DT><A NAME="tex2html30"
 HREF="os.html#89"><STRONG>Resources</STRONG></A>
<DT><A NAME="tex2html127"
 HREF="os.html#1099"><STRONG>Response time</STRONG></A>
<DT><A NAME="tex2html316"
 HREF="os.html#5487"><STRONG>Rings</STRONG></A>
<DT><A NAME="tex2html48"
 HREF="os.html#132"><STRONG>ROM</STRONG></A>
<DT><A NAME="tex2html148"
 HREF="os.html#1220"><STRONG>Round robin scheduling</STRONG></A>
<DT><A NAME="tex2html117"
 HREF="os.html#1083"><STRONG>Round-robin</STRONG></A>
<DT><A NAME="tex2html301"
 HREF="os.html#5389"><STRONG>Router</STRONG></A>
<A NAME="tex2html327"
 HREF="os.html#5628">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html296"
 HREF="os.html#5342"><STRONG>RPC</STRONG></A>
<A NAME="tex2html342"
 HREF="os.html#5663">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html270"
 HREF="os.html#4827">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<A NAME="tex2html277"
 HREF="os.html#4872">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html151"
 HREF="os.html#1225"><STRONG>RR</STRONG></A>
<DT><A NAME="tex2html244"
 HREF="os.html#2950"><STRONG>SCAN algorithm</STRONG></A>
<DT><A NAME="tex2html126"
 HREF="os.html#1094"><STRONG>Scheduing criterea</STRONG></A>
<DT><A NAME="tex2html118"
 HREF="os.html#1067"><STRONG>Scheduling</STRONG></A>
<A NAME="tex2html32"
 HREF="os.html#94">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html61"
 HREF="os.html#201"><STRONG>Screens</STRONG></A>
<DT><A NAME="tex2html231"
 HREF="os.html#2914"><STRONG>SCSI</STRONG></A>
<DT><A NAME="tex2html139"
 HREF="os.html#1141"><STRONG>Seamphores</STRONG></A>
<DT><A NAME="tex2html218"
 HREF="os.html#2810"><STRONG>Second chance algorithm</STRONG></A>
<DT><A NAME="tex2html52"
 HREF="os.html#141"><STRONG>Secondary memory</STRONG></A>
<DT><A NAME="tex2html223"
 HREF="os.html#2888"><STRONG>Secondary storage</STRONG></A>
<DT><A NAME="tex2html228"
 HREF="os.html#2905"><STRONG>Sectors</STRONG></A>
<DT><A NAME="tex2html348"
 HREF="os.html#6508"><STRONG>Security</STRONG></A>
<DT><A NAME="tex2html96"
 HREF="os.html#817"><STRONG>Segmentation</STRONG></A>
<A NAME="tex2html202"
 HREF="os.html#2444">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html97"
 HREF="os.html#818"><STRONG>Segmentation fault</STRONG></A>
<DT><A NAME="tex2html168"
 HREF="os.html#1315"><STRONG>Serialization</STRONG></A>
<A NAME="tex2html137"
 HREF="os.html#1136">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html104"
 HREF="os.html#849"><STRONG>Services</STRONG></A>
<DT><A NAME="tex2html291"
 HREF="os.html#5329"><STRONG>Session layer</STRONG></A>
<DT><A NAME="tex2html352"
 HREF="os.html#6564"><STRONG>Setuid programs</STRONG></A>
<DT><A NAME="tex2html167"
 HREF="os.html#1308"><STRONG>Shared data</STRONG></A>
<DT><A NAME="tex2html193"
 HREF="os.html#2374"><STRONG>Shared libraries</STRONG></A>
<DT><A NAME="tex2html121"
 HREF="os.html#1078"><STRONG>Shortest job first</STRONG></A>
<DT><A NAME="tex2html243"
 HREF="os.html#2948"><STRONG>Shortest seek time first algorithm</STRONG></A>
<DT><A NAME="tex2html175"
 HREF="os.html#1348"><STRONG>Signals</STRONG></A>
<DT><A NAME="tex2html8"
 HREF="os.html#42"><STRONG>Single task
system</STRONG></A>
<DT><A NAME="tex2html6"
 HREF="os.html#37"><STRONG>Single user mode</STRONG></A>
<DT><A NAME="tex2html120"
 HREF="os.html#1077"><STRONG>SJF</STRONG></A>
<DT><A NAME="tex2html158"
 HREF="os.html#1273"><STRONG>SMP</STRONG></A>
<DT><A NAME="tex2html269"
 HREF="os.html#4826"><STRONG>Socket</STRONG></A>
<DT><A NAME="tex2html292"
 HREF="os.html#5330"><STRONG>Sockets</STRONG></A>
<DT><A NAME="tex2html174"
 HREF="os.html#1344"><STRONG>Spin lock</STRONG></A>
<DT><A NAME="tex2html57"
 HREF="os.html#159"><STRONG>Spooling</STRONG></A>
<DT><A NAME="tex2html361"
 HREF="os.html#6612"><STRONG>SSL</STRONG></A>
<DT><A NAME="tex2html242"
 HREF="os.html#2947"><STRONG>SSTF</STRONG></A>
<DT><A NAME="tex2html73"
 HREF="os.html#576"><STRONG>Stack frame</STRONG></A>
<DT><A NAME="tex2html74"
 HREF="os.html#578"><STRONG>Stack overflow</STRONG></A>
<DT><A NAME="tex2html68"
 HREF="os.html#551"><STRONG>Stack pointer</STRONG></A>
<DT><A NAME="tex2html241"
 HREF="os.html#2946"><STRONG>Starvation</STRONG></A>
<DT><A NAME="tex2html69"
 HREF="os.html#552"><STRONG>Status register</STRONG></A>
<DT><A NAME="tex2html21"
 HREF="os.html#63"><STRONG>Sun Microsystems</STRONG></A>
<A NAME="tex2html336"
 HREF="os.html#5651">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html89"
 HREF="os.html#793"><STRONG>Super user</STRONG></A>
<DT><A NAME="tex2html90"
 HREF="os.html#794"><STRONG>Supervisor</STRONG></A>
<DT><A NAME="tex2html94"
 HREF="os.html#805"><STRONG>Supervisor mode</STRONG></A>
<DT><A NAME="tex2html211"
 HREF="os.html#2732"><STRONG>Swapping</STRONG></A>
<DT><A NAME="tex2html107"
 HREF="os.html#864"><STRONG>Syhcronization</STRONG></A>
<DT><A NAME="tex2html159"
 HREF="os.html#1274"><STRONG>Symmetric multiprocessing</STRONG></A>
<DT><A NAME="tex2html165"
 HREF="os.html#1299"><STRONG>Synchronization</STRONG></A>
<DT><A NAME="tex2html80"
 HREF="os.html#600"><STRONG>Synchronous I/O</STRONG></A>
<DT><A NAME="tex2html20"
 HREF="os.html#62"><STRONG>System 5/System V</STRONG></A>
<DT><A NAME="tex2html58"
 HREF="os.html#168"><STRONG>System calls</STRONG></A>
<DT><A NAME="tex2html39"
 HREF="os.html#112"><STRONG>System overhead</STRONG></A>
<DT><A NAME="tex2html112"
 HREF="os.html#1049"><STRONG>Task</STRONG></A>
<DT><A NAME="tex2html303"
 HREF="os.html#5393"><STRONG>TCP</STRONG></A>
<DT><A NAME="tex2html282"
 HREF="os.html#5305"><STRONG>TCP/IP</STRONG></A>
<DT><A NAME="tex2html278"
 HREF="os.html#4881"><STRONG>Telnet</STRONG></A>
<A NAME="tex2html274"
 HREF="os.html#4846">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html208"
 HREF="os.html#2719"><STRONG>Tetris algorithm</STRONG></A>
<DT><A NAME="tex2html222"
 HREF="os.html#2883"><STRONG>Thrashing</STRONG></A>
<DT><A NAME="tex2html109"
 HREF="os.html#1057"><STRONG>Thread</STRONG></A>
<DT><A NAME="tex2html157"
 HREF="os.html#1262"><STRONG>Thread levels</STRONG></A>
<DT><A NAME="tex2html155"
 HREF="os.html#1236"><STRONG>Threads</STRONG></A>
<DT><A NAME="tex2html98"
 HREF="os.html#822"><STRONG>Time sharing</STRONG></A>
<DT><A NAME="tex2html227"
 HREF="os.html#2902"><STRONG>Track</STRONG></A>
<DT><A NAME="tex2html345"
 HREF="os.html#5671"><STRONG>Transarc</STRONG></A>
<DT><A NAME="tex2html290"
 HREF="os.html#5326"><STRONG>Transport layer</STRONG></A>
<DT><A NAME="tex2html55"
 HREF="os.html#146"><STRONG>Traps</STRONG></A>
<DT><A NAME="tex2html357"
 HREF="os.html#6593"><STRONG>Trojan horse</STRONG></A>
<DT><A NAME="tex2html92"
 HREF="os.html#797"><STRONG>Two mode operation</STRONG></A>
<DT><A NAME="tex2html304"
 HREF="os.html#5394"><STRONG>UDP</STRONG></A>
<DT><A NAME="tex2html264"
 HREF="os.html#3049"><STRONG>UFS filesystem</STRONG></A>
<DT><A NAME="tex2html88"
 HREF="os.html#785"><STRONG>UID</STRONG></A>
<DT><A NAME="tex2html306"
 HREF="os.html#5404"><STRONG>Unreliable protocol</STRONG></A>
<DT><A NAME="tex2html87"
 HREF="os.html#784"><STRONG>User ID</STRONG></A>
<DT><A NAME="tex2html93"
 HREF="os.html#804"><STRONG>User mode</STRONG></A>
<DT><A NAME="tex2html85"
 HREF="os.html#782"><STRONG>Users</STRONG></A>
<DT><A NAME="tex2html209"
 HREF="os.html#2730"><STRONG>Virtual memory</STRONG></A>
<DT><A NAME="tex2html355"
 HREF="os.html#6585"><STRONG>Virus</STRONG></A>
<DT><A NAME="tex2html43"
 HREF="os.html#125"><STRONG>VLSI</STRONG></A>
<DT><A NAME="tex2html176"
 HREF="os.html#1349"><STRONG>Waiting</STRONG></A>
<DT><A NAME="tex2html273"
 HREF="os.html#4845"><STRONG>Well known ports</STRONG></A>
<DT><A NAME="tex2html63"
 HREF="os.html#209"><STRONG>Window system</STRONG></A>
<DT><A NAME="tex2html11"
 HREF="os.html#50"><STRONG>Windows</STRONG></A>
<A NAME="tex2html62"
 HREF="os.html#202">, <STRONG><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="http://markburgess.org/usr/share/latex2html/icons/crossref.png"></STRONG></A>
<DT><A NAME="tex2html186"
 HREF="os.html#2345"><STRONG>Word size</STRONG></A>
<DT><A NAME="tex2html354"
 HREF="os.html#6584"><STRONG>Worm</STRONG></A>
<DT><A NAME="tex2html281"
 HREF="os.html#4892"><STRONG>X windows</STRONG></A>
<DT><A NAME="tex2html280"
 HREF="os.html#4891"><STRONG>X11</STRONG></A>
<DT><A NAME="tex2html271"
 HREF="os.html#4828"><STRONG>XDR</STRONG></A>
</DL>
</FONT><FONT SIZE="-2">
</FONT>
<H1><A NAME="SECTION001200000000000000000">
About this document ...</A>
</H1><FONT SIZE="-2">
 </FONT><STRONG>A short introduction to operating systems</STRONG><P>
This document was generated using the
<A HREF="http://www-dsed.llnl.gov/files/programs/unix/latex2html/manual/"><STRONG>LaTeX</STRONG>2<tt>HTML</tt></A> translator Version 99.2beta6 (1.42)
<P>
Copyright &#169; 1993, 1994, 1995, 1996,
<A HREF="http://cbl.leeds.ac.uk/nikos/personal.html">Nikos Drakos</A>, 
Computer Based Learning Unit, University of Leeds.
<BR>
Copyright &#169; 1997, 1998, 1999,
<A HREF="http://www.maths.mq.edu.au/~ross/">Ross Moore</A>, 
Mathematics Department, Macquarie University, Sydney.
<P>
The command line arguments were: <BR>
 <STRONG>latex2html</STRONG> <TT>-show_section_numbers -split 1 os.tex</TT>
<P>
The translation was initiated by Mark Burgess on 2001-10-03<HR>
<!--Navigation Panel-->
<IMG WIDTH="81" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next_inactive"
 SRC="http://markburgess.org/usr/share/latex2html/icons/nx_grp_g.png"> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="http://markburgess.org/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="http://markburgess.org/usr/share/latex2html/icons/prev_g.png">   
<BR>
<!--End of Navigation Panel-->
<ADDRESS>
Mark Burgess
2001-10-03
</ADDRESS>
</BODY>
</HTML>
